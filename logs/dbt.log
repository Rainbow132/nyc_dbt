[0m16:29:30.052304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A6FB87580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A7279D520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A7279D3D0>]}


============================== 16:29:30.056276 | 22d5dccf-82e5-4b58-9d74-7c9449a469ac ==============================
[0m16:29:30.056276 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:29:30.057305 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:29:30.084279 [info ] [MainThread]: dbt version: 1.8.9
[0m16:29:30.085278 [info ] [MainThread]: python version: 3.9.0
[0m16:29:30.086276 [info ] [MainThread]: python path: F:\anaconda3\envs\tomato\python.exe
[0m16:29:30.087278 [info ] [MainThread]: os info: Windows-10-10.0.19041-SP0
[0m16:29:31.476059 [info ] [MainThread]: Using profiles dir at C:\Users\Êù∞Âì•Â∏¶Â∏ÖÊØî\.dbt
[0m16:29:31.476059 [info ] [MainThread]: Using profiles.yml file at C:\Users\Êù∞Âì•Â∏¶Â∏ÖÊØî\.dbt\profiles.yml
[0m16:29:31.477058 [info ] [MainThread]: Using dbt_project.yml file at E:\Á®ãÂ∫è\data-engineering-zoomcamp-main\04-analytics-engineering\homework\dbt_project.yml
[0m16:29:31.478059 [info ] [MainThread]: adapter type: maxcompute
[0m16:29:31.479058 [info ] [MainThread]: adapter version: 1.8.0-alpha8
[0m16:29:31.592059 [info ] [MainThread]: Configuration:
[0m16:29:31.593061 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m16:29:31.593061 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:29:31.594058 [info ] [MainThread]: Required dependencies:
[0m16:29:31.595059 [debug] [MainThread]: Executing "git --help"
[0m16:29:31.698058 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:29:31.699059 [debug] [MainThread]: STDERR: "b''"
[0m16:29:31.700058 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m16:29:31.700058 [info ] [MainThread]: Connection:
[0m16:29:31.701056 [info ] [MainThread]:   project: dataengine_learning
[0m16:29:31.702058 [info ] [MainThread]:   database: dataengine_learning
[0m16:29:31.703059 [info ] [MainThread]:   schema: default
[0m16:29:31.703059 [info ] [MainThread]:   endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
[0m16:29:31.705060 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m16:29:32.507585 [debug] [MainThread]: Acquiring new maxcompute connection 'debug'
[0m16:29:32.739245 [debug] [MainThread]: Using maxcompute connection "debug"
[0m16:29:32.740245 [debug] [MainThread]: On debug: select 1 as id
[0m16:29:32.741245 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:29:36.636623 [debug] [MainThread]: MaxCompute adapter: Current instance id is 20241127082935388g7xhzo8idlr
[0m16:29:36.637620 [debug] [MainThread]: SQL status: OK in 3.897 seconds
[0m16:29:36.637620 [debug] [MainThread]: MaxCompute adapter: Current instance id is 20241127082935388g7xhzo8idlr
[0m16:29:36.638619 [debug] [MainThread]: On debug: Close
[0m16:29:36.639618 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m16:29:36.640618 [info ] [MainThread]: [32mAll checks passed![0m
[0m16:29:36.642618 [debug] [MainThread]: Command `dbt debug` succeeded at 16:29:36.642618 after 6.65 seconds
[0m16:29:36.642618 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m16:29:36.643620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A6FB87580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A704EF6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A0C708DC0>]}
[0m16:29:36.644619 [debug] [MainThread]: Flushing usage events
[0m16:29:36.678807 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m16:24:17.101377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A796E108B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A799A23970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A799A23AC0>]}


============================== 16:24:17.106888 | 32f663b4-e3a5-4954-9e9f-36332f782eb3 ==============================
[0m16:24:17.106888 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:24:17.106888 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'e:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt ', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:24:19.373577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '32f663b4-e3a5-4954-9e9f-36332f782eb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7999DD490>]}
[0m16:24:19.504615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '32f663b4-e3a5-4954-9e9f-36332f782eb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A79980ECD0>]}
[0m16:24:19.506615 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m16:24:20.312410 [debug] [MainThread]: checksum: 7c9f24cadb9ed71bfad0146ef54df7f5d259c85b535c1ae4260269edc44b8995, vars: {}, profile: , target: dev, version: 1.8.9
[0m16:24:20.460375 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m16:24:20.460375 [debug] [MainThread]: previous checksum: 7c9f24cadb9ed71bfad0146ef54df7f5d259c85b535c1ae4260269edc44b8995, current checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1
[0m16:24:20.461376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '32f663b4-e3a5-4954-9e9f-36332f782eb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A79777F070>]}
[0m16:24:22.018649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '32f663b4-e3a5-4954-9e9f-36332f782eb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B5021E80>]}
[0m16:24:22.189502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '32f663b4-e3a5-4954-9e9f-36332f782eb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B5048DF0>]}
[0m16:24:22.190505 [info ] [MainThread]: Found 2 models, 4 data tests, 424 macros
[0m16:24:22.191505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32f663b4-e3a5-4954-9e9f-36332f782eb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B5079520>]}
[0m16:24:22.193509 [info ] [MainThread]: 
[0m16:24:22.195506 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m16:24:22.197541 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m16:24:22.198542 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:24:23.111208 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m16:24:23.112282 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m16:24:23.119260 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m16:24:23.119776 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m16:24:23.120302 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:24:26.480801 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m16:24:26.485648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32f663b4-e3a5-4954-9e9f-36332f782eb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B3912F40>]}
[0m16:24:26.486209 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:24:26.486740 [info ] [MainThread]: 
[0m16:24:26.491458 [debug] [Thread-2  ]: Began running node model.homework.my_first_dbt_model
[0m16:24:26.492458 [info ] [Thread-2  ]: 1 of 1 START sql table model default.my_first_dbt_model ........................ [RUN]
[0m16:24:26.493458 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.my_first_dbt_model'
[0m16:24:26.493458 [debug] [Thread-2  ]: Began compiling node model.homework.my_first_dbt_model
[0m16:24:26.505457 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.my_first_dbt_model"
[0m16:24:26.508458 [debug] [Thread-2  ]: Began executing node model.homework.my_first_dbt_model
[0m16:24:26.565791 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.my_first_dbt_model"
[0m16:24:26.749634 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.my_first_dbt_model"
[0m16:24:26.750197 [debug] [Thread-2  ]: On model.homework.my_first_dbt_model: 
  
    CREATE TABLE IF NOT EXISTS `dataengine_learning`.`default`.`my_first_dbt_model__dbt_tmp`
    
    AS (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    )
    ;

  
[0m16:24:26.750197 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m16:24:29.576239 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241129082427202g153aluwhm1
[0m16:24:29.576808 [debug] [Thread-2  ]: SQL status: OK in 2.826 seconds
[0m16:24:29.577375 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241129082427202g153aluwhm1
[0m16:24:29.781750 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.my_first_dbt_model"
[0m16:24:29.782307 [debug] [Thread-2  ]: On model.homework.my_first_dbt_model: ALTER TABLE `dataengine_learning`.`default`.`my_first_dbt_model__dbt_tmp`
            RENAME TO my_first_dbt_model;
        
[0m16:24:30.829821 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241129082429945gvu3bq7i4gg
[0m16:24:30.830352 [debug] [Thread-2  ]: SQL status: OK in 1.047 seconds
[0m16:24:30.830883 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241129082429945gvu3bq7i4gg
[0m16:24:30.852437 [debug] [Thread-2  ]: On model.homework.my_first_dbt_model: COMMIT
[0m16:24:31.499996 [debug] [Thread-2  ]: On model.homework.my_first_dbt_model: Close
[0m16:24:31.502117 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '32f663b4-e3a5-4954-9e9f-36332f782eb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7971DF760>]}
[0m16:24:31.503305 [info ] [Thread-2  ]: 1 of 1 OK created sql table model default.my_first_dbt_model ................... [[32mOK[0m in 5.01s]
[0m16:24:31.504374 [debug] [Thread-2  ]: Finished running node model.homework.my_first_dbt_model
[0m16:24:31.507062 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:24:31.507583 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m16:24:31.507583 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m16:24:31.508580 [debug] [MainThread]: Connection 'model.homework.my_first_dbt_model' was properly closed.
[0m16:24:31.508580 [info ] [MainThread]: 
[0m16:24:31.509580 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 9.31 seconds (9.31s).
[0m16:24:31.510601 [debug] [MainThread]: Command end result
[0m16:24:31.552410 [info ] [MainThread]: 
[0m16:24:31.554410 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:24:31.554410 [info ] [MainThread]: 
[0m16:24:31.555409 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:24:31.556411 [debug] [MainThread]: Command `cli run` succeeded at 16:24:31.556411 after 14.52 seconds
[0m16:24:31.557448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A796E108B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B5048DF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A797302D30>]}
[0m16:24:31.557448 [debug] [MainThread]: Flushing usage events
[0m16:24:31.592247 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m15:17:37.763052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152118375B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001521444A550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001521444A400>]}


============================== 15:17:37.767055 | f08da290-cd1f-4758-b5cd-4c9b67328ee7 ==============================
[0m15:17:37.767055 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:17:37.767055 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:17:37.792052 [info ] [MainThread]: dbt version: 1.8.9
[0m15:17:37.793052 [info ] [MainThread]: python version: 3.9.0
[0m15:17:37.794052 [info ] [MainThread]: python path: F:\anaconda3\envs\tomato\python.exe
[0m15:17:37.794052 [info ] [MainThread]: os info: Windows-10-10.0.19041-SP0
[0m15:17:39.162740 [info ] [MainThread]: Using profiles dir at C:\Users\Êù∞Âì•Â∏¶Â∏ÖÊØî\.dbt
[0m15:17:39.163826 [info ] [MainThread]: Using profiles.yml file at C:\Users\Êù∞Âì•Â∏¶Â∏ÖÊØî\.dbt\profiles.yml
[0m15:17:39.164740 [info ] [MainThread]: Using dbt_project.yml file at E:\Á®ãÂ∫è\data-engineering-zoomcamp-main\04-analytics-engineering\homework\dbt_project.yml
[0m15:17:39.165740 [info ] [MainThread]: adapter type: maxcompute
[0m15:17:39.165740 [info ] [MainThread]: adapter version: 1.8.0-alpha8
[0m15:17:39.278361 [info ] [MainThread]: Configuration:
[0m15:17:39.278361 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m15:17:39.279361 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m15:17:39.280361 [info ] [MainThread]: Required dependencies:
[0m15:17:39.281364 [debug] [MainThread]: Executing "git --help"
[0m15:17:39.374873 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:17:39.374873 [debug] [MainThread]: STDERR: "b''"
[0m15:17:39.375875 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:17:39.376901 [info ] [MainThread]: Connection:
[0m15:17:39.377873 [info ] [MainThread]:   project: dataengine_learning
[0m15:17:39.378875 [info ] [MainThread]:   database: dataengine_learning
[0m15:17:39.379874 [info ] [MainThread]:   schema: default
[0m15:17:39.380874 [info ] [MainThread]:   endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
[0m15:17:39.381874 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m15:17:40.128018 [debug] [MainThread]: Acquiring new maxcompute connection 'debug'
[0m15:17:40.504785 [debug] [MainThread]: Using maxcompute connection "debug"
[0m15:17:40.504785 [debug] [MainThread]: On debug: select 1 as id
[0m15:17:40.505784 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:17:43.323582 [debug] [MainThread]: MaxCompute adapter: Current instance id is 20241202071743557g78jld9tjxh5
[0m15:17:43.323582 [debug] [MainThread]: SQL status: OK in 2.819 seconds
[0m15:17:43.324581 [debug] [MainThread]: MaxCompute adapter: Current instance id is 20241202071743557g78jld9tjxh5
[0m15:17:43.325582 [debug] [MainThread]: On debug: Close
[0m15:17:43.325582 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m15:17:43.326582 [info ] [MainThread]: [32mAll checks passed![0m
[0m15:17:43.328582 [debug] [MainThread]: Command `dbt debug` succeeded at 15:17:43.328582 after 5.64 seconds
[0m15:17:43.329605 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m15:17:43.329605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152118375B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001522E32AAF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001522E3D5610>]}
[0m15:17:43.330582 [debug] [MainThread]: Flushing usage events
[0m21:00:15.805189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C14847520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C1745D490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C1745D340>]}


============================== 21:00:15.810190 | a0ed5aeb-8519-4144-9e4b-4b27bf7557bd ==============================
[0m21:00:15.810190 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:00:15.811191 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:00:16.063055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a0ed5aeb-8519-4144-9e4b-4b27bf7557bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C174B4E20>]}
[0m21:00:16.104055 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m21:00:16.106086 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m21:00:16.109084 [debug] [MainThread]: Command `dbt deps` succeeded at 21:00:16.108086 after 0.37 seconds
[0m21:00:16.109084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C14847520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C14C16A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024C17555850>]}
[0m21:00:16.110124 [debug] [MainThread]: Flushing usage events
[0m21:00:16.160081 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:01:53.678616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029E9C7F7580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029E9F41B610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029E9F41B4C0>]}


============================== 21:01:53.683580 | 8c51cae4-b619-492d-8e1d-dbb00b96569e ==============================
[0m21:01:53.683580 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:01:53.684577 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:01:55.769020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8c51cae4-b619-492d-8e1d-dbb00b96569e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029EB92FE0A0>]}
[0m21:01:55.893068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8c51cae4-b619-492d-8e1d-dbb00b96569e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029EB930AC10>]}
[0m21:01:55.894071 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:01:56.666225 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:01:56.900224 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 6 files added, 1 files changed.
[0m21:01:56.901224 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_yellow_tripdata.sql
[0m21:01:56.901224 [debug] [MainThread]: Partial parsing: added file: homework://models\core\fact_trips.sql
[0m21:01:56.902224 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_green_tripdata.sql
[0m21:01:56.902224 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\base_homework_yellow_taxi_trips_in.sql
[0m21:01:56.903223 [debug] [MainThread]: Partial parsing: added file: homework://models\overview.md
[0m21:01:56.904222 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_fhv_tripdata.sql
[0m21:01:56.904222 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m21:01:57.223525 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid sources config given in models\staging\schema.yml @ sources: {'name': 'stg_yellow_tripdata', 'columns': [{'name': 'tripid', 'tests': ['unique', 'not_null']}, {'name': 'pickup_datetime', 'tests': ['not_null']}]} - at path []: Additional properties are not allowed ('columns' was unexpected)
[0m21:01:57.225487 [debug] [MainThread]: Command `dbt run` failed at 21:01:57.225487 after 3.60 seconds
[0m21:01:57.226488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029E9C7F7580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029EBA846C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029EBA7C1AC0>]}
[0m21:01:57.227488 [debug] [MainThread]: Flushing usage events
[0m21:01:57.248094 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:07:59.004763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DE5587580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DE81AB610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DE81AB4C0>]}


============================== 21:07:59.008740 | 70971eec-a228-4c60-908b-868d22d6b0b2 ==============================
[0m21:07:59.008740 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:07:59.011175 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:08:00.495369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '70971eec-a228-4c60-908b-868d22d6b0b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019D8208E0A0>]}
[0m21:08:00.609020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '70971eec-a228-4c60-908b-868d22d6b0b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019D8209AC10>]}
[0m21:08:00.610020 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:08:01.357662 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:08:01.587838 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 6 files added, 1 files changed.
[0m21:08:01.588884 [debug] [MainThread]: Partial parsing: added file: homework://models\overview.md
[0m21:08:01.589837 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_yellow_tripdata.sql
[0m21:08:01.589837 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_green_tripdata.sql
[0m21:08:01.590837 [debug] [MainThread]: Partial parsing: added file: homework://models\core\fact_trips.sql
[0m21:08:01.590837 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\base_homework_yellow_taxi_trips_in.sql
[0m21:08:01.591838 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_fhv_tripdata.sql
[0m21:08:01.591838 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m21:08:01.898879 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid sources config given in models\staging\schema.yml @ sources: {'name': 'stg_green_tripdata', 'columns': [{'name': 'tripid', 'tests': ['unique', 'not_null']}, {'name': 'pickup_datetime', 'tests': ['not_null']}]} - at path []: Additional properties are not allowed ('columns' was unexpected)
[0m21:08:01.901879 [debug] [MainThread]: Command `dbt run` failed at 21:08:01.901879 after 2.96 seconds
[0m21:08:01.902878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DE5587580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019D835D6C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019D83551AC0>]}
[0m21:08:01.903878 [debug] [MainThread]: Flushing usage events
[0m21:08:01.922261 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:10:21.237555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207D2FA7580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207D5BCB610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207D5BCB4C0>]}


============================== 21:10:21.240551 | ddcb7647-c2a8-49da-b689-d4cf6125f6e3 ==============================
[0m21:10:21.240551 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:10:21.242552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m21:10:22.778684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ddcb7647-c2a8-49da-b689-d4cf6125f6e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207EFAAE0A0>]}
[0m21:10:22.910628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ddcb7647-c2a8-49da-b689-d4cf6125f6e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207EFABAC10>]}
[0m21:10:22.911630 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:10:23.647217 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:10:23.874480 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 6 files added, 1 files changed.
[0m21:10:23.874480 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\base_homework_yellow_taxi_trips_in.sql
[0m21:10:23.875480 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_green_tripdata.sql
[0m21:10:23.875480 [debug] [MainThread]: Partial parsing: added file: homework://models\overview.md
[0m21:10:23.876479 [debug] [MainThread]: Partial parsing: added file: homework://models\core\fact_trips.sql
[0m21:10:23.876479 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_yellow_tripdata.sql
[0m21:10:23.877480 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_fhv_tripdata.sql
[0m21:10:23.877480 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m21:10:24.163338 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:10:24.164338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'ddcb7647-c2a8-49da-b689-d4cf6125f6e3', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207F0F89A90>]}
[0m21:10:24.390293 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.base_homework_yellow_taxi_trips_in' (models\staging\base_homework_yellow_taxi_trips_in.sql) depends on a source named 'homework.yellow_taxi_trips_in' which was not found
[0m21:10:24.394293 [debug] [MainThread]: Command `dbt run` failed at 21:10:24.393292 after 3.22 seconds
[0m21:10:24.394293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207D2FA7580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207F124B520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207F124BCD0>]}
[0m21:10:24.395292 [debug] [MainThread]: Flushing usage events
[0m21:10:24.412400 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:12:10.343632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F567CD75B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F56A90B640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F56A90B4F0>]}


============================== 21:12:10.348053 | cb0a5693-83a9-4c62-b7a6-48a003e854c5 ==============================
[0m21:12:10.348053 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:12:10.349118 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:12:11.860256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cb0a5693-83a9-4c62-b7a6-48a003e854c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5680AA940>]}
[0m21:12:11.979236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cb0a5693-83a9-4c62-b7a6-48a003e854c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F56A8C0790>]}
[0m21:12:11.981236 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:12:12.723571 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:12:12.984152 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 6 files added, 1 files changed.
[0m21:12:12.985151 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_green_tripdata.sql
[0m21:12:12.985151 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_yellow_tripdata.sql
[0m21:12:12.986153 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_fhv_tripdata.sql
[0m21:12:12.986153 [debug] [MainThread]: Partial parsing: added file: homework://models\core\fact_trips.sql
[0m21:12:12.987190 [debug] [MainThread]: Partial parsing: added file: homework://models\overview.md
[0m21:12:12.987190 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\base_homework_yellow_taxi_trips_in.sql
[0m21:12:12.988194 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m21:12:12.989196 [debug] [MainThread]: Partial parsing: deleted file: homework://models\example\my_first_dbt_model.sql
[0m21:12:13.285775 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:12:13.287774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'cb0a5693-83a9-4c62-b7a6-48a003e854c5', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F505CB8880>]}
[0m21:12:13.504774 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'my_first_dbt_model' in the 'models' section of file 'models\example\schema.yml'
[0m21:12:13.523775 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.stg_green_tripdata' (models\staging\stg_green_tripdata.sql) depends on a source named 'nyc_taxi.green_taxi_trips_in' which was not found
[0m21:12:13.526774 [debug] [MainThread]: Command `dbt run` failed at 21:12:13.526774 after 3.25 seconds
[0m21:12:13.527775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F567CD75B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F505FB8820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F505FB8430>]}
[0m21:12:13.527775 [debug] [MainThread]: Flushing usage events
[0m21:12:13.547658 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:14:04.413525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5B5C37520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5B885B580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5B885B430>]}


============================== 21:14:04.416989 | e302bea4-567f-4694-82ad-aaf6a3836c3a ==============================
[0m21:14:04.416989 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:14:04.417990 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m21:14:06.188849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e302bea4-567f-4694-82ad-aaf6a3836c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5D273ADC0>]}
[0m21:14:06.317844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e302bea4-567f-4694-82ad-aaf6a3836c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5D2845E20>]}
[0m21:14:06.318840 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:14:07.104062 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:14:07.324418 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 6 files added, 1 files changed.
[0m21:14:07.325461 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\base_homework_yellow_taxi_trips_in.sql
[0m21:14:07.325461 [debug] [MainThread]: Partial parsing: added file: homework://models\core\fact_trips.sql
[0m21:14:07.326455 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_green_tripdata.sql
[0m21:14:07.326455 [debug] [MainThread]: Partial parsing: added file: homework://models\overview.md
[0m21:14:07.327455 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_fhv_tripdata.sql
[0m21:14:07.327455 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_yellow_tripdata.sql
[0m21:14:07.328456 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m21:14:07.328456 [debug] [MainThread]: Partial parsing: deleted file: homework://models\example\my_first_dbt_model.sql
[0m21:14:07.612491 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:14:07.614493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'e302bea4-567f-4694-82ad-aaf6a3836c3a', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5D27815B0>]}
[0m21:14:07.837886 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'my_first_dbt_model' in the 'models' section of file 'models\example\schema.yml'
[0m21:14:07.857886 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.base_homework_yellow_taxi_trips_in' (models\staging\base_homework_yellow_taxi_trips_in.sql) depends on a source named 'homework.yellow_taxi_trips_in' which was not found
[0m21:14:07.859888 [debug] [MainThread]: Command `dbt run` failed at 21:14:07.859888 after 3.52 seconds
[0m21:14:07.860889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5B5C37520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5D3C09D60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5D3C868E0>]}
[0m21:14:07.861887 [debug] [MainThread]: Flushing usage events
[0m21:14:07.880455 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:14:48.726101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2BF0875B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2C1CAB640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2C1CAB4F0>]}


============================== 21:14:48.730067 | 33117c84-a1f1-45a0-9ceb-daa0e19d5206 ==============================
[0m21:14:48.730067 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:14:48.731071 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:14:50.237105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '33117c84-a1f1-45a0-9ceb-daa0e19d5206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2BF45A940>]}
[0m21:14:50.352784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '33117c84-a1f1-45a0-9ceb-daa0e19d5206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2C1C60790>]}
[0m21:14:50.353782 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:14:51.093007 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:14:51.313619 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 5 files added, 1 files changed.
[0m21:14:51.314622 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_green_tripdata.sql
[0m21:14:51.314622 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_fhv_tripdata.sql
[0m21:14:51.315619 [debug] [MainThread]: Partial parsing: added file: homework://models\overview.md
[0m21:14:51.315619 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_yellow_tripdata.sql
[0m21:14:51.316619 [debug] [MainThread]: Partial parsing: added file: homework://models\core\fact_trips.sql
[0m21:14:51.316619 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m21:14:51.317617 [debug] [MainThread]: Partial parsing: deleted file: homework://models\example\my_first_dbt_model.sql
[0m21:14:51.600500 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:14:51.601501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '33117c84-a1f1-45a0-9ceb-daa0e19d5206', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2DCF945B0>]}
[0m21:14:51.818877 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'my_first_dbt_model' in the 'models' section of file 'models\example\schema.yml'
[0m21:14:51.836880 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.fact_trips' (models\core\fact_trips.sql) depends on a node named 'dim_zones' which was not found
[0m21:14:51.839878 [debug] [MainThread]: Command `dbt run` failed at 21:14:51.839878 after 3.17 seconds
[0m21:14:51.840878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2BF0875B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2DD0442E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2DD10B9A0>]}
[0m21:14:51.841875 [debug] [MainThread]: Flushing usage events
[0m21:14:51.865702 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:32:37.919635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2260D7580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A228CFC610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A228CFC4C0>]}


============================== 21:32:37.923635 | a9161cdf-138a-4277-88c6-4e225c1e250b ==============================
[0m21:32:37.923635 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:32:37.924638 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m21:32:39.478621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a9161cdf-138a-4277-88c6-4e225c1e250b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A242BDE0A0>]}
[0m21:32:39.613109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a9161cdf-138a-4277-88c6-4e225c1e250b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A242BEAC10>]}
[0m21:32:39.615108 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:32:40.389733 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:32:40.619416 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 7 files added, 1 files changed.
[0m21:32:40.620415 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_taxi_zone_lookup.sql
[0m21:32:40.620415 [debug] [MainThread]: Partial parsing: added file: homework://models\overview.md
[0m21:32:40.621416 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_fhv_tripdata.sql
[0m21:32:40.621416 [debug] [MainThread]: Partial parsing: added file: homework://models\core\dim_zones.sql
[0m21:32:40.622415 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_green_tripdata.sql
[0m21:32:40.622415 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_yellow_tripdata.sql
[0m21:32:40.623416 [debug] [MainThread]: Partial parsing: added file: homework://models\core\fact_trips.sql
[0m21:32:40.623416 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m21:32:40.624416 [debug] [MainThread]: Partial parsing: deleted file: homework://models\example\my_first_dbt_model.sql
[0m21:32:40.922414 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:32:40.923413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'a9161cdf-138a-4277-88c6-4e225c1e250b', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A24426F490>]}
[0m21:32:41.181739 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'my_first_dbt_model' in the 'models' section of file 'models\example\schema.yml'
[0m21:32:41.199658 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.dim_zones' (models\core\dim_zones.sql) depends on a node named 'taxi_zone_lookup' which was not found
[0m21:32:41.202657 [debug] [MainThread]: Command `dbt run` failed at 21:32:41.202657 after 3.35 seconds
[0m21:32:41.203656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2260D7580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2441B8820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2443680D0>]}
[0m21:32:41.203656 [debug] [MainThread]: Flushing usage events
[0m21:32:41.223821 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:39:36.341035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024CA47565B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024CA737B640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024CA737B4F0>]}


============================== 21:39:36.345036 | a0ec5686-f4fb-4867-87ae-2270c8e62d59 ==============================
[0m21:39:36.345036 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:39:36.346038 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --full-refresh', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:39:37.877347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a0ec5686-f4fb-4867-87ae-2270c8e62d59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024CA4B2A940>]}
[0m21:39:38.026373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a0ec5686-f4fb-4867-87ae-2270c8e62d59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024CA7330790>]}
[0m21:39:38.028056 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:39:38.790166 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:39:39.013272 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 7 files added, 1 files changed.
[0m21:39:39.014272 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_fhv_tripdata.sql
[0m21:39:39.014272 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_taxi_zone_lookup.sql
[0m21:39:39.015272 [debug] [MainThread]: Partial parsing: added file: homework://models\core\fact_trips.sql
[0m21:39:39.015272 [debug] [MainThread]: Partial parsing: added file: homework://models\core\dim_zones.sql
[0m21:39:39.016271 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_yellow_tripdata.sql
[0m21:39:39.016271 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_green_tripdata.sql
[0m21:39:39.017272 [debug] [MainThread]: Partial parsing: added file: homework://models\overview.md
[0m21:39:39.018272 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m21:39:39.018272 [debug] [MainThread]: Partial parsing: deleted file: homework://models\example\my_first_dbt_model.sql
[0m21:39:39.315716 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:39:39.316717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'a0ec5686-f4fb-4867-87ae-2270c8e62d59', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024CC1326820>]}
[0m21:39:39.570380 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'my_first_dbt_model' in the 'models' section of file 'models\example\schema.yml'
[0m21:39:39.591311 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.my_second_dbt_model' (models\example\my_second_dbt_model.sql) depends on a node named 'my_first_dbt_model' which was not found
[0m21:39:39.594311 [debug] [MainThread]: Command `dbt run` failed at 21:39:39.593311 after 3.32 seconds
[0m21:39:39.594311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024CA47565B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024CC274BCA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024CC29C42B0>]}
[0m21:39:39.595311 [debug] [MainThread]: Flushing usage events
[0m21:39:39.612197 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:40:05.699639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A8BA17580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A8E63B610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A8E63B4C0>]}


============================== 21:40:05.703639 | 27964907-4031-4c05-9c7c-229195a08da8 ==============================
[0m21:40:05.703639 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:40:05.704639 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m21:40:07.211516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA851E0A0>]}
[0m21:40:07.330516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA852AC10>]}
[0m21:40:07.331593 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:40:08.113260 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:40:08.343194 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 7 files added, 1 files changed.
[0m21:40:08.345108 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_green_tripdata.sql
[0m21:40:08.345665 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_yellow_tripdata.sql
[0m21:40:08.345746 [debug] [MainThread]: Partial parsing: added file: homework://models\core\dim_zones.sql
[0m21:40:08.346345 [debug] [MainThread]: Partial parsing: added file: homework://models\core\fact_trips.sql
[0m21:40:08.346890 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_fhv_tripdata.sql
[0m21:40:08.347449 [debug] [MainThread]: Partial parsing: added file: homework://models\overview.md
[0m21:40:08.348010 [debug] [MainThread]: Partial parsing: added file: homework://models\staging\stg_taxi_zone_lookup.sql
[0m21:40:08.349070 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m21:40:08.349584 [debug] [MainThread]: Partial parsing: deleted file: homework://models\example\my_first_dbt_model.sql
[0m21:40:08.350161 [debug] [MainThread]: Partial parsing: deleted file: homework://models\example\my_second_dbt_model.sql
[0m21:40:08.632833 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:40:08.634794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA99F8E20>]}
[0m21:40:08.871848 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'my_first_dbt_model' in the 'models' section of file 'models\example\schema.yml'
[0m21:40:08.874848 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'my_second_dbt_model' in the 'models' section of file 'models\example\schema.yml'
[0m21:40:08.898851 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.homework.unique_my_first_dbt_model_id.16e066b321' (models\example\schema.yml) depends on a node named 'my_first_dbt_model' in package '' which was not found
[0m21:40:08.899850 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.homework.not_null_my_first_dbt_model_id.5fb22c2710' (models\example\schema.yml) depends on a node named 'my_first_dbt_model' in package '' which was not found
[0m21:40:08.900850 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.homework.unique_my_second_dbt_model_id.57a0f8c493' (models\example\schema.yml) depends on a node named 'my_second_dbt_model' in package '' which was not found
[0m21:40:08.901849 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.homework.not_null_my_second_dbt_model_id.151b76d778' (models\example\schema.yml) depends on a node named 'my_second_dbt_model' in package '' which was not found
[0m21:40:08.984847 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.homework.example
[0m21:40:08.997469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA9D90550>]}
[0m21:40:09.171497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA9D818E0>]}
[0m21:40:09.171497 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 424 macros
[0m21:40:09.172497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA9D81100>]}
[0m21:40:09.174498 [info ] [MainThread]: 
[0m21:40:09.175499 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m21:40:09.182498 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m21:40:09.183498 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:40:09.946146 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m21:40:09.946668 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m21:40:09.949348 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m21:40:09.949903 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m21:40:09.950541 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:40:14.398785 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m21:40:14.403230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA851B9D0>]}
[0m21:40:14.403787 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:40:14.404876 [info ] [MainThread]: 
[0m21:40:14.409047 [debug] [Thread-2  ]: Began running node model.homework.stg_fhv_tripdata
[0m21:40:14.410049 [info ] [Thread-2  ]: 1 of 6 START sql view model default.stg_fhv_tripdata ........................... [RUN]
[0m21:40:14.411050 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.stg_fhv_tripdata'
[0m21:40:14.412049 [debug] [Thread-2  ]: Began compiling node model.homework.stg_fhv_tripdata
[0m21:40:14.430049 [debug] [Thread-2  ]: Compilation Error in model stg_fhv_tripdata (models\staging\stg_fhv_tripdata.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m21:40:14.432049 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA9ED4040>]}
[0m21:40:14.434049 [error] [Thread-2  ]: 1 of 6 ERROR creating sql view model default.stg_fhv_tripdata .................. [[31mERROR[0m in 0.02s]
[0m21:40:14.435050 [debug] [Thread-2  ]: Finished running node model.homework.stg_fhv_tripdata
[0m21:40:14.436088 [debug] [Thread-2  ]: Began running node model.homework.stg_green_tripdata
[0m21:40:14.437049 [info ] [Thread-2  ]: 2 of 6 START sql view model default.stg_green_tripdata ......................... [RUN]
[0m21:40:14.438050 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_fhv_tripdata, now model.homework.stg_green_tripdata)
[0m21:40:14.439049 [debug] [Thread-2  ]: Began compiling node model.homework.stg_green_tripdata
[0m21:40:14.444048 [debug] [Thread-2  ]: Compilation Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m21:40:14.445048 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA9ECD8B0>]}
[0m21:40:14.446048 [error] [Thread-2  ]: 2 of 6 ERROR creating sql view model default.stg_green_tripdata ................ [[31mERROR[0m in 0.01s]
[0m21:40:14.447049 [debug] [Thread-2  ]: Finished running node model.homework.stg_green_tripdata
[0m21:40:14.448049 [debug] [Thread-2  ]: Began running node model.homework.stg_taxi_zone_lookup
[0m21:40:14.449052 [info ] [Thread-2  ]: 3 of 6 START sql view model default.stg_taxi_zone_lookup ....................... [RUN]
[0m21:40:14.450047 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_green_tripdata, now model.homework.stg_taxi_zone_lookup)
[0m21:40:14.450047 [debug] [Thread-2  ]: Began compiling node model.homework.stg_taxi_zone_lookup
[0m21:40:14.454050 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_taxi_zone_lookup"
[0m21:40:14.456055 [debug] [Thread-2  ]: Began executing node model.homework.stg_taxi_zone_lookup
[0m21:40:14.505593 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_taxi_zone_lookup"
[0m21:40:14.629737 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m21:40:14.629737 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    cast(locationid as integer) as locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`default`.`taxi_zone_lookup`);

[0m21:40:14.630736 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m21:40:15.705711 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130131: InstanceId: 20241202134017726g1zp2ggahcr4
ODPS-0130131:[9,6] Table not found - table dataengine_learning.`default`.taxi_zone_lookup cannot be resolved
ODPS-0130071:[5,24] Semantic analysis exception - class integer cannot be loaded from any resources
, retry times 0
[0m21:40:26.505773 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130131: InstanceId: 20241202134028593gef0g8hwsod
ODPS-0130131:[9,6] Table not found - table dataengine_learning.`default`.taxi_zone_lookup cannot be resolved
ODPS-0130071:[5,24] Semantic analysis exception - class integer cannot be loaded from any resources
, retry times 1
[0m21:40:37.303963 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    cast(locationid as integer) as locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`default`.`taxi_zone_lookup`);

[0m21:40:37.305078 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130131: InstanceId: 20241202134039363gms5l9kddlr
ODPS-0130131:[9,6] Table not found - table dataengine_learning.`default`.taxi_zone_lookup cannot be resolved
ODPS-0130071:[5,24] Semantic analysis exception - class integer cannot be loaded from any resources

[0m21:40:37.305919 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ROLLBACK
[0m21:40:37.316890 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_taxi_zone_lookup'
[0m21:40:37.316890 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: Close
[0m21:40:37.318890 [debug] [Thread-2  ]: Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130131: InstanceId: 20241202134039363gms5l9kddlr
  ODPS-0130131:[9,6] Table not found - table dataengine_learning.`default`.taxi_zone_lookup cannot be resolved
  ODPS-0130071:[5,24] Semantic analysis exception - class integer cannot be loaded from any resources
  
[0m21:40:37.319930 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA9ECD8E0>]}
[0m21:40:37.320915 [error] [Thread-2  ]: 3 of 6 ERROR creating sql view model default.stg_taxi_zone_lookup .............. [[31mERROR[0m in 22.87s]
[0m21:40:37.322889 [debug] [Thread-2  ]: Finished running node model.homework.stg_taxi_zone_lookup
[0m21:40:37.322889 [debug] [Thread-2  ]: Began running node model.homework.stg_yellow_tripdata
[0m21:40:37.323889 [info ] [Thread-2  ]: 4 of 6 START sql view model default.stg_yellow_tripdata ........................ [RUN]
[0m21:40:37.324888 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_taxi_zone_lookup, now model.homework.stg_yellow_tripdata)
[0m21:40:37.325892 [debug] [Thread-2  ]: Began compiling node model.homework.stg_yellow_tripdata
[0m21:40:37.331891 [debug] [Thread-2  ]: Compilation Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m21:40:37.332891 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27964907-4031-4c05-9c7c-229195a08da8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA9FA7190>]}
[0m21:40:37.333987 [error] [Thread-2  ]: 4 of 6 ERROR creating sql view model default.stg_yellow_tripdata ............... [[31mERROR[0m in 0.01s]
[0m21:40:37.334888 [debug] [Thread-2  ]: Finished running node model.homework.stg_yellow_tripdata
[0m21:40:37.335892 [debug] [Thread-2  ]: Began running node model.homework.dim_zones
[0m21:40:37.336888 [info ] [Thread-2  ]: 5 of 6 SKIP relation default.dim_zones ......................................... [[33mSKIP[0m]
[0m21:40:37.337891 [debug] [Thread-2  ]: Finished running node model.homework.dim_zones
[0m21:40:37.338889 [debug] [Thread-2  ]: Began running node model.homework.fact_trips
[0m21:40:37.339890 [info ] [Thread-2  ]: 6 of 6 SKIP relation default.fact_trips ........................................ [[33mSKIP[0m]
[0m21:40:37.340890 [debug] [Thread-2  ]: Finished running node model.homework.fact_trips
[0m21:40:37.344889 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:40:37.346890 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m21:40:37.347926 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m21:40:37.348925 [debug] [MainThread]: Connection 'model.homework.stg_yellow_tripdata' was properly closed.
[0m21:40:37.348925 [info ] [MainThread]: 
[0m21:40:37.349919 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 0 minutes and 28.17 seconds (28.17s).
[0m21:40:37.351888 [debug] [MainThread]: Command end result
[0m21:40:37.395891 [info ] [MainThread]: 
[0m21:40:37.396889 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m21:40:37.397889 [info ] [MainThread]: 
[0m21:40:37.398887 [error] [MainThread]:   Compilation Error in model stg_fhv_tripdata (models\staging\stg_fhv_tripdata.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m21:40:37.399888 [info ] [MainThread]: 
[0m21:40:37.400888 [error] [MainThread]:   Compilation Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m21:40:37.401888 [info ] [MainThread]: 
[0m21:40:37.402890 [error] [MainThread]:   Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130131: InstanceId: 20241202134039363gms5l9kddlr
  ODPS-0130131:[9,6] Table not found - table dataengine_learning.`default`.taxi_zone_lookup cannot be resolved
  ODPS-0130071:[5,24] Semantic analysis exception - class integer cannot be loaded from any resources
  
[0m21:40:37.404889 [info ] [MainThread]: 
[0m21:40:37.405891 [error] [MainThread]:   Compilation Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m21:40:37.406888 [info ] [MainThread]: 
[0m21:40:37.407891 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=2 TOTAL=6
[0m21:40:37.410890 [debug] [MainThread]: Command `dbt run` failed at 21:40:37.410890 after 31.78 seconds
[0m21:40:37.411888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A8BA17580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015AA9A7BA30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A8BF3ECD0>]}
[0m21:40:37.412888 [debug] [MainThread]: Flushing usage events
[0m21:40:37.433126 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:43:21.416613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C79C2275E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C79EE3A550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C79EE3A400>]}


============================== 21:43:21.420617 | 86c66b98-318d-4b9d-9ccd-b04b64805e06 ==============================
[0m21:43:21.420617 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:43:21.421613 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:43:21.662630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '86c66b98-318d-4b9d-9ccd-b04b64805e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C79EC714F0>]}
[0m21:43:21.688633 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m21:43:21.690589 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m21:43:21.692566 [debug] [MainThread]: Command `dbt deps` succeeded at 21:43:21.692566 after 0.34 seconds
[0m21:43:21.693566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C79C2275E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C79EF409A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C79EC433A0>]}
[0m21:43:21.693566 [debug] [MainThread]: Flushing usage events
[0m21:43:21.715265 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:44:14.916105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022DDD377520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022DDFF8C460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022DDFF8C370>]}


============================== 21:44:14.922109 | 25d78db9-e9e0-4c8f-84a2-ee86e6532ad6 ==============================
[0m21:44:14.922109 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:44:14.923107 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m21:44:15.198730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '25d78db9-e9e0-4c8f-84a2-ee86e6532ad6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022DDFF8C6D0>]}
[0m21:44:15.228728 [debug] [MainThread]: Set downloads directory='C:\Users\Êù∞Âì•Â∏¶~1\AppData\Local\Temp\dbt-downloads-7fgeoafe'
[0m21:44:15.229730 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:44:15.260734 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:44:15.261254 [debug] [MainThread]: Retrying external call. Attempt: 0 Max attempts: 5
[0m21:44:16.261431 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:44:16.275884 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:44:16.276402 [debug] [MainThread]: Retrying external call. Attempt: 1 Max attempts: 5
[0m21:44:17.286086 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:44:17.301235 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:44:17.301752 [debug] [MainThread]: Retrying external call. Attempt: 2 Max attempts: 5
[0m21:44:18.316574 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:44:18.344663 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:44:18.345182 [debug] [MainThread]: Retrying external call. Attempt: 3 Max attempts: 5
[0m21:44:19.359246 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:44:19.385676 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:44:19.385676 [debug] [MainThread]: Retrying external call. Attempt: 4 Max attempts: 5
[0m21:44:20.400354 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:44:20.416551 [error] [MainThread]: Encountered an error:
External connection exception occurred: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:44:20.437070 [error] [MainThread]: Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\cli\requires.py", line 201, in wrapper
    return func(*args, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\cli\requires.py", line 247, in wrapper
    return func(*args, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\cli\main.py", line 447, in deps
    results = task.run()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\task\deps.py", line 217, in run
    self.lock()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\task\deps.py", line 194, in lock
    resolved_deps = resolve_packages(packages, self.project, self.cli_vars)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\deps\resolver.py", line 128, in resolve_packages
    target = final[package].resolved().fetch_metadata(project, renderer)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\deps\registry.py", line 101, in resolved
    self._check_in_index()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\deps\registry.py", line 78, in _check_in_index
    index = registry.index_cached()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\utils.py", line 127, in __call__
    value = self.func(*args)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 187, in index
    return connection_exception_retry(get_index_fn, 5)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 34, in connection_exception_retry
    return connection_exception_retry(fn, max_attempts, attempt + 1)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 34, in connection_exception_retry
    return connection_exception_retry(fn, max_attempts, attempt + 1)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 34, in connection_exception_retry
    return connection_exception_retry(fn, max_attempts, attempt + 1)
  [Previous line repeated 2 more times]
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 36, in connection_exception_retry
    raise ConnectionError("External connection exception occurred: " + str(exc))
dbt_common.exceptions.connection.ConnectionError: External connection exception occurred: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

[0m21:44:20.485759 [debug] [MainThread]: Command `dbt deps` failed at 21:44:20.484754 after 5.63 seconds
[0m21:44:20.485759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022DDD377520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022DE013DF40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022DE013DF70>]}
[0m21:44:20.486757 [debug] [MainThread]: Flushing usage events
[0m21:44:20.504270 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:45:27.155141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001902C2C6550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001902EEDD4C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001902EEDD3D0>]}


============================== 21:45:27.160145 | 136bcc9f-8243-4da2-80a4-affcbcf1d4ed ==============================
[0m21:45:27.160145 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:45:27.161146 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:45:27.419912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '136bcc9f-8243-4da2-80a4-affcbcf1d4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001902ED6BCA0>]}
[0m21:45:27.448975 [debug] [MainThread]: Set downloads directory='C:\Users\Êù∞Âì•Â∏¶~1\AppData\Local\Temp\dbt-downloads-h72ncbx5'
[0m21:45:27.449536 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:27.466861 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:45:27.467373 [debug] [MainThread]: Retrying external call. Attempt: 0 Max attempts: 5
[0m21:45:28.468548 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:28.495033 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:45:28.495033 [debug] [MainThread]: Retrying external call. Attempt: 1 Max attempts: 5
[0m21:45:29.506718 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:29.520760 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:45:29.521349 [debug] [MainThread]: Retrying external call. Attempt: 2 Max attempts: 5
[0m21:45:30.529466 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:30.543165 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:45:30.543680 [debug] [MainThread]: Retrying external call. Attempt: 3 Max attempts: 5
[0m21:45:31.555537 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:31.568721 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:45:31.569239 [debug] [MainThread]: Retrying external call. Attempt: 4 Max attempts: 5
[0m21:45:32.573430 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:32.587453 [error] [MainThread]: Encountered an error:
External connection exception occurred: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:45:32.594485 [error] [MainThread]: Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 369, in connect
    self.sock = conn = self._connect_tls_proxy(hostname, conn)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connection.py", line 504, in _connect_tls_proxy
    socket = ssl_wrap_socket(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 453, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\ssl_.py", line 495, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock)
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1040, in _create
    self.do_handshake()
  File "F:\anaconda3\envs\tomato\lib\ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1122)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "F:\anaconda3\envs\tomato\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 21, in connection_exception_retry
    return fn()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 166, in _get_index
    resp = requests.get(url, timeout=30)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\requests\adapters.py", line 563, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\cli\requires.py", line 201, in wrapper
    return func(*args, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\cli\requires.py", line 247, in wrapper
    return func(*args, **kwargs)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\cli\main.py", line 447, in deps
    results = task.run()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\task\deps.py", line 217, in run
    self.lock()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\task\deps.py", line 194, in lock
    resolved_deps = resolve_packages(packages, self.project, self.cli_vars)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\deps\resolver.py", line 128, in resolve_packages
    target = final[package].resolved().fetch_metadata(project, renderer)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\deps\registry.py", line 101, in resolved
    self._check_in_index()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\deps\registry.py", line 78, in _check_in_index
    index = registry.index_cached()
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\utils.py", line 127, in __call__
    value = self.func(*args)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt\clients\registry.py", line 187, in index
    return connection_exception_retry(get_index_fn, 5)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 34, in connection_exception_retry
    return connection_exception_retry(fn, max_attempts, attempt + 1)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 34, in connection_exception_retry
    return connection_exception_retry(fn, max_attempts, attempt + 1)
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 34, in connection_exception_retry
    return connection_exception_retry(fn, max_attempts, attempt + 1)
  [Previous line repeated 2 more times]
  File "F:\anaconda3\envs\tomato\lib\site-packages\dbt_common\utils\connection.py", line 36, in connection_exception_retry
    raise ConnectionError("External connection exception occurred: " + str(exc))
dbt_common.exceptions.connection.ConnectionError: External connection exception occurred: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))

[0m21:45:32.644852 [debug] [MainThread]: Command `dbt deps` failed at 21:45:32.644852 after 5.56 seconds
[0m21:45:32.645888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001902C2C6550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001902F08DFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001902F08DFA0>]}
[0m21:45:32.646889 [debug] [MainThread]: Flushing usage events
[0m21:45:32.668382 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:45:44.944583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000213193B7580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002131BFCA4F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002131BFCA400>]}


============================== 21:45:44.948584 | ca53341c-8203-4e87-82a0-540925df5e1b ==============================
[0m21:45:44.948584 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:45:44.950400 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m21:45:45.233671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ca53341c-8203-4e87-82a0-540925df5e1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002131B9BD4C0>]}
[0m21:45:45.261621 [debug] [MainThread]: Set downloads directory='C:\Users\Êù∞Âì•Â∏¶~1\AppData\Local\Temp\dbt-downloads-oo_ujxj0'
[0m21:45:45.262658 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:45.283874 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:45:45.284822 [debug] [MainThread]: Retrying external call. Attempt: 0 Max attempts: 5
[0m21:45:46.301029 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:46.315220 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:45:46.315734 [debug] [MainThread]: Retrying external call. Attempt: 1 Max attempts: 5
[0m21:45:47.321107 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:47.334310 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:45:47.334824 [debug] [MainThread]: Retrying external call. Attempt: 2 Max attempts: 5
[0m21:45:48.343612 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:48.371170 [debug] [MainThread]: External call exception: HTTPSConnectionPool(host='hub.getdbt.com', port=443): Max retries exceeded with url: /api/v1/index.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1122)')))
[0m21:45:48.371688 [debug] [MainThread]: Retrying external call. Attempt: 3 Max attempts: 5
[0m21:45:49.381694 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:45:49.940040 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m21:45:49.946039 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m21:45:50.233091 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m21:45:50.250614 [info ] [MainThread]: Updating lock file in file path: E:\Á®ãÂ∫è\data-engineering-zoomcamp-main\04-analytics-engineering\homework/package-lock.yml
[0m21:45:50.254610 [debug] [MainThread]: Set downloads directory='C:\Users\Êù∞Âì•Â∏¶~1\AppData\Local\Temp\dbt-downloads-bv55z2sc'
[0m21:45:50.258696 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m21:45:51.906865 [info ] [MainThread]: Installed from version 1.1.1
[0m21:45:51.907866 [info ] [MainThread]: Updated version available: 1.3.0
[0m21:45:51.908866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'ca53341c-8203-4e87-82a0-540925df5e1b', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002131C127D00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021319D2B460>]}
[0m21:45:51.908866 [info ] [MainThread]: 
[0m21:45:51.909866 [info ] [MainThread]: Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
[0m21:45:51.912865 [debug] [MainThread]: Command `dbt deps` succeeded at 21:45:51.912865 after 7.04 seconds
[0m21:45:51.912865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000213193B7580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002131C05A1F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000213159D33D0>]}
[0m21:45:51.913866 [debug] [MainThread]: Flushing usage events
[0m21:49:25.630113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FBC9F6580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FBF61B5E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FBF61B4F0>]}


============================== 21:49:25.634114 | c70cacca-ec57-4737-a58a-14f59cce0a28 ==============================
[0m21:49:25.634114 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:49:25.635113 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --full-refresh', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:49:27.250754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FD9509700>]}
[0m21:49:27.377030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FBF3EA1F0>]}
[0m21:49:27.378030 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:49:28.130069 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:49:28.278082 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m21:49:28.280079 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:49:28.281079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FBEA2C9A0>]}
[0m21:49:29.850939 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:49:29.851981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FDAA772B0>]}
[0m21:49:30.204312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FDAD93C10>]}
[0m21:49:30.362955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FDACF3D00>]}
[0m21:49:30.362955 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 538 macros
[0m21:49:30.363993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FDAD58910>]}
[0m21:49:30.365954 [info ] [MainThread]: 
[0m21:49:30.367956 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m21:49:30.374955 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m21:49:30.375954 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:49:31.135943 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m21:49:31.136943 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m21:49:31.138941 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m21:49:31.139942 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m21:49:31.139942 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:49:35.031138 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m21:49:35.036138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FBF5D0400>]}
[0m21:49:35.036138 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:49:35.037138 [info ] [MainThread]: 
[0m21:49:35.041139 [debug] [Thread-2  ]: Began running node model.homework.stg_fhv_tripdata
[0m21:49:35.042140 [info ] [Thread-2  ]: 1 of 6 START sql view model default.stg_fhv_tripdata ........................... [RUN]
[0m21:49:35.043142 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.stg_fhv_tripdata'
[0m21:49:35.043142 [debug] [Thread-2  ]: Began compiling node model.homework.stg_fhv_tripdata
[0m21:49:35.058138 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_fhv_tripdata"
[0m21:49:35.060137 [debug] [Thread-2  ]: Began executing node model.homework.stg_fhv_tripdata
[0m21:49:35.169137 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_fhv_tripdata"
[0m21:49:35.268142 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m21:49:35.268142 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    dispatching_base_num,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as timestamp) as pickup_datetime,
    cast(dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as integer) as sr_flag,
    affiliated_base_number

from `dataengine_learning`.`max_dbt`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime) = 2019);

[0m21:49:35.269138 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m21:49:36.451243 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130131: InstanceId: 20241202134938373g4bok67wsod
ODPS-0130131:[26,6] Table not found - table dataengine_learning.max_dbt.fhv_taxi_trips_in cannot be resolved
ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources
, retry times 0
[0m21:49:47.299882 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130131: InstanceId: 20241202134949308go7y1na1f3k
ODPS-0130131:[26,6] Table not found - table dataengine_learning.max_dbt.fhv_taxi_trips_in cannot be resolved
ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources
, retry times 1
[0m21:49:58.314415 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    dispatching_base_num,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as timestamp) as pickup_datetime,
    cast(dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as integer) as sr_flag,
    affiliated_base_number

from `dataengine_learning`.`max_dbt`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime) = 2019);

[0m21:49:58.315414 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130131: InstanceId: 20241202135000161gdbwrjxrpks
ODPS-0130131:[26,6] Table not found - table dataengine_learning.max_dbt.fhv_taxi_trips_in cannot be resolved
ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources

[0m21:49:58.316453 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ROLLBACK
[0m21:49:58.322413 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_fhv_tripdata'
[0m21:49:58.323417 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: Close
[0m21:49:58.325417 [debug] [Thread-2  ]: Runtime Error in model stg_fhv_tripdata (models\staging\stg_fhv_tripdata.sql)
  ODPS-0130131: InstanceId: 20241202135000161gdbwrjxrpks
  ODPS-0130131:[26,6] Table not found - table dataengine_learning.max_dbt.fhv_taxi_trips_in cannot be resolved
  ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources
  
[0m21:49:58.327418 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FDAB0F910>]}
[0m21:49:58.328416 [error] [Thread-2  ]: 1 of 6 ERROR creating sql view model default.stg_fhv_tripdata .................. [[31mERROR[0m in 23.28s]
[0m21:49:58.329415 [debug] [Thread-2  ]: Finished running node model.homework.stg_fhv_tripdata
[0m21:49:58.330414 [debug] [Thread-2  ]: Began running node model.homework.stg_green_tripdata
[0m21:49:58.331414 [info ] [Thread-2  ]: 2 of 6 START sql view model default.stg_green_tripdata ......................... [RUN]
[0m21:49:58.331414 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_fhv_tripdata, now model.homework.stg_green_tripdata)
[0m21:49:58.332413 [debug] [Thread-2  ]: Began compiling node model.homework.stg_green_tripdata
[0m21:49:58.340416 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_green_tripdata"
[0m21:49:58.342416 [debug] [Thread-2  ]: Began executing node model.homework.stg_green_tripdata
[0m21:49:58.347416 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_green_tripdata"
[0m21:49:58.349416 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m21:49:58.349416 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(lpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount

from `dataengine_learning`.`max_dbt`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m21:49:58.350417 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m21:49:59.557783 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130131: InstanceId: 20241202135001454g5qp9aiwk22
ODPS-0130131:[32,6] Table not found - table dataengine_learning.max_dbt.green_taxi_trips_in cannot be resolved
ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources
, retry times 0
[0m21:50:10.507651 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130131: InstanceId: 20241202135012418glup9aiwk22
ODPS-0130131:[32,6] Table not found - table dataengine_learning.max_dbt.green_taxi_trips_in cannot be resolved
ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources
, retry times 1
[0m21:50:21.383863 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(lpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount

from `dataengine_learning`.`max_dbt`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m21:50:21.383863 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130131: InstanceId: 20241202135023387gyx6i09gtlq
ODPS-0130131:[32,6] Table not found - table dataengine_learning.max_dbt.green_taxi_trips_in cannot be resolved
ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources

[0m21:50:21.384863 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ROLLBACK
[0m21:50:21.386862 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_green_tripdata'
[0m21:50:21.387861 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: Close
[0m21:50:21.389864 [debug] [Thread-2  ]: Runtime Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  ODPS-0130131: InstanceId: 20241202135023387gyx6i09gtlq
  ODPS-0130131:[32,6] Table not found - table dataengine_learning.max_dbt.green_taxi_trips_in cannot be resolved
  ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources
  
[0m21:50:21.390865 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FDAC424C0>]}
[0m21:50:21.391865 [error] [Thread-2  ]: 2 of 6 ERROR creating sql view model default.stg_green_tripdata ................ [[31mERROR[0m in 23.06s]
[0m21:50:21.393902 [debug] [Thread-2  ]: Finished running node model.homework.stg_green_tripdata
[0m21:50:21.393902 [debug] [Thread-2  ]: Began running node model.homework.stg_taxi_zone_lookup
[0m21:50:21.394903 [info ] [Thread-2  ]: 3 of 6 START sql view model default.stg_taxi_zone_lookup ....................... [RUN]
[0m21:50:21.395863 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_green_tripdata, now model.homework.stg_taxi_zone_lookup)
[0m21:50:21.396863 [debug] [Thread-2  ]: Began compiling node model.homework.stg_taxi_zone_lookup
[0m21:50:21.399863 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_taxi_zone_lookup"
[0m21:50:21.401862 [debug] [Thread-2  ]: Began executing node model.homework.stg_taxi_zone_lookup
[0m21:50:21.406862 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_taxi_zone_lookup"
[0m21:50:21.407862 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m21:50:21.408862 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`max_dbt`.`taxi_zone_lookup`);

[0m21:50:21.408862 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m21:50:22.488332 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130131: InstanceId: 20241202135024547gghbznj0ozd
ODPS-0130131:[9,6] Table not found - table dataengine_learning.max_dbt.taxi_zone_lookup cannot be resolved
, retry times 0
[0m21:50:33.367891 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130131: InstanceId: 20241202135035394gvdz2pnuq
ODPS-0130131:[9,6] Table not found - table dataengine_learning.max_dbt.taxi_zone_lookup cannot be resolved
, retry times 1
[0m21:50:44.091926 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`max_dbt`.`taxi_zone_lookup`);

[0m21:50:44.091926 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130131: InstanceId: 20241202135046214gim12fopyz1
ODPS-0130131:[9,6] Table not found - table dataengine_learning.max_dbt.taxi_zone_lookup cannot be resolved

[0m21:50:44.092925 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ROLLBACK
[0m21:50:44.095975 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_taxi_zone_lookup'
[0m21:50:44.095975 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: Close
[0m21:50:44.098968 [debug] [Thread-2  ]: Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130131: InstanceId: 20241202135046214gim12fopyz1
  ODPS-0130131:[9,6] Table not found - table dataengine_learning.max_dbt.taxi_zone_lookup cannot be resolved
  
[0m21:50:44.098968 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FD95C7B20>]}
[0m21:50:44.099955 [error] [Thread-2  ]: 3 of 6 ERROR creating sql view model default.stg_taxi_zone_lookup .............. [[31mERROR[0m in 22.70s]
[0m21:50:44.101927 [debug] [Thread-2  ]: Finished running node model.homework.stg_taxi_zone_lookup
[0m21:50:44.102930 [debug] [Thread-2  ]: Began running node model.homework.stg_yellow_tripdata
[0m21:50:44.103928 [info ] [Thread-2  ]: 4 of 6 START sql view model default.stg_yellow_tripdata ........................ [RUN]
[0m21:50:44.104926 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_taxi_zone_lookup, now model.homework.stg_yellow_tripdata)
[0m21:50:44.105927 [debug] [Thread-2  ]: Began compiling node model.homework.stg_yellow_tripdata
[0m21:50:44.112928 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_yellow_tripdata"
[0m21:50:44.114927 [debug] [Thread-2  ]: Began executing node model.homework.stg_yellow_tripdata
[0m21:50:44.121932 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_yellow_tripdata"
[0m21:50:44.124926 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m21:50:44.124926 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Yellow' as service_type,

    -- Êó∂Èó¥Êà≥
    cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount
from `dataengine_learning`.`max_dbt`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m21:50:44.125927 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m21:50:44.567077 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Yellow' as service_type,

    -- Êó∂Èó¥Êà≥
    cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount
from `dataengine_learning`.`max_dbt`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m21:50:44.568110 [debug] [Thread-2  ]: MaxCompute adapter: ParseError: RequestId: 674DBB3713B92FCA34802396 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Yellow' as service_type,

    -- Êó∂Èó¥Êà≥
    cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount
from `dataengine_learning`.`max_dbt`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

ODPS-0130161:[5,9] Parse exception - invalid token 'then'
ODPS-0130161:[6,5] Parse exception - invalid token 'else'
ODPS-0130161:[7,12] Parse exception - invalid token '('
ODPS-0130161:[7,21] Parse exception - invalid token ')'
ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m21:50:44.569073 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ROLLBACK
[0m21:50:44.575074 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_yellow_tripdata'
[0m21:50:44.576072 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: Close
[0m21:50:44.578070 [debug] [Thread-2  ]: Runtime Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  ParseError: RequestId: 674DBB3713B92FCA34802396 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
  SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (
  
  select 
      -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
          then md5('')
      else
          md5(concat())
      endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
      case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
          then md5('')
      else
          md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
      end as tripid,
      cast(vendorid as integer) as vendor_id,
      'Yellow' as service_type,
  
      -- Êó∂Èó¥Êà≥
      cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
      cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
      
      -- Ë°åÁ®ã‰ø°ÊÅØ
      cast(passenger_count as integer) as passenger_count,
      cast(trip_distance as numeric) as trip_distance,
      cast(ratecodeid as integer) as ratecode_id,
      
      -- ‰ΩçÁΩÆ‰ø°ÊÅØ
      cast(pulocationid as integer) as pickup_locationid,
      cast(dolocationid as integer) as dropoff_locationid,
      
      -- ÊîØ‰ªò‰ø°ÊÅØ
      cast(payment_type as integer) as payment_type,
      cast(fare_amount as numeric) as fare_amount,
      cast(total_amount as numeric) as total_amount
  from `dataengine_learning`.`max_dbt`.`yellow_taxi_trips_in`
  where extract(year from tpep_pickup_datetime) in (2019, 2020));
  
  ODPS-0130161:[5,9] Parse exception - invalid token 'then'
  ODPS-0130161:[6,5] Parse exception - invalid token 'else'
  ODPS-0130161:[7,12] Parse exception - invalid token '('
  ODPS-0130161:[7,21] Parse exception - invalid token ')'
  ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m21:50:44.579070 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70cacca-ec57-4737-a58a-14f59cce0a28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FDA967070>]}
[0m21:50:44.580072 [error] [Thread-2  ]: 4 of 6 ERROR creating sql view model default.stg_yellow_tripdata ............... [[31mERROR[0m in 0.47s]
[0m21:50:44.581072 [debug] [Thread-2  ]: Finished running node model.homework.stg_yellow_tripdata
[0m21:50:44.582074 [debug] [Thread-2  ]: Began running node model.homework.dim_zones
[0m21:50:44.583074 [info ] [Thread-2  ]: 5 of 6 SKIP relation default.dim_zones ......................................... [[33mSKIP[0m]
[0m21:50:44.584072 [debug] [Thread-2  ]: Finished running node model.homework.dim_zones
[0m21:50:44.585071 [debug] [Thread-2  ]: Began running node model.homework.fact_trips
[0m21:50:44.585071 [info ] [Thread-2  ]: 6 of 6 SKIP relation default.fact_trips ........................................ [[33mSKIP[0m]
[0m21:50:44.587073 [debug] [Thread-2  ]: Finished running node model.homework.fact_trips
[0m21:50:44.589072 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:50:44.589072 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m21:50:44.590072 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m21:50:44.590072 [debug] [MainThread]: Connection 'model.homework.stg_yellow_tripdata' was properly closed.
[0m21:50:44.591071 [info ] [MainThread]: 
[0m21:50:44.591071 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 1 minutes and 14.22 seconds (74.22s).
[0m21:50:44.594073 [debug] [MainThread]: Command end result
[0m21:50:44.645072 [info ] [MainThread]: 
[0m21:50:44.646073 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m21:50:44.647072 [info ] [MainThread]: 
[0m21:50:44.647072 [error] [MainThread]:   Runtime Error in model stg_fhv_tripdata (models\staging\stg_fhv_tripdata.sql)
  ODPS-0130131: InstanceId: 20241202135000161gdbwrjxrpks
  ODPS-0130131:[26,6] Table not found - table dataengine_learning.max_dbt.fhv_taxi_trips_in cannot be resolved
  ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources
  
[0m21:50:44.649072 [info ] [MainThread]: 
[0m21:50:44.650072 [error] [MainThread]:   Runtime Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  ODPS-0130131: InstanceId: 20241202135023387gyx6i09gtlq
  ODPS-0130131:[32,6] Table not found - table dataengine_learning.max_dbt.green_taxi_trips_in cannot be resolved
  ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources
  
[0m21:50:44.653076 [info ] [MainThread]: 
[0m21:50:44.654077 [error] [MainThread]:   Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130131: InstanceId: 20241202135046214gim12fopyz1
  ODPS-0130131:[9,6] Table not found - table dataengine_learning.max_dbt.taxi_zone_lookup cannot be resolved
  
[0m21:50:44.655076 [info ] [MainThread]: 
[0m21:50:44.656074 [error] [MainThread]:   Runtime Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  ParseError: RequestId: 674DBB3713B92FCA34802396 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
  SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (
  
  select 
      -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
          then md5('')
      else
          md5(concat())
      endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
      case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
          then md5('')
      else
          md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
      end as tripid,
      cast(vendorid as integer) as vendor_id,
      'Yellow' as service_type,
  
      -- Êó∂Èó¥Êà≥
      cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
      cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
      
      -- Ë°åÁ®ã‰ø°ÊÅØ
      cast(passenger_count as integer) as passenger_count,
      cast(trip_distance as numeric) as trip_distance,
      cast(ratecodeid as integer) as ratecode_id,
      
      -- ‰ΩçÁΩÆ‰ø°ÊÅØ
      cast(pulocationid as integer) as pickup_locationid,
      cast(dolocationid as integer) as dropoff_locationid,
      
      -- ÊîØ‰ªò‰ø°ÊÅØ
      cast(payment_type as integer) as payment_type,
      cast(fare_amount as numeric) as fare_amount,
      cast(total_amount as numeric) as total_amount
  from `dataengine_learning`.`max_dbt`.`yellow_taxi_trips_in`
  where extract(year from tpep_pickup_datetime) in (2019, 2020));
  
  ODPS-0130161:[5,9] Parse exception - invalid token 'then'
  ODPS-0130161:[6,5] Parse exception - invalid token 'else'
  ODPS-0130161:[7,12] Parse exception - invalid token '('
  ODPS-0130161:[7,21] Parse exception - invalid token ')'
  ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m21:50:44.662072 [info ] [MainThread]: 
[0m21:50:44.663072 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=2 TOTAL=6
[0m21:50:44.664072 [debug] [MainThread]: Command `dbt run` failed at 21:50:44.664072 after 79.10 seconds
[0m21:50:44.665072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FBC9F6580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FDACF3D00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FBAB901C0>]}
[0m21:50:44.666071 [debug] [MainThread]: Flushing usage events
[0m21:51:01.778958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186357C6550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186383EC610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186383EC520>]}


============================== 21:51:01.781960 | e0d915c7-b5d3-43a3-b4eb-7561185a07eb ==============================
[0m21:51:01.781960 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:51:01.782960 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --full-refresh', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:51:03.331335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186522D9C10>]}
[0m21:51:03.453335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186522D3E20>]}
[0m21:51:03.454335 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:51:04.206747 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:51:04.482750 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:51:04.483751 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m21:51:04.811646 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:51:04.812645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001865381CD60>]}
[0m21:51:05.141646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018653BA5E80>]}
[0m21:51:05.297193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018653ACEF70>]}
[0m21:51:05.297193 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 538 macros
[0m21:51:05.298194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186537B52B0>]}
[0m21:51:05.300233 [info ] [MainThread]: 
[0m21:51:05.301195 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m21:51:05.307194 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m21:51:05.308194 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:51:06.003152 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m21:51:06.004151 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m21:51:06.007153 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m21:51:06.007153 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m21:51:06.008153 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:51:09.858442 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m21:51:09.862442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186522CB9A0>]}
[0m21:51:09.863441 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:51:09.864442 [info ] [MainThread]: 
[0m21:51:09.867441 [debug] [Thread-2  ]: Began running node model.homework.stg_fhv_tripdata
[0m21:51:09.867441 [info ] [Thread-2  ]: 1 of 6 START sql view model default.stg_fhv_tripdata ........................... [RUN]
[0m21:51:09.868441 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.stg_fhv_tripdata'
[0m21:51:09.869443 [debug] [Thread-2  ]: Began compiling node model.homework.stg_fhv_tripdata
[0m21:51:09.881480 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_fhv_tripdata"
[0m21:51:09.882441 [debug] [Thread-2  ]: Began executing node model.homework.stg_fhv_tripdata
[0m21:51:09.923441 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_fhv_tripdata"
[0m21:51:10.024456 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m21:51:10.024456 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    dispatching_base_num,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as timestamp) as pickup_datetime,
    cast(dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as integer) as sr_flag,
    affiliated_base_number

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime) = 2019);

[0m21:51:10.025495 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m21:51:11.274659 [error] [Thread-2  ]: MaxCompute adapter: http://logview.odps.aliyun.com/logview/?h=https://service.cn-hangzhou.maxcompute.aliyun.com/api&p=dataengine_learning&i=20241202135113135g9qz2pnuq&token=Si9vRjdGemJubnJoWTdYQStsWEdMMTVVdHhNPSxPRFBTX09CTzpwNF8yMDMyMzQxMzEyMjczOTkwNjAsMTczNTczOTQ3NCx7IlN0YXRlbWVudCI6W3siQWN0aW9uIjpbIm9kcHM6UmVhZCJdLCJFZmZlY3QiOiJBbGxvdyIsIlJlc291cmNlIjpbImFjczpvZHBzOio6cHJvamVjdHMvZGF0YWVuZ2luZV9sZWFybmluZy9pbnN0YW5jZXMvMjAyNDEyMDIxMzUxMTMxMzVnOXF6MnBudXEiXX1dLCJWZXJzaW9uIjoiMSJ9
[0m21:51:11.276660 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    dispatching_base_num,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as timestamp) as pickup_datetime,
    cast(dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as integer) as sr_flag,
    affiliated_base_number

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime) = 2019);

[0m21:51:11.276660 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130071: InstanceId: 20241202135113135g9qz2pnuq
ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources

[0m21:51:11.277656 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ROLLBACK
[0m21:51:11.283695 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_fhv_tripdata'
[0m21:51:11.283695 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: Close
[0m21:51:11.285656 [debug] [Thread-2  ]: Runtime Error in model stg_fhv_tripdata (models\staging\stg_fhv_tripdata.sql)
  ODPS-0130071: InstanceId: 20241202135113135g9qz2pnuq
  ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources
  
[0m21:51:11.287658 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018637F21340>]}
[0m21:51:11.288656 [error] [Thread-2  ]: 1 of 6 ERROR creating sql view model default.stg_fhv_tripdata .................. [[31mERROR[0m in 1.42s]
[0m21:51:11.289657 [debug] [Thread-2  ]: Finished running node model.homework.stg_fhv_tripdata
[0m21:51:11.290656 [debug] [Thread-2  ]: Began running node model.homework.stg_green_tripdata
[0m21:51:11.291658 [info ] [Thread-2  ]: 2 of 6 START sql view model default.stg_green_tripdata ......................... [RUN]
[0m21:51:11.292656 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_fhv_tripdata, now model.homework.stg_green_tripdata)
[0m21:51:11.292656 [debug] [Thread-2  ]: Began compiling node model.homework.stg_green_tripdata
[0m21:51:11.299656 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_green_tripdata"
[0m21:51:11.300695 [debug] [Thread-2  ]: Began executing node model.homework.stg_green_tripdata
[0m21:51:11.375860 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_green_tripdata"
[0m21:51:11.376898 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m21:51:11.377863 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(lpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount

from `dataengine_learning`.`default`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m21:51:11.378864 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m21:51:12.506969 [error] [Thread-2  ]: MaxCompute adapter: http://logview.odps.aliyun.com/logview/?h=https://service.cn-hangzhou.maxcompute.aliyun.com/api&p=dataengine_learning&i=20241202135114456gqejvkvh6kf&token=Mjc3bTJ3cWIzdUlWWDIvTjhyL1l4V3YzaFhNPSxPRFBTX09CTzpwNF8yMDMyMzQxMzEyMjczOTkwNjAsMTczNTczOTQ3NSx7IlN0YXRlbWVudCI6W3siQWN0aW9uIjpbIm9kcHM6UmVhZCJdLCJFZmZlY3QiOiJBbGxvdyIsIlJlc291cmNlIjpbImFjczpvZHBzOio6cHJvamVjdHMvZGF0YWVuZ2luZV9sZWFybmluZy9pbnN0YW5jZXMvMjAyNDEyMDIxMzUxMTQ0NTZncWVqdmt2aDZrZiJdfV0sIlZlcnNpb24iOiIxIn0=
[0m21:51:12.508961 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(lpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount

from `dataengine_learning`.`default`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m21:51:12.508961 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130071: InstanceId: 20241202135114456gqejvkvh6kf
ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources

[0m21:51:12.509961 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ROLLBACK
[0m21:51:12.513960 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_green_tripdata'
[0m21:51:12.514959 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: Close
[0m21:51:12.518965 [debug] [Thread-2  ]: Runtime Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  ODPS-0130071: InstanceId: 20241202135114456gqejvkvh6kf
  ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources
  
[0m21:51:12.519982 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186544AE310>]}
[0m21:51:12.520972 [error] [Thread-2  ]: 2 of 6 ERROR creating sql view model default.stg_green_tripdata ................ [[31mERROR[0m in 1.23s]
[0m21:51:12.522961 [debug] [Thread-2  ]: Finished running node model.homework.stg_green_tripdata
[0m21:51:12.522961 [debug] [Thread-2  ]: Began running node model.homework.stg_taxi_zone_lookup
[0m21:51:12.523961 [info ] [Thread-2  ]: 3 of 6 START sql view model default.stg_taxi_zone_lookup ....................... [RUN]
[0m21:51:12.524958 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_green_tripdata, now model.homework.stg_taxi_zone_lookup)
[0m21:51:12.525962 [debug] [Thread-2  ]: Began compiling node model.homework.stg_taxi_zone_lookup
[0m21:51:12.530965 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_taxi_zone_lookup"
[0m21:51:12.531963 [debug] [Thread-2  ]: Began executing node model.homework.stg_taxi_zone_lookup
[0m21:51:12.538960 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_taxi_zone_lookup"
[0m21:51:12.539961 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m21:51:12.540962 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`default`.`taxi_zone_lookup`);

[0m21:51:12.541961 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m21:51:13.587507 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130131: InstanceId: 20241202135115647grawkm1idlr
ODPS-0130131:[9,6] Table not found - table dataengine_learning.`default`.taxi_zone_lookup cannot be resolved
, retry times 0
[0m21:51:24.331307 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130131: InstanceId: 20241202135126445goehx09tjxh5
ODPS-0130131:[9,6] Table not found - table dataengine_learning.`default`.taxi_zone_lookup cannot be resolved
, retry times 1
[0m21:51:35.081613 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`default`.`taxi_zone_lookup`);

[0m21:51:35.082616 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130131: InstanceId: 20241202135137200gnaw2ggahcr4
ODPS-0130131:[9,6] Table not found - table dataengine_learning.`default`.taxi_zone_lookup cannot be resolved

[0m21:51:35.083615 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ROLLBACK
[0m21:51:35.085612 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_taxi_zone_lookup'
[0m21:51:35.086613 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: Close
[0m21:51:35.088612 [debug] [Thread-2  ]: Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130131: InstanceId: 20241202135137200gnaw2ggahcr4
  ODPS-0130131:[9,6] Table not found - table dataengine_learning.`default`.taxi_zone_lookup cannot be resolved
  
[0m21:51:35.088612 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186539F07F0>]}
[0m21:51:35.089613 [error] [Thread-2  ]: 3 of 6 ERROR creating sql view model default.stg_taxi_zone_lookup .............. [[31mERROR[0m in 22.56s]
[0m21:51:35.090612 [debug] [Thread-2  ]: Finished running node model.homework.stg_taxi_zone_lookup
[0m21:51:35.091648 [debug] [Thread-2  ]: Began running node model.homework.stg_yellow_tripdata
[0m21:51:35.092612 [info ] [Thread-2  ]: 4 of 6 START sql view model default.stg_yellow_tripdata ........................ [RUN]
[0m21:51:35.093612 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_taxi_zone_lookup, now model.homework.stg_yellow_tripdata)
[0m21:51:35.093612 [debug] [Thread-2  ]: Began compiling node model.homework.stg_yellow_tripdata
[0m21:51:35.101650 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_yellow_tripdata"
[0m21:51:35.102682 [debug] [Thread-2  ]: Began executing node model.homework.stg_yellow_tripdata
[0m21:51:35.108609 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_yellow_tripdata"
[0m21:51:35.110609 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m21:51:35.110609 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Yellow' as service_type,

    -- Êó∂Èó¥Êà≥
    cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m21:51:35.111612 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m21:51:35.570196 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Yellow' as service_type,

    -- Êó∂Èó¥Êà≥
    cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m21:51:35.571196 [debug] [Thread-2  ]: MaxCompute adapter: ParseError: RequestId: 674DBB6AEB21814C6D4808A3 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Yellow' as service_type,

    -- Êó∂Èó¥Êà≥
    cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

ODPS-0130161:[5,9] Parse exception - invalid token 'then'
ODPS-0130161:[6,5] Parse exception - invalid token 'else'
ODPS-0130161:[7,12] Parse exception - invalid token '('
ODPS-0130161:[7,21] Parse exception - invalid token ')'
ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m21:51:35.572196 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ROLLBACK
[0m21:51:35.576195 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_yellow_tripdata'
[0m21:51:35.577195 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: Close
[0m21:51:35.580197 [debug] [Thread-2  ]: Runtime Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  ParseError: RequestId: 674DBB6AEB21814C6D4808A3 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
  SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (
  
  select 
      -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
          then md5('')
      else
          md5(concat())
      endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
      case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
          then md5('')
      else
          md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
      end as tripid,
      cast(vendorid as integer) as vendor_id,
      'Yellow' as service_type,
  
      -- Êó∂Èó¥Êà≥
      cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
      cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
      
      -- Ë°åÁ®ã‰ø°ÊÅØ
      cast(passenger_count as integer) as passenger_count,
      cast(trip_distance as numeric) as trip_distance,
      cast(ratecodeid as integer) as ratecode_id,
      
      -- ‰ΩçÁΩÆ‰ø°ÊÅØ
      cast(pulocationid as integer) as pickup_locationid,
      cast(dolocationid as integer) as dropoff_locationid,
      
      -- ÊîØ‰ªò‰ø°ÊÅØ
      cast(payment_type as integer) as payment_type,
      cast(fare_amount as numeric) as fare_amount,
      cast(total_amount as numeric) as total_amount
  from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
  where extract(year from tpep_pickup_datetime) in (2019, 2020));
  
  ODPS-0130161:[5,9] Parse exception - invalid token 'then'
  ODPS-0130161:[6,5] Parse exception - invalid token 'else'
  ODPS-0130161:[7,12] Parse exception - invalid token '('
  ODPS-0130161:[7,21] Parse exception - invalid token ')'
  ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m21:51:35.581195 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e0d915c7-b5d3-43a3-b4eb-7561185a07eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001863612BE80>]}
[0m21:51:35.582197 [error] [Thread-2  ]: 4 of 6 ERROR creating sql view model default.stg_yellow_tripdata ............... [[31mERROR[0m in 0.49s]
[0m21:51:35.583192 [debug] [Thread-2  ]: Finished running node model.homework.stg_yellow_tripdata
[0m21:51:35.584192 [debug] [Thread-2  ]: Began running node model.homework.dim_zones
[0m21:51:35.585193 [info ] [Thread-2  ]: 5 of 6 SKIP relation default.dim_zones ......................................... [[33mSKIP[0m]
[0m21:51:35.587192 [debug] [Thread-2  ]: Finished running node model.homework.dim_zones
[0m21:51:35.588195 [debug] [Thread-2  ]: Began running node model.homework.fact_trips
[0m21:51:35.589191 [info ] [Thread-2  ]: 6 of 6 SKIP relation default.fact_trips ........................................ [[33mSKIP[0m]
[0m21:51:35.590192 [debug] [Thread-2  ]: Finished running node model.homework.fact_trips
[0m21:51:35.593195 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:51:35.593195 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m21:51:35.594195 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m21:51:35.594195 [debug] [MainThread]: Connection 'model.homework.stg_yellow_tripdata' was properly closed.
[0m21:51:35.595195 [info ] [MainThread]: 
[0m21:51:35.595195 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 0 minutes and 30.29 seconds (30.29s).
[0m21:51:35.597192 [debug] [MainThread]: Command end result
[0m21:51:35.653575 [info ] [MainThread]: 
[0m21:51:35.654575 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m21:51:35.655575 [info ] [MainThread]: 
[0m21:51:35.656575 [error] [MainThread]:   Runtime Error in model stg_fhv_tripdata (models\staging\stg_fhv_tripdata.sql)
  ODPS-0130071: InstanceId: 20241202135113135g9qz2pnuq
  ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources
  
[0m21:51:35.659288 [info ] [MainThread]: 
[0m21:51:35.659822 [error] [MainThread]:   Runtime Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  ODPS-0130071: InstanceId: 20241202135114456gqejvkvh6kf
  ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources
  
[0m21:51:35.663547 [info ] [MainThread]: 
[0m21:51:35.664100 [error] [MainThread]:   Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130131: InstanceId: 20241202135137200gnaw2ggahcr4
  ODPS-0130131:[9,6] Table not found - table dataengine_learning.`default`.taxi_zone_lookup cannot be resolved
  
[0m21:51:35.665206 [info ] [MainThread]: 
[0m21:51:35.665725 [error] [MainThread]:   Runtime Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  ParseError: RequestId: 674DBB6AEB21814C6D4808A3 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
  SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (
  
  select 
      -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
          then md5('')
      else
          md5(concat())
      endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
      case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
          then md5('')
      else
          md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
      end as tripid,
      cast(vendorid as integer) as vendor_id,
      'Yellow' as service_type,
  
      -- Êó∂Èó¥Êà≥
      cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
      cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
      
      -- Ë°åÁ®ã‰ø°ÊÅØ
      cast(passenger_count as integer) as passenger_count,
      cast(trip_distance as numeric) as trip_distance,
      cast(ratecodeid as integer) as ratecode_id,
      
      -- ‰ΩçÁΩÆ‰ø°ÊÅØ
      cast(pulocationid as integer) as pickup_locationid,
      cast(dolocationid as integer) as dropoff_locationid,
      
      -- ÊîØ‰ªò‰ø°ÊÅØ
      cast(payment_type as integer) as payment_type,
      cast(fare_amount as numeric) as fare_amount,
      cast(total_amount as numeric) as total_amount
  from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
  where extract(year from tpep_pickup_datetime) in (2019, 2020));
  
  ODPS-0130161:[5,9] Parse exception - invalid token 'then'
  ODPS-0130161:[6,5] Parse exception - invalid token 'else'
  ODPS-0130161:[7,12] Parse exception - invalid token '('
  ODPS-0130161:[7,21] Parse exception - invalid token ')'
  ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m21:51:35.671723 [info ] [MainThread]: 
[0m21:51:35.672727 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=2 TOTAL=6
[0m21:51:35.674752 [debug] [MainThread]: Command `dbt run` failed at 21:51:35.674752 after 33.96 seconds
[0m21:51:35.675721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186357C6550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018653BF41F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018653BF4040>]}
[0m21:51:35.675721 [debug] [MainThread]: Flushing usage events
[0m21:54:02.782834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BEA3F77550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BEA6B9B610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BEA6B9B520>]}


============================== 21:54:02.787833 | af2cc2e9-800e-4e38-935c-fb7de4b72e4b ==============================
[0m21:54:02.787833 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:54:02.788839 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --full-refresh', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:54:04.387827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'af2cc2e9-800e-4e38-935c-fb7de4b72e4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BEC0A89C10>]}
[0m21:54:04.512827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'af2cc2e9-800e-4e38-935c-fb7de4b72e4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BEC0A83E20>]}
[0m21:54:04.513831 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:54:05.265085 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:54:05.521637 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:54:05.522713 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_taxi_zone_lookup.sql
[0m21:54:05.792457 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:54:05.793457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'af2cc2e9-800e-4e38-935c-fb7de4b72e4b', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BEC1FD53D0>]}
[0m21:54:05.910457 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.stg_taxi_zone_lookup' (models\staging\stg_taxi_zone_lookup.sql) depends on a source named 'nyc_taxi.taxi_zone_lookup_in' which was not found
[0m21:54:05.912458 [debug] [MainThread]: Command `dbt run` failed at 21:54:05.912458 after 3.20 seconds
[0m21:54:05.913458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BEA3F77550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BEC1FB6D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BEC2125580>]}
[0m21:54:05.913458 [debug] [MainThread]: Flushing usage events
[0m21:54:51.283398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214594C7520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002145C0DB550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002145C0DB460>]}


============================== 21:54:51.287399 | 33f61d79-2c10-4ce4-8fbd-6106266e5b1d ==============================
[0m21:54:51.287399 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:54:51.288400 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --full-refresh', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:54:52.826588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '33f61d79-2c10-4ce4-8fbd-6106266e5b1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021475FD9610>]}
[0m21:54:52.954678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '33f61d79-2c10-4ce4-8fbd-6106266e5b1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021476042EE0>]}
[0m21:54:52.956678 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:54:53.710585 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:54:53.969377 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:54:53.970514 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_taxi_zone_lookup.sql
[0m21:54:54.233414 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:54:54.234445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '33f61d79-2c10-4ce4-8fbd-6106266e5b1d', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214775D0160>]}
[0m21:54:54.350487 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.stg_taxi_zone_lookup' (models\staging\stg_taxi_zone_lookup.sql) depends on a source named 'nyc_taxi.taxi_zone_lookup_in' which was not found
[0m21:54:54.353450 [debug] [MainThread]: Command `dbt run` failed at 21:54:54.353450 after 3.13 seconds
[0m21:54:54.354450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214594C7520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021477506D60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021477675550>]}
[0m21:54:54.354450 [debug] [MainThread]: Flushing usage events
[0m21:55:27.907759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D14406520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D1702B550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D1702B460>]}


============================== 21:55:27.911759 | c1fe2db4-9b72-4551-81ee-cd3aca510bd0 ==============================
[0m21:55:27.911759 [info ] [MainThread]: Running with dbt=1.8.9
[0m21:55:27.913760 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:55:29.511781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c1fe2db4-9b72-4551-81ee-cd3aca510bd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D30F19610>]}
[0m21:55:29.643966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c1fe2db4-9b72-4551-81ee-cd3aca510bd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D30F82EE0>]}
[0m21:55:29.644966 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m21:55:30.387527 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m21:55:30.669740 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:55:30.670737 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_taxi_zone_lookup.sql
[0m21:55:30.917004 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m21:55:30.918001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'c1fe2db4-9b72-4551-81ee-cd3aca510bd0', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D32510160>]}
[0m21:55:31.044040 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.stg_taxi_zone_lookup' (models\staging\stg_taxi_zone_lookup.sql) depends on a source named 'dataengine_learning.taxi_zone_lookup_in' which was not found
[0m21:55:31.047001 [debug] [MainThread]: Command `dbt run` failed at 21:55:31.046031 after 3.21 seconds
[0m21:55:31.047001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D14406520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D32446D60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D325B5550>]}
[0m21:55:31.048001 [debug] [MainThread]: Flushing usage events
[0m22:12:15.649256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC527764F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC5539B5B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC5539B4C0>]}


============================== 22:12:15.654257 | ca4c9f27-2575-4d44-be5b-f6a9f581d573 ==============================
[0m22:12:15.654257 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:12:15.656256 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:12:17.248946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ca4c9f27-2575-4d44-be5b-f6a9f581d573', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC53111130>]}
[0m22:12:17.368843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ca4c9f27-2575-4d44-be5b-f6a9f581d573', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC54CA32B0>]}
[0m22:12:17.370824 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:12:18.140695 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m22:12:18.414129 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:12:18.415129 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_taxi_zone_lookup.sql
[0m22:12:18.682862 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m22:12:18.684861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'ca4c9f27-2575-4d44-be5b-f6a9f581d573', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC6F3789A0>]}
[0m22:12:18.810019 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.stg_taxi_zone_lookup' (models\staging\stg_taxi_zone_lookup.sql) depends on a source named 'nyc_taxi.taxi_zone_lookup_in' which was not found
[0m22:12:18.813017 [debug] [MainThread]: Command `dbt run` failed at 22:12:18.813017 after 3.24 seconds
[0m22:12:18.815021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC527764F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC707B6D30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AC70925520>]}
[0m22:12:18.816048 [debug] [MainThread]: Flushing usage events
[0m22:15:03.318646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002183D3064F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002183FF1D400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002183FF1D310>]}


============================== 22:15:03.321645 | 4996fc7b-8bef-453a-bc2e-10ae0f81b049 ==============================
[0m22:15:03.321645 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:15:03.323645 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:15:03.359678 [info ] [MainThread]: dbt version: 1.8.9
[0m22:15:03.361681 [info ] [MainThread]: python version: 3.9.0
[0m22:15:03.362677 [info ] [MainThread]: python path: F:\anaconda3\envs\tomato\python.exe
[0m22:15:03.363717 [info ] [MainThread]: os info: Windows-10-10.0.19041-SP0
[0m22:15:04.862230 [info ] [MainThread]: Using profiles dir at C:\Users\Êù∞Âì•Â∏¶Â∏ÖÊØî\.dbt
[0m22:15:04.864229 [info ] [MainThread]: Using profiles.yml file at C:\Users\Êù∞Âì•Â∏¶Â∏ÖÊØî\.dbt\profiles.yml
[0m22:15:04.865226 [info ] [MainThread]: Using dbt_project.yml file at E:\Á®ãÂ∫è\data-engineering-zoomcamp-main\04-analytics-engineering\homework\dbt_project.yml
[0m22:15:04.866257 [info ] [MainThread]: adapter type: maxcompute
[0m22:15:04.867225 [info ] [MainThread]: adapter version: 1.8.0-alpha8
[0m22:15:04.993592 [info ] [MainThread]: Configuration:
[0m22:15:04.994593 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m22:15:04.995593 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m22:15:04.996592 [info ] [MainThread]: Required dependencies:
[0m22:15:04.997592 [debug] [MainThread]: Executing "git --help"
[0m22:15:05.106993 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m22:15:05.108002 [debug] [MainThread]: STDERR: "b''"
[0m22:15:05.108002 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m22:15:05.110013 [info ] [MainThread]: Connection:
[0m22:15:05.110994 [info ] [MainThread]:   project: dataengine_learning
[0m22:15:05.111991 [info ] [MainThread]:   database: dataengine_learning
[0m22:15:05.113026 [info ] [MainThread]:   schema: default
[0m22:15:05.113993 [info ] [MainThread]:   endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
[0m22:15:05.114994 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:15:05.907598 [debug] [MainThread]: Acquiring new maxcompute connection 'debug'
[0m22:15:06.067631 [debug] [MainThread]: Using maxcompute connection "debug"
[0m22:15:06.067631 [debug] [MainThread]: On debug: select 1 as id
[0m22:15:06.068572 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:15:08.974141 [debug] [MainThread]: MaxCompute adapter: Current instance id is 20241202141506754g7ukvdgq63k
[0m22:15:08.974659 [debug] [MainThread]: SQL status: OK in 2.906 seconds
[0m22:15:08.975177 [debug] [MainThread]: MaxCompute adapter: Current instance id is 20241202141506754g7ukvdgq63k
[0m22:15:08.976206 [debug] [MainThread]: On debug: Close
[0m22:15:08.976723 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m22:15:08.977759 [info ] [MainThread]: [32mAll checks passed![0m
[0m22:15:08.979784 [debug] [MainThread]: Command `dbt debug` succeeded at 22:15:08.979279 after 5.73 seconds
[0m22:15:08.979799 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m22:15:08.980322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002183D3064F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002183F35C550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021859E92DC0>]}
[0m22:15:08.980873 [debug] [MainThread]: Flushing usage events
[0m22:16:08.876400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002471F4F75E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002472211B670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002472211B580>]}


============================== 22:16:08.881402 | 88d81425-5382-4d56-8df5-dc6ea7457166 ==============================
[0m22:16:08.881402 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:16:08.882398 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:16:10.437839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '88d81425-5382-4d56-8df5-dc6ea7457166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002471FEA7C40>]}
[0m22:16:10.563838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '88d81425-5382-4d56-8df5-dc6ea7457166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000247214F6070>]}
[0m22:16:10.565841 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:16:11.328124 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m22:16:11.585169 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 1 files changed.
[0m22:16:11.586167 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_taxi_zone_lookup.sql
[0m22:16:11.841823 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m22:16:11.842824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '88d81425-5382-4d56-8df5-dc6ea7457166', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002473C0C8FD0>]}
[0m22:16:12.004335 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.stg_taxi_zone_lookup' (models\staging\stg_taxi_zone_lookup.sql) depends on a source named 'nyc_taxi.taxi_zone_lookup_in' which was not found
[0m22:16:12.007334 [debug] [MainThread]: Command `dbt run` failed at 22:16:12.006335 after 3.20 seconds
[0m22:16:12.007334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002471F4F75E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002473D536CA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002473D6A5490>]}
[0m22:16:12.008333 [debug] [MainThread]: Flushing usage events
[0m22:17:56.882101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CEFEE16520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE81B7B550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE81B7B460>]}


============================== 22:17:56.886100 | 62e69df0-7216-4908-b08e-dbb6b8d599d9 ==============================
[0m22:17:56.886100 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:17:56.887101 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m22:17:58.563120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9B929610>]}
[0m22:17:58.680199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9B992EE0>]}
[0m22:17:58.681143 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:17:59.464834 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m22:17:59.735833 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 2 files changed.
[0m22:17:59.736831 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\schema.yml
[0m22:17:59.737832 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_taxi_zone_lookup.sql
[0m22:18:00.120921 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m22:18:00.121918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9B96CF70>]}
[0m22:18:00.851878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9D1F3FA0>]}
[0m22:18:01.067969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9D18B940>]}
[0m22:18:01.068968 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 538 macros
[0m22:18:01.069968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9CE31220>]}
[0m22:18:01.071968 [info ] [MainThread]: 
[0m22:18:01.072968 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m22:18:01.079968 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m22:18:01.080968 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:18:01.772723 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m22:18:01.773817 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m22:18:01.775998 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m22:18:01.776589 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m22:18:01.777116 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:18:05.630547 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m22:18:05.634956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9B91B9A0>]}
[0m22:18:05.636099 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:18:05.636679 [info ] [MainThread]: 
[0m22:18:05.640950 [debug] [Thread-2  ]: Began running node model.homework.stg_fhv_tripdata
[0m22:18:05.641991 [info ] [Thread-2  ]: 1 of 6 START sql view model default.stg_fhv_tripdata ........................... [RUN]
[0m22:18:05.642949 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.stg_fhv_tripdata'
[0m22:18:05.642949 [debug] [Thread-2  ]: Began compiling node model.homework.stg_fhv_tripdata
[0m22:18:05.656948 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_fhv_tripdata"
[0m22:18:05.658950 [debug] [Thread-2  ]: Began executing node model.homework.stg_fhv_tripdata
[0m22:18:05.705962 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_fhv_tripdata"
[0m22:18:05.804246 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:18:05.805247 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    dispatching_base_num,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as timestamp) as pickup_datetime,
    cast(dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as integer) as sr_flag,
    affiliated_base_number

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime) = 2019);

[0m22:18:05.806247 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m22:18:07.006504 [error] [Thread-2  ]: MaxCompute adapter: http://logview.odps.aliyun.com/logview/?h=https://service.cn-hangzhou.maxcompute.aliyun.com/api&p=dataengine_learning&i=20241202141806160gzw1ytc4z8g&token=SGx6bS8wN1NYR0MycXQzNk81SnhJSkhCdUdzPSxPRFBTX09CTzpwNF8yMDMyMzQxMzEyMjczOTkwNjAsMTczNTc0MTA4Nyx7IlN0YXRlbWVudCI6W3siQWN0aW9uIjpbIm9kcHM6UmVhZCJdLCJFZmZlY3QiOiJBbGxvdyIsIlJlc291cmNlIjpbImFjczpvZHBzOio6cHJvamVjdHMvZGF0YWVuZ2luZV9sZWFybmluZy9pbnN0YW5jZXMvMjAyNDEyMDIxNDE4MDYxNjBnencxeXRjNHo4ZyJdfV0sIlZlcnNpb24iOiIxIn0=
[0m22:18:07.009114 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    dispatching_base_num,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as timestamp) as pickup_datetime,
    cast(dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as integer) as sr_flag,
    affiliated_base_number

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime) = 2019);

[0m22:18:07.009649 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130071: InstanceId: 20241202141806160gzw1ytc4z8g
ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources

[0m22:18:07.010173 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ROLLBACK
[0m22:18:07.015979 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_fhv_tripdata'
[0m22:18:07.016512 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: Close
[0m22:18:07.018611 [debug] [Thread-2  ]: Runtime Error in model stg_fhv_tripdata (models\staging\stg_fhv_tripdata.sql)
  ODPS-0130071: InstanceId: 20241202141806160gzw1ytc4z8g
  ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources
  
[0m22:18:07.020576 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE815469A0>]}
[0m22:18:07.021576 [error] [Thread-2  ]: 1 of 6 ERROR creating sql view model default.stg_fhv_tripdata .................. [[31mERROR[0m in 1.38s]
[0m22:18:07.023578 [debug] [Thread-2  ]: Finished running node model.homework.stg_fhv_tripdata
[0m22:18:07.023578 [debug] [Thread-2  ]: Began running node model.homework.stg_green_tripdata
[0m22:18:07.024576 [info ] [Thread-2  ]: 2 of 6 START sql view model default.stg_green_tripdata ......................... [RUN]
[0m22:18:07.025577 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_fhv_tripdata, now model.homework.stg_green_tripdata)
[0m22:18:07.026578 [debug] [Thread-2  ]: Began compiling node model.homework.stg_green_tripdata
[0m22:18:07.033614 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_green_tripdata"
[0m22:18:07.034612 [debug] [Thread-2  ]: Began executing node model.homework.stg_green_tripdata
[0m22:18:07.113280 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_green_tripdata"
[0m22:18:07.115267 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:18:07.116291 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(lpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount

from `dataengine_learning`.`default`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m22:18:07.116291 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:18:08.341109 [error] [Thread-2  ]: MaxCompute adapter: http://logview.odps.aliyun.com/logview/?h=https://service.cn-hangzhou.maxcompute.aliyun.com/api&p=dataengine_learning&i=20241202141807485gl3d0j7pgtb&token=QTlib01jaHdkMC8rc3NqdVBZYjV5TjZRSzUwPSxPRFBTX09CTzpwNF8yMDMyMzQxMzEyMjczOTkwNjAsMTczNTc0MTA4OCx7IlN0YXRlbWVudCI6W3siQWN0aW9uIjpbIm9kcHM6UmVhZCJdLCJFZmZlY3QiOiJBbGxvdyIsIlJlc291cmNlIjpbImFjczpvZHBzOio6cHJvamVjdHMvZGF0YWVuZ2luZV9sZWFybmluZy9pbnN0YW5jZXMvMjAyNDEyMDIxNDE4MDc0ODVnbDNkMGo3cGd0YiJdfV0sIlZlcnNpb24iOiIxIn0=
[0m22:18:08.343797 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(lpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount

from `dataengine_learning`.`default`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m22:18:08.344855 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130071: InstanceId: 20241202141807485gl3d0j7pgtb
ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources

[0m22:18:08.345908 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ROLLBACK
[0m22:18:08.348449 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_green_tripdata'
[0m22:18:08.348974 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: Close
[0m22:18:08.351440 [debug] [Thread-2  ]: Runtime Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  ODPS-0130071: InstanceId: 20241202141807485gl3d0j7pgtb
  ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources
  
[0m22:18:08.352082 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE815991C0>]}
[0m22:18:08.352254 [error] [Thread-2  ]: 2 of 6 ERROR creating sql view model default.stg_green_tripdata ................ [[31mERROR[0m in 1.33s]
[0m22:18:08.353429 [debug] [Thread-2  ]: Finished running node model.homework.stg_green_tripdata
[0m22:18:08.354334 [debug] [Thread-2  ]: Began running node model.homework.stg_taxi_zone_lookup
[0m22:18:08.355334 [info ] [Thread-2  ]: 3 of 6 START sql view model default.stg_taxi_zone_lookup ....................... [RUN]
[0m22:18:08.356331 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_green_tripdata, now model.homework.stg_taxi_zone_lookup)
[0m22:18:08.357332 [debug] [Thread-2  ]: Began compiling node model.homework.stg_taxi_zone_lookup
[0m22:18:08.361331 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_taxi_zone_lookup"
[0m22:18:08.362331 [debug] [Thread-2  ]: Began executing node model.homework.stg_taxi_zone_lookup
[0m22:18:08.367330 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_taxi_zone_lookup"
[0m22:18:08.368331 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:18:08.369331 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`default`.`taxi_zone_lookup_in`);

[0m22:18:08.369331 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:18:09.750728 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202141808727gq0ttmbgtlq
[0m22:18:09.751805 [debug] [Thread-2  ]: SQL status: OK in 1.382 seconds
[0m22:18:09.752314 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202141808727gq0ttmbgtlq
[0m22:18:09.930058 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:18:09.930626 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup__dbt_tmp
            RENAME TO stg_taxi_zone_lookup;
        
[0m22:18:11.084255 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214181051g5ex00ei4gg
[0m22:18:11.084836 [debug] [Thread-2  ]: SQL status: OK in 1.154 seconds
[0m22:18:11.085420 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214181051g5ex00ei4gg
[0m22:18:11.102934 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: COMMIT
[0m22:18:11.812256 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: Close
[0m22:18:11.813322 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9D12AF70>]}
[0m22:18:11.813853 [info ] [Thread-2  ]: 3 of 6 OK created sql view model default.stg_taxi_zone_lookup .................. [[32mOK[0m in 3.46s]
[0m22:18:11.815492 [debug] [Thread-2  ]: Finished running node model.homework.stg_taxi_zone_lookup
[0m22:18:11.816106 [debug] [Thread-2  ]: Began running node model.homework.stg_yellow_tripdata
[0m22:18:11.816665 [info ] [Thread-2  ]: 4 of 6 START sql view model default.stg_yellow_tripdata ........................ [RUN]
[0m22:18:11.817698 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_taxi_zone_lookup, now model.homework.stg_yellow_tripdata)
[0m22:18:11.818264 [debug] [Thread-2  ]: Began compiling node model.homework.stg_yellow_tripdata
[0m22:18:11.829525 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_yellow_tripdata"
[0m22:18:11.831527 [debug] [Thread-2  ]: Began executing node model.homework.stg_yellow_tripdata
[0m22:18:11.836526 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_yellow_tripdata"
[0m22:18:11.837526 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:18:11.838525 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Yellow' as service_type,

    -- Êó∂Èó¥Êà≥
    cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m22:18:11.839526 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:18:12.279077 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Yellow' as service_type,

    -- Êó∂Èó¥Êà≥
    cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m22:18:12.280155 [debug] [Thread-2  ]: MaxCompute adapter: ParseError: RequestId: 674DC1A4D39357D85C0B9057 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as integer) as vendor_id,
    'Yellow' as service_type,

    -- Êó∂Èó¥Êà≥
    cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
    cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
    
    -- Ë°åÁ®ã‰ø°ÊÅØ
    cast(passenger_count as integer) as passenger_count,
    cast(trip_distance as numeric) as trip_distance,
    cast(ratecodeid as integer) as ratecode_id,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as integer) as pickup_locationid,
    cast(dolocationid as integer) as dropoff_locationid,
    
    -- ÊîØ‰ªò‰ø°ÊÅØ
    cast(payment_type as integer) as payment_type,
    cast(fare_amount as numeric) as fare_amount,
    cast(total_amount as numeric) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

ODPS-0130161:[5,9] Parse exception - invalid token 'then'
ODPS-0130161:[6,5] Parse exception - invalid token 'else'
ODPS-0130161:[7,12] Parse exception - invalid token '('
ODPS-0130161:[7,21] Parse exception - invalid token ')'
ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m22:18:12.281241 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ROLLBACK
[0m22:18:12.286951 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_yellow_tripdata'
[0m22:18:12.288121 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: Close
[0m22:18:12.290745 [debug] [Thread-2  ]: Runtime Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  ParseError: RequestId: 674DC1A4D39357D85C0B9057 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
  SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (
  
  select 
      -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
          then md5('')
      else
          md5(concat())
      endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
      case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
          then md5('')
      else
          md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
      end as tripid,
      cast(vendorid as integer) as vendor_id,
      'Yellow' as service_type,
  
      -- Êó∂Èó¥Êà≥
      cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
      cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
      
      -- Ë°åÁ®ã‰ø°ÊÅØ
      cast(passenger_count as integer) as passenger_count,
      cast(trip_distance as numeric) as trip_distance,
      cast(ratecodeid as integer) as ratecode_id,
      
      -- ‰ΩçÁΩÆ‰ø°ÊÅØ
      cast(pulocationid as integer) as pickup_locationid,
      cast(dolocationid as integer) as dropoff_locationid,
      
      -- ÊîØ‰ªò‰ø°ÊÅØ
      cast(payment_type as integer) as payment_type,
      cast(fare_amount as numeric) as fare_amount,
      cast(total_amount as numeric) as total_amount
  from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
  where extract(year from tpep_pickup_datetime) in (2019, 2020));
  
  ODPS-0130161:[5,9] Parse exception - invalid token 'then'
  ODPS-0130161:[6,5] Parse exception - invalid token 'else'
  ODPS-0130161:[7,12] Parse exception - invalid token '('
  ODPS-0130161:[7,21] Parse exception - invalid token ')'
  ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m22:18:12.292742 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE81599340>]}
[0m22:18:12.293743 [error] [Thread-2  ]: 4 of 6 ERROR creating sql view model default.stg_yellow_tripdata ............... [[31mERROR[0m in 0.47s]
[0m22:18:12.294742 [debug] [Thread-2  ]: Finished running node model.homework.stg_yellow_tripdata
[0m22:18:12.295742 [debug] [Thread-2  ]: Began running node model.homework.dim_zones
[0m22:18:12.297744 [info ] [Thread-2  ]: 5 of 6 START sql table model default.dim_zones ................................. [RUN]
[0m22:18:12.300743 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_yellow_tripdata, now model.homework.dim_zones)
[0m22:18:12.303083 [debug] [Thread-2  ]: Began compiling node model.homework.dim_zones
[0m22:18:12.311082 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.dim_zones"
[0m22:18:12.314042 [debug] [Thread-2  ]: Began executing node model.homework.dim_zones
[0m22:18:12.344231 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.dim_zones"
[0m22:18:12.346229 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.dim_zones"
[0m22:18:12.347230 [debug] [Thread-2  ]: On model.homework.dim_zones: 
  
    CREATE TABLE IF NOT EXISTS `dataengine_learning`.`default`.`dim_zones__dbt_tmp`
    
    AS (
      -- models/core/dim_zones.sql Áª¥Â∫¶Ë°®Á§∫‰æã


select 
    locationid,          -- Áª¥Â∫¶‰∏ªÈîÆ
    borough,            -- ÊèèËø∞ÊÄßÂ±ûÊÄßÔºöË°åÊîøÂå∫
    zone,              -- ÊèèËø∞ÊÄßÂ±ûÊÄßÔºöÂÖ∑‰ΩìÂå∫Âüü
    service_zone       -- ÊèèËø∞ÊÄßÂ±ûÊÄßÔºöÊúçÂä°Âå∫ÂüüÁ±ªÂûã
from `dataengine_learning`.`default`.`stg_taxi_zone_lookup`
    )
    ;

  
[0m22:18:12.348233 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:18:15.953189 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202141812680gz5qx1rddlr
[0m22:18:15.953715 [debug] [Thread-2  ]: SQL status: OK in 3.605 seconds
[0m22:18:15.954238 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202141812680gz5qx1rddlr
[0m22:18:16.198917 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.dim_zones"
[0m22:18:16.198917 [debug] [Thread-2  ]: On model.homework.dim_zones: ALTER TABLE `dataengine_learning`.`default`.`dim_zones__dbt_tmp`
            RENAME TO dim_zones;
        
[0m22:18:18.765032 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202141816330gol30n6tjxh5
[0m22:18:18.765558 [debug] [Thread-2  ]: SQL status: OK in 2.566 seconds
[0m22:18:18.766186 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202141816330gol30n6tjxh5
[0m22:18:18.772469 [debug] [Thread-2  ]: On model.homework.dim_zones: COMMIT
[0m22:18:19.413763 [debug] [Thread-2  ]: On model.homework.dim_zones: Close
[0m22:18:19.414299 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '62e69df0-7216-4908-b08e-dbb6b8d599d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9B929430>]}
[0m22:18:19.414820 [info ] [Thread-2  ]: 5 of 6 OK created sql table model default.dim_zones ............................ [[32mOK[0m in 7.11s]
[0m22:18:19.416512 [debug] [Thread-2  ]: Finished running node model.homework.dim_zones
[0m22:18:19.417615 [debug] [Thread-2  ]: Began running node model.homework.fact_trips
[0m22:18:19.418710 [info ] [Thread-2  ]: 6 of 6 SKIP relation default.fact_trips ........................................ [[33mSKIP[0m]
[0m22:18:19.420544 [debug] [Thread-2  ]: Finished running node model.homework.fact_trips
[0m22:18:19.422703 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:18:19.423222 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m22:18:19.423735 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m22:18:19.423735 [debug] [MainThread]: Connection 'model.homework.dim_zones' was properly closed.
[0m22:18:19.424734 [info ] [MainThread]: 
[0m22:18:19.425789 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 0 minutes and 18.35 seconds (18.35s).
[0m22:18:19.427787 [debug] [MainThread]: Command end result
[0m22:18:19.475923 [info ] [MainThread]: 
[0m22:18:19.477246 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m22:18:19.477881 [info ] [MainThread]: 
[0m22:18:19.478801 [error] [MainThread]:   Runtime Error in model stg_fhv_tripdata (models\staging\stg_fhv_tripdata.sql)
  ODPS-0130071: InstanceId: 20241202141806160gzw1ytc4z8g
  ODPS-0130071:[19,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[23,21] Semantic analysis exception - class integer cannot be loaded from any resources
  
[0m22:18:19.480798 [info ] [MainThread]: 
[0m22:18:19.481798 [error] [MainThread]:   Runtime Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  ODPS-0130071: InstanceId: 20241202141807485gl3d0j7pgtb
  ODPS-0130071:[11,22] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[19,29] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[20,27] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[21,24] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[24,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[25,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[28,26] Semantic analysis exception - class integer cannot be loaded from any resources
  ODPS-0130071:[29,25] Semantic analysis exception - class numeric cannot be loaded from any resources
  ODPS-0130071:[30,26] Semantic analysis exception - class numeric cannot be loaded from any resources
  
[0m22:18:19.485829 [info ] [MainThread]: 
[0m22:18:19.486800 [error] [MainThread]:   Runtime Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  ParseError: RequestId: 674DC1A4D39357D85C0B9057 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
  SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (
  
  select 
      -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
          then md5('')
      else
          md5(concat())
      endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
      case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
          then md5('')
      else
          md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
      end as tripid,
      cast(vendorid as integer) as vendor_id,
      'Yellow' as service_type,
  
      -- Êó∂Èó¥Êà≥
      cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
      cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
      
      -- Ë°åÁ®ã‰ø°ÊÅØ
      cast(passenger_count as integer) as passenger_count,
      cast(trip_distance as numeric) as trip_distance,
      cast(ratecodeid as integer) as ratecode_id,
      
      -- ‰ΩçÁΩÆ‰ø°ÊÅØ
      cast(pulocationid as integer) as pickup_locationid,
      cast(dolocationid as integer) as dropoff_locationid,
      
      -- ÊîØ‰ªò‰ø°ÊÅØ
      cast(payment_type as integer) as payment_type,
      cast(fare_amount as numeric) as fare_amount,
      cast(total_amount as numeric) as total_amount
  from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
  where extract(year from tpep_pickup_datetime) in (2019, 2020));
  
  ODPS-0130161:[5,9] Parse exception - invalid token 'then'
  ODPS-0130161:[6,5] Parse exception - invalid token 'else'
  ODPS-0130161:[7,12] Parse exception - invalid token '('
  ODPS-0130161:[7,21] Parse exception - invalid token ')'
  ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m22:18:19.492508 [info ] [MainThread]: 
[0m22:18:19.493509 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=3 SKIP=1 TOTAL=6
[0m22:18:19.495507 [debug] [MainThread]: Command `dbt run` failed at 22:18:19.495507 after 22.68 seconds
[0m22:18:19.495507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CEFEE16520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9D18B940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE81424FD0>]}
[0m22:18:19.496506 [debug] [MainThread]: Flushing usage events
[0m22:18:22.621134 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m22:26:10.796786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D2427580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D504B5E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D504B4F0>]}


============================== 22:26:10.800785 | 51deaecc-a883-4481-9a3e-76e23d7c70e5 ==============================
[0m22:26:10.800785 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:26:10.800785 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:26:12.484338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231EEF39700>]}
[0m22:26:12.606377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D4E1A1F0>]}
[0m22:26:12.608390 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:26:13.339289 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m22:26:13.605253 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m22:26:13.607251 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_green_tripdata.sql
[0m22:26:13.608251 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_yellow_tripdata.sql
[0m22:26:13.608251 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_fhv_tripdata.sql
[0m22:26:13.932253 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m22:26:13.934254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231F0532CA0>]}
[0m22:26:14.195127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231F07C83D0>]}
[0m22:26:14.374349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231F07D6AC0>]}
[0m22:26:14.374349 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 538 macros
[0m22:26:14.375350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231F07D62B0>]}
[0m22:26:14.377350 [info ] [MainThread]: 
[0m22:26:14.378349 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m22:26:14.387965 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m22:26:14.388964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:26:15.165840 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m22:26:15.166423 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m22:26:15.169047 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m22:26:15.169566 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m22:26:15.170084 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:26:19.328607 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m22:26:19.334055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231F0521AC0>]}
[0m22:26:19.334627 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:26:19.335693 [info ] [MainThread]: 
[0m22:26:19.344720 [debug] [Thread-2  ]: Began running node model.homework.stg_fhv_tripdata
[0m22:26:19.345642 [info ] [Thread-2  ]: 1 of 6 START sql view model default.stg_fhv_tripdata ........................... [RUN]
[0m22:26:19.346646 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.stg_fhv_tripdata'
[0m22:26:19.347643 [debug] [Thread-2  ]: Began compiling node model.homework.stg_fhv_tripdata
[0m22:26:19.362642 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_fhv_tripdata"
[0m22:26:19.363644 [debug] [Thread-2  ]: Began executing node model.homework.stg_fhv_tripdata
[0m22:26:19.411644 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_fhv_tripdata"
[0m22:26:19.505641 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:26:19.506641 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(dispatching_base_num as string) as dispatching_base_num,
    cast(affiliated_base_number as string) as affiliated_base_number,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as datetime) as pickup_datetime,
    cast(dropoff_datetime as datetime) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as BIGINT) as pickup_locationid,
    cast(dolocationid as BIGINT) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as BIGINT) as sr_flag,

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime)  in (2019, 2020));

[0m22:26:19.506641 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m22:26:20.034069 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(dispatching_base_num as string) as dispatching_base_num,
    cast(affiliated_base_number as string) as affiliated_base_number,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as datetime) as pickup_datetime,
    cast(dropoff_datetime as datetime) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as BIGINT) as pickup_locationid,
    cast(dolocationid as BIGINT) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as BIGINT) as sr_flag,

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime)  in (2019, 2020));

[0m22:26:20.034632 [debug] [Thread-2  ]: MaxCompute adapter: ParseError: RequestId: 674DC38BECBE20C7C446DA4A Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(dispatching_base_num as string) as dispatching_base_num,
    cast(affiliated_base_number as string) as affiliated_base_number,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as datetime) as pickup_datetime,
    cast(dropoff_datetime as datetime) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as BIGINT) as pickup_locationid,
    cast(dolocationid as BIGINT) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as BIGINT) as sr_flag,

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime)  in (2019, 2020));

ODPS-0130161:[24,39] Parse exception - invalid token ','
[0m22:26:20.035736 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ROLLBACK
[0m22:26:20.041317 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_fhv_tripdata'
[0m22:26:20.042231 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: Close
[0m22:26:20.044209 [debug] [Thread-2  ]: Runtime Error in model stg_fhv_tripdata (models\staging\stg_fhv_tripdata.sql)
  ParseError: RequestId: 674DC38BECBE20C7C446DA4A Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
  SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql
  
  
  select
      -- Ê†áËØÜÁ¨¶
      case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
          then md5('')
      else
          md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
      end as tripid,
      cast(dispatching_base_num as string) as dispatching_base_num,
      cast(affiliated_base_number as string) as affiliated_base_number,
      'FHV' as service_type,
      
      -- Êó∂Èó¥Êà≥
      cast(pickup_datetime as datetime) as pickup_datetime,
      cast(dropoff_datetime as datetime) as dropoff_datetime,
      
      -- ‰ΩçÁΩÆ‰ø°ÊÅØ
      cast(pulocationid as BIGINT) as pickup_locationid,
      cast(dolocationid as BIGINT) as dropoff_locationid,
      
      -- FHVÁâπÊúâ‰ø°ÊÅØ
      cast(sr_flag as BIGINT) as sr_flag,
  
  from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
  where extract(year from pickup_datetime)  in (2019, 2020));
  
  ODPS-0130161:[24,39] Parse exception - invalid token ','
[0m22:26:20.046299 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D4474040>]}
[0m22:26:20.046816 [error] [Thread-2  ]: 1 of 6 ERROR creating sql view model default.stg_fhv_tripdata .................. [[31mERROR[0m in 0.70s]
[0m22:26:20.047847 [debug] [Thread-2  ]: Finished running node model.homework.stg_fhv_tripdata
[0m22:26:20.048425 [debug] [Thread-2  ]: Began running node model.homework.stg_green_tripdata
[0m22:26:20.049360 [info ] [Thread-2  ]: 2 of 6 START sql view model default.stg_green_tripdata ......................... [RUN]
[0m22:26:20.050358 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_fhv_tripdata, now model.homework.stg_green_tripdata)
[0m22:26:20.051360 [debug] [Thread-2  ]: Began compiling node model.homework.stg_green_tripdata
[0m22:26:20.057391 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_green_tripdata"
[0m22:26:20.058399 [debug] [Thread-2  ]: Began executing node model.homework.stg_green_tripdata
[0m22:26:20.063359 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_green_tripdata"
[0m22:26:20.064360 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:26:20.065360 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as datetime) as pickup_datetime,
    cast(lpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(store_and_fwd_flag as string) as store_and_fwd_flag,
    cast(ratecodeid as bigint) as ratecode_id,
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(extra as double) as extra,
    cast(mta_tax as double) as mta_tax,
    cast(tip_amount as double) as tip_amount,
    cast(tolls_amount as double) as tolls_amount,
    cast(improvement_surcharge as double) as improvement_surcharge,
    cast(total_amount as double) as total_amount,
    cast(congestion_surcharge as double) as congestion_surcharge
    
from `dataengine_learning`.`default`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m22:26:20.065360 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:26:21.390247 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142620717gnjentxm1y
[0m22:26:21.391312 [debug] [Thread-2  ]: SQL status: OK in 1.325 seconds
[0m22:26:21.391361 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142620717gnjentxm1y
[0m22:26:21.604261 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:26:21.604817 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ALTER VIEW dataengine_learning.default.stg_green_tripdata__dbt_tmp
            RENAME TO stg_green_tripdata;
        
[0m22:26:22.512605 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142621722gw4l60a4z8g
[0m22:26:22.513669 [debug] [Thread-2  ]: SQL status: OK in 0.908 seconds
[0m22:26:22.514191 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142621722gw4l60a4z8g
[0m22:26:22.534879 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: COMMIT
[0m22:26:23.378857 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: Close
[0m22:26:23.379375 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D27F6430>]}
[0m22:26:23.380436 [info ] [Thread-2  ]: 2 of 6 OK created sql view model default.stg_green_tripdata .................... [[32mOK[0m in 3.33s]
[0m22:26:23.381985 [debug] [Thread-2  ]: Finished running node model.homework.stg_green_tripdata
[0m22:26:23.382644 [debug] [Thread-2  ]: Began running node model.homework.stg_taxi_zone_lookup
[0m22:26:23.383168 [info ] [Thread-2  ]: 3 of 6 START sql view model default.stg_taxi_zone_lookup ....................... [RUN]
[0m22:26:23.384242 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_green_tripdata, now model.homework.stg_taxi_zone_lookup)
[0m22:26:23.384766 [debug] [Thread-2  ]: Began compiling node model.homework.stg_taxi_zone_lookup
[0m22:26:23.388870 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_taxi_zone_lookup"
[0m22:26:23.389870 [debug] [Thread-2  ]: Began executing node model.homework.stg_taxi_zone_lookup
[0m22:26:23.395870 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_taxi_zone_lookup"
[0m22:26:23.396871 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:26:23.397870 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`default`.`taxi_zone_lookup_in`);

[0m22:26:23.397870 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:26:24.430663 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142623715gznrzp5ahcr4
[0m22:26:24.431900 [debug] [Thread-2  ]: SQL status: OK in 1.033 seconds
[0m22:26:24.433059 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142623715gznrzp5ahcr4
[0m22:26:24.606648 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:26:24.607156 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup
            RENAME TO stg_taxi_zone_lookup__dbt_backup;
        
[0m22:26:25.562224 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142624703gn7ounlig7
[0m22:26:25.562751 [debug] [Thread-2  ]: SQL status: OK in 0.955 seconds
[0m22:26:25.563277 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142624703gn7ounlig7
[0m22:26:25.836349 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:26:25.836912 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup__dbt_tmp
            RENAME TO stg_taxi_zone_lookup;
        
[0m22:26:26.901400 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142625957gqjzxm5caa
[0m22:26:26.902450 [debug] [Thread-2  ]: SQL status: OK in 1.065 seconds
[0m22:26:26.902976 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142625957gqjzxm5caa
[0m22:26:26.907185 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: COMMIT
[0m22:26:27.615162 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: Close
[0m22:26:27.615686 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231F10C3280>]}
[0m22:26:27.616766 [info ] [Thread-2  ]: 3 of 6 OK created sql view model default.stg_taxi_zone_lookup .................. [[32mOK[0m in 4.23s]
[0m22:26:27.617801 [debug] [Thread-2  ]: Finished running node model.homework.stg_taxi_zone_lookup
[0m22:26:27.618393 [debug] [Thread-2  ]: Began running node model.homework.stg_yellow_tripdata
[0m22:26:27.619465 [info ] [Thread-2  ]: 4 of 6 START sql view model default.stg_yellow_tripdata ........................ [RUN]
[0m22:26:27.620514 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_taxi_zone_lookup, now model.homework.stg_yellow_tripdata)
[0m22:26:27.621036 [debug] [Thread-2  ]: Began compiling node model.homework.stg_yellow_tripdata
[0m22:26:27.630295 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_yellow_tripdata"
[0m22:26:27.631297 [debug] [Thread-2  ]: Began executing node model.homework.stg_yellow_tripdata
[0m22:26:27.640296 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_yellow_tripdata"
[0m22:26:27.641296 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:26:27.642296 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Yellow' as service_type,
    
    -- timestamps
    cast(tpep_pickup_datetime as datetime) as pickup_datetime,
    cast(tpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    cast(ratecodeid as bigint) as ratecode_id,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(total_amount as double) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m22:26:27.643296 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:26:28.080243 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Yellow' as service_type,
    
    -- timestamps
    cast(tpep_pickup_datetime as datetime) as pickup_datetime,
    cast(tpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    cast(ratecodeid as bigint) as ratecode_id,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(total_amount as double) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m22:26:28.081374 [debug] [Thread-2  ]: MaxCompute adapter: ParseError: RequestId: 674DC393ECBE20C7C446E0E0 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
        then md5('')
    else
        md5(concat())
    endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Yellow' as service_type,
    
    -- timestamps
    cast(tpep_pickup_datetime as datetime) as pickup_datetime,
    cast(tpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    cast(ratecodeid as bigint) as ratecode_id,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(total_amount as double) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

ODPS-0130161:[5,9] Parse exception - invalid token 'then'
ODPS-0130161:[6,5] Parse exception - invalid token 'else'
ODPS-0130161:[7,12] Parse exception - invalid token '('
ODPS-0130161:[7,21] Parse exception - invalid token ')'
ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m22:26:28.081952 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ROLLBACK
[0m22:26:28.084532 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_yellow_tripdata'
[0m22:26:28.085091 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: Close
[0m22:26:28.087304 [debug] [Thread-2  ]: Runtime Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  ParseError: RequestId: 674DC393ECBE20C7C446E0E0 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
  SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (
  
  select 
      -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
          then md5('')
      else
          md5(concat())
      endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
      case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
          then md5('')
      else
          md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
      end as tripid,
      cast(vendorid as bigint) as vendor_id,
      'Yellow' as service_type,
      
      -- timestamps
      cast(tpep_pickup_datetime as datetime) as pickup_datetime,
      cast(tpep_dropoff_datetime as datetime) as dropoff_datetime,
      
      -- trip info
      cast(passenger_count as bigint) as passenger_count,
      cast(trip_distance as double) as trip_distance,
      cast(ratecodeid as bigint) as ratecode_id,
      
      -- location info
      cast(pulocationid as bigint) as pickup_locationid,
      cast(dolocationid as bigint) as dropoff_locationid,
      
      -- payment info
      cast(payment_type as bigint) as payment_type,
      cast(fare_amount as double) as fare_amount,
      cast(total_amount as double) as total_amount
  from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
  where extract(year from tpep_pickup_datetime) in (2019, 2020));
  
  ODPS-0130161:[5,9] Parse exception - invalid token 'then'
  ODPS-0130161:[6,5] Parse exception - invalid token 'else'
  ODPS-0130161:[7,12] Parse exception - invalid token '('
  ODPS-0130161:[7,21] Parse exception - invalid token ')'
  ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m22:26:28.088236 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231F10CD550>]}
[0m22:26:28.088950 [error] [Thread-2  ]: 4 of 6 ERROR creating sql view model default.stg_yellow_tripdata ............... [[31mERROR[0m in 0.47s]
[0m22:26:28.090037 [debug] [Thread-2  ]: Finished running node model.homework.stg_yellow_tripdata
[0m22:26:28.091131 [debug] [Thread-2  ]: Began running node model.homework.dim_zones
[0m22:26:28.091657 [info ] [Thread-2  ]: 5 of 6 START sql table model default.dim_zones ................................. [RUN]
[0m22:26:28.092651 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_yellow_tripdata, now model.homework.dim_zones)
[0m22:26:28.093648 [debug] [Thread-2  ]: Began compiling node model.homework.dim_zones
[0m22:26:28.096688 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.dim_zones"
[0m22:26:28.098685 [debug] [Thread-2  ]: Began executing node model.homework.dim_zones
[0m22:26:28.120647 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.dim_zones"
[0m22:26:28.121647 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.dim_zones"
[0m22:26:28.122647 [debug] [Thread-2  ]: On model.homework.dim_zones: 
  
    CREATE TABLE IF NOT EXISTS `dataengine_learning`.`default`.`dim_zones__dbt_tmp`
    
    AS (
      -- models/core/dim_zones.sql Áª¥Â∫¶Ë°®Á§∫‰æã


select 
    locationid,          -- Áª¥Â∫¶‰∏ªÈîÆ
    borough,            -- ÊèèËø∞ÊÄßÂ±ûÊÄßÔºöË°åÊîøÂå∫
    zone,              -- ÊèèËø∞ÊÄßÂ±ûÊÄßÔºöÂÖ∑‰ΩìÂå∫Âüü
    service_zone       -- ÊèèËø∞ÊÄßÂ±ûÊÄßÔºöÊúçÂä°Âå∫ÂüüÁ±ªÂûã
from `dataengine_learning`.`default`.`stg_taxi_zone_lookup`
    )
    ;

  
[0m22:26:28.122647 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:26:31.014682 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142628475gch2ratorjg
[0m22:26:31.015334 [debug] [Thread-2  ]: SQL status: OK in 2.892 seconds
[0m22:26:31.015900 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142628475gch2ratorjg
[0m22:26:31.205062 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.dim_zones"
[0m22:26:31.206198 [debug] [Thread-2  ]: On model.homework.dim_zones: ALTER TABLE `dataengine_learning`.`default`.`dim_zones`
            RENAME TO dim_zones__dbt_backup;
        
[0m22:26:32.392403 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142631325gbuendemg7
[0m22:26:32.393463 [debug] [Thread-2  ]: SQL status: OK in 1.187 seconds
[0m22:26:32.393983 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142631325gbuendemg7
[0m22:26:32.541428 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.dim_zones"
[0m22:26:32.541956 [debug] [Thread-2  ]: On model.homework.dim_zones: ALTER TABLE `dataengine_learning`.`default`.`dim_zones__dbt_tmp`
            RENAME TO dim_zones;
        
[0m22:26:33.585568 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142632658gw9ounlig7
[0m22:26:33.586702 [debug] [Thread-2  ]: SQL status: OK in 1.044 seconds
[0m22:26:33.587785 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142632658gw9ounlig7
[0m22:26:33.596589 [debug] [Thread-2  ]: On model.homework.dim_zones: COMMIT
[0m22:26:34.399111 [debug] [Thread-2  ]: On model.homework.dim_zones: Close
[0m22:26:34.400232 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '51deaecc-a883-4481-9a3e-76e23d7c70e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231F10CD910>]}
[0m22:26:34.400790 [info ] [Thread-2  ]: 5 of 6 OK created sql table model default.dim_zones ............................ [[32mOK[0m in 6.31s]
[0m22:26:34.403158 [debug] [Thread-2  ]: Finished running node model.homework.dim_zones
[0m22:26:34.403674 [debug] [Thread-2  ]: Began running node model.homework.fact_trips
[0m22:26:34.404706 [info ] [Thread-2  ]: 6 of 6 SKIP relation default.fact_trips ........................................ [[33mSKIP[0m]
[0m22:26:34.405758 [debug] [Thread-2  ]: Finished running node model.homework.fact_trips
[0m22:26:34.407845 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:26:34.408368 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m22:26:34.409475 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m22:26:34.409991 [debug] [MainThread]: Connection 'model.homework.dim_zones' was properly closed.
[0m22:26:34.409991 [info ] [MainThread]: 
[0m22:26:34.410987 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 0 minutes and 20.03 seconds (20.03s).
[0m22:26:34.413035 [debug] [MainThread]: Command end result
[0m22:26:34.467379 [info ] [MainThread]: 
[0m22:26:34.468453 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m22:26:34.469040 [info ] [MainThread]: 
[0m22:26:34.470088 [error] [MainThread]:   Runtime Error in model stg_fhv_tripdata (models\staging\stg_fhv_tripdata.sql)
  ParseError: RequestId: 674DC38BECBE20C7C446DA4A Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
  SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql
  
  
  select
      -- Ê†áËØÜÁ¨¶
      case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
          then md5('')
      else
          md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
      end as tripid,
      cast(dispatching_base_num as string) as dispatching_base_num,
      cast(affiliated_base_number as string) as affiliated_base_number,
      'FHV' as service_type,
      
      -- Êó∂Èó¥Êà≥
      cast(pickup_datetime as datetime) as pickup_datetime,
      cast(dropoff_datetime as datetime) as dropoff_datetime,
      
      -- ‰ΩçÁΩÆ‰ø°ÊÅØ
      cast(pulocationid as BIGINT) as pickup_locationid,
      cast(dolocationid as BIGINT) as dropoff_locationid,
      
      -- FHVÁâπÊúâ‰ø°ÊÅØ
      cast(sr_flag as BIGINT) as sr_flag,
  
  from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
  where extract(year from pickup_datetime)  in (2019, 2020));
  
  ODPS-0130161:[24,39] Parse exception - invalid token ','
[0m22:26:34.473766 [info ] [MainThread]: 
[0m22:26:34.474931 [error] [MainThread]:   Runtime Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  ParseError: RequestId: 674DC393ECBE20C7C446E0E0 Tag: ODPS Endpoint: https://service.cn-hangzhou.maxcompute.aliyun.com/api
  SQL Statement: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (
  
  select 
      -- Ê†áËØÜÁ¨¶ÔºåËøôÈáåcase when concat() = NULL
          then md5('')
      else
          md5(concat())
      endÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
      case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
          then md5('')
      else
          md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
      end as tripid,
      cast(vendorid as bigint) as vendor_id,
      'Yellow' as service_type,
      
      -- timestamps
      cast(tpep_pickup_datetime as datetime) as pickup_datetime,
      cast(tpep_dropoff_datetime as datetime) as dropoff_datetime,
      
      -- trip info
      cast(passenger_count as bigint) as passenger_count,
      cast(trip_distance as double) as trip_distance,
      cast(ratecodeid as bigint) as ratecode_id,
      
      -- location info
      cast(pulocationid as bigint) as pickup_locationid,
      cast(dolocationid as bigint) as dropoff_locationid,
      
      -- payment info
      cast(payment_type as bigint) as payment_type,
      cast(fare_amount as double) as fare_amount,
      cast(total_amount as double) as total_amount
  from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
  where extract(year from tpep_pickup_datetime) in (2019, 2020));
  
  ODPS-0130161:[5,9] Parse exception - invalid token 'then'
  ODPS-0130161:[6,5] Parse exception - invalid token 'else'
  ODPS-0130161:[7,12] Parse exception - invalid token '('
  ODPS-0130161:[7,21] Parse exception - invalid token ')'
  ODPS-0130161:[35,62] Parse exception - invalid token ')'
[0m22:26:34.479608 [info ] [MainThread]: 
[0m22:26:34.481112 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=1 TOTAL=6
[0m22:26:34.484844 [debug] [MainThread]: Command `dbt run` failed at 22:26:34.484319 after 23.75 seconds
[0m22:26:34.486479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D2427580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231D4E1A1F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231EF041700>]}
[0m22:26:34.488135 [debug] [MainThread]: Flushing usage events
[0m22:29:26.959414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B378C765B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B37B89B610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B37B89B520>]}


============================== 22:29:26.962413 | 0f3529ae-723b-452a-8a08-a303637acbf5 ==============================
[0m22:29:26.962413 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:29:26.963415 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:29:28.514668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B31578D7F0>]}
[0m22:29:28.642200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B3147F4EE0>]}
[0m22:29:28.643924 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:29:29.439296 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m22:29:29.722557 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m22:29:29.723103 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_fhv_tripdata.sql
[0m22:29:29.724220 [debug] [MainThread]: Partial parsing: updated file: homework://models\staging\stg_yellow_tripdata.sql
[0m22:29:30.029813 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m22:29:30.031813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B315892EB0>]}
[0m22:29:30.249866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B316F9B820>]}
[0m22:29:30.416064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B317001940>]}
[0m22:29:30.416064 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 538 macros
[0m22:29:30.417065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B316FE6550>]}
[0m22:29:30.419065 [info ] [MainThread]: 
[0m22:29:30.420064 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m22:29:30.427064 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m22:29:30.428064 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:29:31.199391 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m22:29:31.199915 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m22:29:31.202054 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m22:29:31.203115 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m22:29:31.203638 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:29:35.443568 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m22:29:35.448969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B31577AA00>]}
[0m22:29:35.449626 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:29:35.450668 [info ] [MainThread]: 
[0m22:29:35.455368 [debug] [Thread-2  ]: Began running node model.homework.stg_fhv_tripdata
[0m22:29:35.456368 [info ] [Thread-2  ]: 1 of 6 START sql view model default.stg_fhv_tripdata ........................... [RUN]
[0m22:29:35.457368 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.stg_fhv_tripdata'
[0m22:29:35.458369 [debug] [Thread-2  ]: Began compiling node model.homework.stg_fhv_tripdata
[0m22:29:35.470372 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_fhv_tripdata"
[0m22:29:35.471369 [debug] [Thread-2  ]: Began executing node model.homework.stg_fhv_tripdata
[0m22:29:35.514160 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_fhv_tripdata"
[0m22:29:35.621573 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:29:35.622574 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(dispatching_base_num as string) as dispatching_base_num,
    cast(affiliated_base_number as string) as affiliated_base_number,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as datetime) as pickup_datetime,
    cast(dropoff_datetime as datetime) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as BIGINT) as pickup_locationid,
    cast(dolocationid as BIGINT) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as BIGINT) as sr_flag

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime)  in (2019, 2020));

[0m22:29:35.623574 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m22:29:36.770269 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142935984gy2nknhi4gg
[0m22:29:36.770782 [debug] [Thread-2  ]: SQL status: OK in 1.147 seconds
[0m22:29:36.771355 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142935984gy2nknhi4gg
[0m22:29:36.931298 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:29:36.932394 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ALTER VIEW dataengine_learning.default.stg_fhv_tripdata__dbt_tmp
            RENAME TO stg_fhv_tripdata;
        
[0m22:29:37.853212 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214293740gpkaq8lhaz1
[0m22:29:37.853800 [debug] [Thread-2  ]: SQL status: OK in 0.921 seconds
[0m22:29:37.854377 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214293740gpkaq8lhaz1
[0m22:29:37.869863 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: COMMIT
[0m22:29:38.557303 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: Close
[0m22:29:38.558631 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B379046460>]}
[0m22:29:38.559450 [info ] [Thread-2  ]: 1 of 6 OK created sql view model default.stg_fhv_tripdata ...................... [[32mOK[0m in 3.10s]
[0m22:29:38.561124 [debug] [Thread-2  ]: Finished running node model.homework.stg_fhv_tripdata
[0m22:29:38.561636 [debug] [Thread-2  ]: Began running node model.homework.stg_green_tripdata
[0m22:29:38.562642 [info ] [Thread-2  ]: 2 of 6 START sql view model default.stg_green_tripdata ......................... [RUN]
[0m22:29:38.563150 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_fhv_tripdata, now model.homework.stg_green_tripdata)
[0m22:29:38.564116 [debug] [Thread-2  ]: Began compiling node model.homework.stg_green_tripdata
[0m22:29:38.570306 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_green_tripdata"
[0m22:29:38.571306 [debug] [Thread-2  ]: Began executing node model.homework.stg_green_tripdata
[0m22:29:38.577306 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_green_tripdata"
[0m22:29:38.578307 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:29:38.578307 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as datetime) as pickup_datetime,
    cast(lpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(store_and_fwd_flag as string) as store_and_fwd_flag,
    cast(ratecodeid as bigint) as ratecode_id,
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(extra as double) as extra,
    cast(mta_tax as double) as mta_tax,
    cast(tip_amount as double) as tip_amount,
    cast(tolls_amount as double) as tolls_amount,
    cast(improvement_surcharge as double) as improvement_surcharge,
    cast(total_amount as double) as total_amount,
    cast(congestion_surcharge as double) as congestion_surcharge
    
from `dataengine_learning`.`default`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m22:29:38.579306 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:29:44.570167 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142943921ge0nim06l22
[0m22:29:44.570679 [debug] [Thread-2  ]: SQL status: OK in 5.991 seconds
[0m22:29:44.571280 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142943921ge0nim06l22
[0m22:29:44.790544 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:29:44.791336 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ALTER VIEW dataengine_learning.default.stg_green_tripdata
            RENAME TO stg_green_tripdata__dbt_backup;
        
[0m22:29:45.729575 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142944900g3vns8hddlr
[0m22:29:45.730624 [debug] [Thread-2  ]: SQL status: OK in 0.939 seconds
[0m22:29:45.731151 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142944900g3vns8hddlr
[0m22:29:45.946077 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:29:45.946686 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ALTER VIEW dataengine_learning.default.stg_green_tripdata__dbt_tmp
            RENAME TO stg_green_tripdata;
        
[0m22:29:47.163066 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142946121g5kgub4awkr
[0m22:29:47.163745 [debug] [Thread-2  ]: SQL status: OK in 1.217 seconds
[0m22:29:47.164274 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142946121g5kgub4awkr
[0m22:29:47.169189 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: COMMIT
[0m22:29:47.756691 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: Close
[0m22:29:47.757201 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B316FB0430>]}
[0m22:29:47.757717 [info ] [Thread-2  ]: 2 of 6 OK created sql view model default.stg_green_tripdata .................... [[32mOK[0m in 9.19s]
[0m22:29:47.759304 [debug] [Thread-2  ]: Finished running node model.homework.stg_green_tripdata
[0m22:29:47.759885 [debug] [Thread-2  ]: Began running node model.homework.stg_taxi_zone_lookup
[0m22:29:47.760397 [info ] [Thread-2  ]: 3 of 6 START sql view model default.stg_taxi_zone_lookup ....................... [RUN]
[0m22:29:47.761506 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_green_tripdata, now model.homework.stg_taxi_zone_lookup)
[0m22:29:47.762035 [debug] [Thread-2  ]: Began compiling node model.homework.stg_taxi_zone_lookup
[0m22:29:47.765826 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_taxi_zone_lookup"
[0m22:29:47.766863 [debug] [Thread-2  ]: Began executing node model.homework.stg_taxi_zone_lookup
[0m22:29:47.772685 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:29:48.631837 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_taxi_zone_lookup"
[0m22:29:48.632760 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:29:48.633904 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`default`.`taxi_zone_lookup_in`);

[0m22:29:49.344009 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142948738gcb4ratorjg
[0m22:29:49.344537 [debug] [Thread-2  ]: SQL status: OK in 0.710 seconds
[0m22:29:49.345614 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202142948738gcb4ratorjg
[0m22:29:49.504843 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:29:49.505366 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup
            RENAME TO stg_taxi_zone_lookup__dbt_backup;
        
[0m22:29:50.217626 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 20241202142949608gb2n0smmlcr4
ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
, retry times 0
[0m22:30:00.880959 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 20241202143000339gf6nim06l22
ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
, retry times 1
[0m22:30:11.532121 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup
            RENAME TO stg_taxi_zone_lookup__dbt_backup;
        
[0m22:30:11.532649 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130211: InstanceId: 20241202143010999gcen0smmlcr4
ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined

[0m22:30:11.533753 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ROLLBACK
[0m22:30:11.540013 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_taxi_zone_lookup'
[0m22:30:11.541217 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: Close
[0m22:30:11.542907 [debug] [Thread-2  ]: Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130211: InstanceId: 20241202143010999gcen0smmlcr4
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
  
[0m22:30:11.543904 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B316CB74F0>]}
[0m22:30:11.544902 [error] [Thread-2  ]: 3 of 6 ERROR creating sql view model default.stg_taxi_zone_lookup .............. [[31mERROR[0m in 23.78s]
[0m22:30:11.545904 [debug] [Thread-2  ]: Finished running node model.homework.stg_taxi_zone_lookup
[0m22:30:11.546941 [debug] [Thread-2  ]: Began running node model.homework.stg_yellow_tripdata
[0m22:30:11.547939 [info ] [Thread-2  ]: 4 of 6 START sql view model default.stg_yellow_tripdata ........................ [RUN]
[0m22:30:11.548902 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_taxi_zone_lookup, now model.homework.stg_yellow_tripdata)
[0m22:30:11.548902 [debug] [Thread-2  ]: Began compiling node model.homework.stg_yellow_tripdata
[0m22:30:11.554940 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_yellow_tripdata"
[0m22:30:11.556903 [debug] [Thread-2  ]: Began executing node model.homework.stg_yellow_tripdata
[0m22:30:11.564622 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_yellow_tripdata"
[0m22:30:11.566421 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:30:11.567466 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáågenerate_surrogate_key()ÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Yellow' as service_type,
    
    -- timestamps
    cast(tpep_pickup_datetime as datetime) as pickup_datetime,
    cast(tpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    cast(ratecodeid as bigint) as ratecode_id,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(total_amount as double) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m22:30:11.567986 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:30:12.522422 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143011908glwgndemg7
[0m22:30:12.522943 [debug] [Thread-2  ]: SQL status: OK in 0.955 seconds
[0m22:30:12.523468 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143011908glwgndemg7
[0m22:30:12.698343 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:30:12.698873 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ALTER VIEW dataengine_learning.default.stg_yellow_tripdata__dbt_tmp
            RENAME TO stg_yellow_tripdata;
        
[0m22:30:13.616418 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143012810g7xgndemg7
[0m22:30:13.616930 [debug] [Thread-2  ]: SQL status: OK in 0.918 seconds
[0m22:30:13.618055 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143012810g7xgndemg7
[0m22:30:13.619745 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: COMMIT
[0m22:30:14.218545 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: Close
[0m22:30:14.219501 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f3529ae-723b-452a-8a08-a303637acbf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B316BE8100>]}
[0m22:30:14.220582 [info ] [Thread-2  ]: 4 of 6 OK created sql view model default.stg_yellow_tripdata ................... [[32mOK[0m in 2.67s]
[0m22:30:14.221727 [debug] [Thread-2  ]: Finished running node model.homework.stg_yellow_tripdata
[0m22:30:14.222809 [debug] [Thread-2  ]: Began running node model.homework.dim_zones
[0m22:30:14.223344 [info ] [Thread-2  ]: 5 of 6 SKIP relation default.dim_zones ......................................... [[33mSKIP[0m]
[0m22:30:14.224401 [debug] [Thread-2  ]: Finished running node model.homework.dim_zones
[0m22:30:14.225958 [debug] [Thread-2  ]: Began running node model.homework.fact_trips
[0m22:30:14.226569 [info ] [Thread-2  ]: 6 of 6 SKIP relation default.fact_trips ........................................ [[33mSKIP[0m]
[0m22:30:14.227629 [debug] [Thread-2  ]: Finished running node model.homework.fact_trips
[0m22:30:14.230337 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:30:14.231335 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m22:30:14.231335 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m22:30:14.232335 [debug] [MainThread]: Connection 'model.homework.stg_yellow_tripdata' was properly closed.
[0m22:30:14.232335 [info ] [MainThread]: 
[0m22:30:14.234338 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 0 minutes and 43.81 seconds (43.81s).
[0m22:30:14.235336 [debug] [MainThread]: Command end result
[0m22:30:14.292335 [info ] [MainThread]: 
[0m22:30:14.293700 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:30:14.294769 [info ] [MainThread]: 
[0m22:30:14.295293 [error] [MainThread]:   Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130211: InstanceId: 20241202143010999gcen0smmlcr4
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
  
[0m22:30:14.296883 [info ] [MainThread]: 
[0m22:30:14.297951 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=2 TOTAL=6
[0m22:30:14.300755 [debug] [MainThread]: Command `dbt run` failed at 22:30:14.300184 after 47.41 seconds
[0m22:30:14.301291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B378C765B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B315A79F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B3157DC5E0>]}
[0m22:30:14.301839 [debug] [MainThread]: Flushing usage events
[0m22:32:40.852217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B4899B65B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B48C5CA520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B48C5CA430>]}


============================== 22:32:40.857215 | 9dbb00a6-3b80-4b3f-bb2c-36d88f718be1 ==============================
[0m22:32:40.857215 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:32:40.858218 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:32:41.099354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9dbb00a6-3b80-4b3f-bb2c-36d88f718be1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B48C5CA790>]}
[0m22:32:41.179022 [debug] [MainThread]: Command `dbt clean` succeeded at 22:32:41.179022 after 0.39 seconds
[0m22:32:41.180023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B4899B65B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B489D8A940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B48C63B7F0>]}
[0m22:32:41.181021 [debug] [MainThread]: Flushing usage events
[0m22:33:31.183337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D79E9C65B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7A15EB610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7A15EB520>]}


============================== 22:33:31.187385 | 134b12a0-ba87-4c48-8fe9-963ffb5440c8 ==============================
[0m22:33:31.187385 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:33:31.188505 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --full-refresh', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:33:32.899854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '134b12a0-ba87-4c48-8fe9-963ffb5440c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7BB4DD7F0>]}
[0m22:33:33.051768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '134b12a0-ba87-4c48-8fe9-963ffb5440c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7BA544EE0>]}
[0m22:33:33.052768 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:33:33.852127 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found 1 package(s) specified in packages.yml, but only 0 package(s) installed in dbt_packages. Run "dbt deps" to install package dependencies.
[0m22:33:33.855127 [debug] [MainThread]: Command `dbt run` failed at 22:33:33.855127 after 2.73 seconds
[0m22:33:33.855127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D79E9C65B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7BB533820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7BB535D30>]}
[0m22:33:33.856128 [debug] [MainThread]: Flushing usage events
[0m22:34:05.587648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026EBBE67490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026EBEA7C430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026EBEA7C340>]}


============================== 22:34:05.591647 | f4511a74-3671-4c44-a290-6abb8f0fc25a ==============================
[0m22:34:05.591647 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:34:05.593647 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m22:34:05.871723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f4511a74-3671-4c44-a290-6abb8f0fc25a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026EBEA7C6A0>]}
[0m22:34:05.903681 [debug] [MainThread]: Set downloads directory='C:\Users\Êù∞Âì•Â∏¶~1\AppData\Local\Temp\dbt-downloads-2gxcqhwj'
[0m22:34:05.903681 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m22:34:07.145095 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m22:34:07.146865 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m22:34:07.903277 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m22:34:07.909214 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m22:34:09.640881 [info ] [MainThread]: Installed from version 1.1.1
[0m22:34:09.641881 [info ] [MainThread]: Updated version available: 1.3.0
[0m22:34:09.641881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'f4511a74-3671-4c44-a290-6abb8f0fc25a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026EBC7E1CA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026EBC77F880>]}
[0m22:34:09.642881 [info ] [MainThread]: 
[0m22:34:09.643881 [info ] [MainThread]: Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
[0m22:34:09.646881 [debug] [MainThread]: Command `dbt deps` succeeded at 22:34:09.646881 after 4.13 seconds
[0m22:34:09.647881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026EBBE67490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026EBC77F880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026EBEBC0520>]}
[0m22:34:09.647881 [debug] [MainThread]: Flushing usage events
[0m22:34:15.380817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A36B47580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A3976B5E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A3976B4F0>]}


============================== 22:34:15.383817 | 90a8eb31-ffb0-4099-905b-5da3fcb86f97 ==============================
[0m22:34:15.383817 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:34:15.385817 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m22:34:17.136517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A53659700>]}
[0m22:34:17.266676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A3953A1F0>]}
[0m22:34:17.268676 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:34:18.053164 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m22:34:18.054165 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m22:34:18.055164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A331538E0>]}
[0m22:34:19.644899 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m22:34:19.646898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A5365D700>]}
[0m22:34:20.028849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A54EA60A0>]}
[0m22:34:20.198896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A54F1A670>]}
[0m22:34:20.199895 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 538 macros
[0m22:34:20.200895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A54C75430>]}
[0m22:34:20.202895 [info ] [MainThread]: 
[0m22:34:20.203895 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m22:34:20.210889 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m22:34:20.210889 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:20.945310 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m22:34:20.945828 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m22:34:20.948588 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m22:34:20.949163 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m22:34:20.949684 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:25.671574 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m22:34:25.678025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A5364A9D0>]}
[0m22:34:25.679202 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:34:25.680346 [info ] [MainThread]: 
[0m22:34:25.682858 [debug] [Thread-2  ]: Began running node model.homework.stg_fhv_tripdata
[0m22:34:25.683857 [info ] [Thread-2  ]: 1 of 6 START sql view model default.stg_fhv_tripdata ........................... [RUN]
[0m22:34:25.684857 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.stg_fhv_tripdata'
[0m22:34:25.685861 [debug] [Thread-2  ]: Began compiling node model.homework.stg_fhv_tripdata
[0m22:34:25.702469 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_fhv_tripdata"
[0m22:34:25.706468 [debug] [Thread-2  ]: Began executing node model.homework.stg_fhv_tripdata
[0m22:34:25.751576 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_fhv_tripdata"
[0m22:34:25.852493 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:34:25.853492 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(dispatching_base_num as string) as dispatching_base_num,
    cast(affiliated_base_number as string) as affiliated_base_number,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as datetime) as pickup_datetime,
    cast(dropoff_datetime as datetime) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as BIGINT) as pickup_locationid,
    cast(dolocationid as BIGINT) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as BIGINT) as sr_flag

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime)  in (2019, 2020));

[0m22:34:25.853492 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m22:34:26.987794 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143426233g8g4ym5caa
[0m22:34:26.988936 [debug] [Thread-2  ]: SQL status: OK in 1.135 seconds
[0m22:34:26.990015 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143426233g8g4ym5caa
[0m22:34:27.223349 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:34:27.223872 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ALTER VIEW dataengine_learning.default.stg_fhv_tripdata
            RENAME TO stg_fhv_tripdata__dbt_backup;
        
[0m22:34:28.183507 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143427363gozljhwk0kd4
[0m22:34:28.184600 [debug] [Thread-2  ]: SQL status: OK in 0.960 seconds
[0m22:34:28.185681 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143427363gozljhwk0kd4
[0m22:34:28.361302 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:34:28.361829 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ALTER VIEW dataengine_learning.default.stg_fhv_tripdata__dbt_tmp
            RENAME TO stg_fhv_tripdata;
        
[0m22:34:29.369718 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143428468gf3rejuuulq
[0m22:34:29.370242 [debug] [Thread-2  ]: SQL status: OK in 1.008 seconds
[0m22:34:29.370774 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143428468gf3rejuuulq
[0m22:34:29.390373 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: COMMIT
[0m22:34:30.013859 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: Close
[0m22:34:30.015970 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A36F16430>]}
[0m22:34:30.016497 [info ] [Thread-2  ]: 1 of 6 OK created sql view model default.stg_fhv_tripdata ...................... [[32mOK[0m in 4.33s]
[0m22:34:30.018061 [debug] [Thread-2  ]: Finished running node model.homework.stg_fhv_tripdata
[0m22:34:30.018588 [debug] [Thread-2  ]: Began running node model.homework.stg_green_tripdata
[0m22:34:30.019155 [info ] [Thread-2  ]: 2 of 6 START sql view model default.stg_green_tripdata ......................... [RUN]
[0m22:34:30.020282 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_fhv_tripdata, now model.homework.stg_green_tripdata)
[0m22:34:30.020880 [debug] [Thread-2  ]: Began compiling node model.homework.stg_green_tripdata
[0m22:34:30.028063 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_green_tripdata"
[0m22:34:30.030064 [debug] [Thread-2  ]: Began executing node model.homework.stg_green_tripdata
[0m22:34:30.040301 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:34:30.916639 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_green_tripdata"
[0m22:34:30.918774 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:34:30.919310 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as datetime) as pickup_datetime,
    cast(lpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(store_and_fwd_flag as string) as store_and_fwd_flag,
    cast(ratecodeid as bigint) as ratecode_id,
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(extra as double) as extra,
    cast(mta_tax as double) as mta_tax,
    cast(tip_amount as double) as tip_amount,
    cast(tolls_amount as double) as tolls_amount,
    cast(improvement_surcharge as double) as improvement_surcharge,
    cast(total_amount as double) as total_amount,
    cast(congestion_surcharge as double) as congestion_surcharge
    
from `dataengine_learning`.`default`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m22:34:31.707265 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214343124grs5lsab0e1
[0m22:34:31.707785 [debug] [Thread-2  ]: SQL status: OK in 0.788 seconds
[0m22:34:31.708305 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214343124grs5lsab0e1
[0m22:34:31.977194 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:34:31.977719 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ALTER VIEW dataengine_learning.default.stg_green_tripdata
            RENAME TO stg_green_tripdata__dbt_backup;
        
[0m22:34:32.834681 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 2024120214343297gzu4foh7x8g
ODPS-0130211:[2,23] Table or view already exists - table or view stg_green_tripdata__dbt_backup is already defined
, retry times 0
[0m22:34:43.602805 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 20241202143442962gmb9ljxm1y
ODPS-0130211:[2,23] Table or view already exists - table or view stg_green_tripdata__dbt_backup is already defined
, retry times 1
[0m22:34:54.282784 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
ALTER VIEW dataengine_learning.default.stg_green_tripdata
            RENAME TO stg_green_tripdata__dbt_backup;
        
[0m22:34:54.283305 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130211: InstanceId: 20241202143453718gisfqckuq
ODPS-0130211:[2,23] Table or view already exists - table or view stg_green_tripdata__dbt_backup is already defined

[0m22:34:54.283891 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ROLLBACK
[0m22:34:54.289806 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_green_tripdata'
[0m22:34:54.290366 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: Close
[0m22:34:54.292576 [debug] [Thread-2  ]: Runtime Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  ODPS-0130211: InstanceId: 20241202143453718gisfqckuq
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_green_tripdata__dbt_backup is already defined
  
[0m22:34:54.293185 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A555144C0>]}
[0m22:34:54.294186 [error] [Thread-2  ]: 2 of 6 ERROR creating sql view model default.stg_green_tripdata ................ [[31mERROR[0m in 24.27s]
[0m22:34:54.297185 [debug] [Thread-2  ]: Finished running node model.homework.stg_green_tripdata
[0m22:34:54.298196 [debug] [Thread-2  ]: Began running node model.homework.stg_taxi_zone_lookup
[0m22:34:54.299930 [info ] [Thread-2  ]: 3 of 6 START sql view model default.stg_taxi_zone_lookup ....................... [RUN]
[0m22:34:54.300928 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_green_tripdata, now model.homework.stg_taxi_zone_lookup)
[0m22:34:54.301927 [debug] [Thread-2  ]: Began compiling node model.homework.stg_taxi_zone_lookup
[0m22:34:54.309439 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_taxi_zone_lookup"
[0m22:34:54.311445 [debug] [Thread-2  ]: Began executing node model.homework.stg_taxi_zone_lookup
[0m22:34:54.320440 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:34:55.795898 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_taxi_zone_lookup"
[0m22:34:55.797463 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:34:55.797984 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`default`.`taxi_zone_lookup_in`);

[0m22:34:56.446102 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143455904gf25foh7x8g
[0m22:34:56.446672 [debug] [Thread-2  ]: SQL status: OK in 0.648 seconds
[0m22:34:56.447796 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143455904gf25foh7x8g
[0m22:34:56.622703 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:34:56.623705 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup
            RENAME TO stg_taxi_zone_lookup__dbt_backup;
        
[0m22:34:57.292489 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 20241202143456736gmoqknhi4gg
ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
, retry times 0
[0m22:35:07.971518 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 20241202143507419gv9kub4awkr
ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
, retry times 1
[0m22:35:18.617453 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup
            RENAME TO stg_taxi_zone_lookup__dbt_backup;
        
[0m22:35:18.617974 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130211: InstanceId: 2024120214351881gfz4ym5caa
ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined

[0m22:35:18.618497 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ROLLBACK
[0m22:35:18.621107 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_taxi_zone_lookup'
[0m22:35:18.621627 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: Close
[0m22:35:18.623767 [debug] [Thread-2  ]: Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130211: InstanceId: 2024120214351881gfz4ym5caa
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
  
[0m22:35:18.624324 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A54C5AD30>]}
[0m22:35:18.624936 [error] [Thread-2  ]: 3 of 6 ERROR creating sql view model default.stg_taxi_zone_lookup .............. [[31mERROR[0m in 24.32s]
[0m22:35:18.626579 [debug] [Thread-2  ]: Finished running node model.homework.stg_taxi_zone_lookup
[0m22:35:18.627102 [debug] [Thread-2  ]: Began running node model.homework.stg_yellow_tripdata
[0m22:35:18.628150 [info ] [Thread-2  ]: 4 of 6 START sql view model default.stg_yellow_tripdata ........................ [RUN]
[0m22:35:18.629147 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_taxi_zone_lookup, now model.homework.stg_yellow_tripdata)
[0m22:35:18.630147 [debug] [Thread-2  ]: Began compiling node model.homework.stg_yellow_tripdata
[0m22:35:18.637147 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_yellow_tripdata"
[0m22:35:18.637959 [debug] [Thread-2  ]: Began executing node model.homework.stg_yellow_tripdata
[0m22:35:18.644946 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_yellow_tripdata"
[0m22:35:18.646950 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:35:18.647994 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáågenerate_surrogate_key()ÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Yellow' as service_type,
    
    -- timestamps
    cast(tpep_pickup_datetime as datetime) as pickup_datetime,
    cast(tpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    cast(ratecodeid as bigint) as ratecode_id,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(total_amount as double) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m22:35:18.648948 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:35:19.643285 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143518986guqbt1uisn2
[0m22:35:19.644438 [debug] [Thread-2  ]: SQL status: OK in 0.996 seconds
[0m22:35:19.645507 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143518986guqbt1uisn2
[0m22:35:19.918167 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:35:19.919380 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ALTER VIEW dataengine_learning.default.stg_yellow_tripdata
            RENAME TO stg_yellow_tripdata__dbt_backup;
        
[0m22:35:20.960600 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214352041gdakzr7idlr
[0m22:35:20.961689 [debug] [Thread-2  ]: SQL status: OK in 1.041 seconds
[0m22:35:20.962247 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214352041gdakzr7idlr
[0m22:35:21.193755 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:35:21.194331 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ALTER VIEW dataengine_learning.default.stg_yellow_tripdata__dbt_tmp
            RENAME TO stg_yellow_tripdata;
        
[0m22:35:22.098597 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143521311gp7onz1vq
[0m22:35:22.099135 [debug] [Thread-2  ]: SQL status: OK in 0.904 seconds
[0m22:35:22.099721 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143521311gp7onz1vq
[0m22:35:22.101970 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: COMMIT
[0m22:35:22.676900 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: Close
[0m22:35:22.677991 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90a8eb31-ffb0-4099-905b-5da3fcb86f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A53ABC160>]}
[0m22:35:22.678520 [info ] [Thread-2  ]: 4 of 6 OK created sql view model default.stg_yellow_tripdata ................... [[32mOK[0m in 4.05s]
[0m22:35:22.679645 [debug] [Thread-2  ]: Finished running node model.homework.stg_yellow_tripdata
[0m22:35:22.680664 [debug] [Thread-2  ]: Began running node model.homework.dim_zones
[0m22:35:22.681304 [info ] [Thread-2  ]: 5 of 6 SKIP relation default.dim_zones ......................................... [[33mSKIP[0m]
[0m22:35:22.682358 [debug] [Thread-2  ]: Finished running node model.homework.dim_zones
[0m22:35:22.683986 [debug] [Thread-2  ]: Began running node model.homework.fact_trips
[0m22:35:22.684537 [info ] [Thread-2  ]: 6 of 6 SKIP relation default.fact_trips ........................................ [[33mSKIP[0m]
[0m22:35:22.686162 [debug] [Thread-2  ]: Finished running node model.homework.fact_trips
[0m22:35:22.688726 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:35:22.689726 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m22:35:22.690725 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m22:35:22.691724 [debug] [MainThread]: Connection 'model.homework.stg_yellow_tripdata' was properly closed.
[0m22:35:22.692725 [info ] [MainThread]: 
[0m22:35:22.693726 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 1 minutes and 2.49 seconds (62.49s).
[0m22:35:22.696727 [debug] [MainThread]: Command end result
[0m22:35:22.765154 [info ] [MainThread]: 
[0m22:35:22.767153 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m22:35:22.767693 [info ] [MainThread]: 
[0m22:35:22.768674 [error] [MainThread]:   Runtime Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  ODPS-0130211: InstanceId: 20241202143453718gisfqckuq
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_green_tripdata__dbt_backup is already defined
  
[0m22:35:22.770669 [info ] [MainThread]: 
[0m22:35:22.770669 [error] [MainThread]:   Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130211: InstanceId: 2024120214351881gfz4ym5caa
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
  
[0m22:35:22.772671 [info ] [MainThread]: 
[0m22:35:22.773671 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=2 TOTAL=6
[0m22:35:22.776669 [debug] [MainThread]: Command `dbt run` failed at 22:35:22.776669 after 67.46 seconds
[0m22:35:22.777671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A36B47580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A370280D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013A39058C40>]}
[0m22:35:22.777671 [debug] [MainThread]: Flushing usage events
[0m22:37:46.138551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E692775B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E6BE9B610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E6BE9B520>]}


============================== 22:37:46.142549 | 26be2ebc-bb73-4977-9cb0-284bffb933ed ==============================
[0m22:37:46.142549 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:37:46.143550 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --full-refresh', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:37:47.752103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '26be2ebc-bb73-4977-9cb0-284bffb933ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E05D8D7F0>]}
[0m22:37:47.911099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '26be2ebc-bb73-4977-9cb0-284bffb933ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E04DF4EE0>]}
[0m22:37:47.913095 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:37:48.677941 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m22:37:48.954614 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:37:48.954614 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:37:49.020378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '26be2ebc-bb73-4977-9cb0-284bffb933ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E072AC490>]}
[0m22:37:49.185543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '26be2ebc-bb73-4977-9cb0-284bffb933ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E07291910>]}
[0m22:37:49.186541 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 538 macros
[0m22:37:49.186541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '26be2ebc-bb73-4977-9cb0-284bffb933ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E07295A60>]}
[0m22:37:49.188542 [info ] [MainThread]: 
[0m22:37:49.189543 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m22:37:49.196541 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m22:37:49.196541 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:37:49.768270 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m22:37:49.768912 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m22:37:49.771555 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m22:37:49.772636 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m22:37:49.773236 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:37:54.779614 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m22:37:54.786130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '26be2ebc-bb73-4977-9cb0-284bffb933ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E6BE4B430>]}
[0m22:37:54.786649 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:37:54.787697 [info ] [MainThread]: 
[0m22:37:54.790382 [debug] [Thread-2  ]: Began running node model.homework.stg_fhv_tripdata
[0m22:37:54.791385 [info ] [Thread-2  ]: 1 of 6 START sql view model default.stg_fhv_tripdata ........................... [RUN]
[0m22:37:54.792385 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.stg_fhv_tripdata'
[0m22:37:54.793386 [debug] [Thread-2  ]: Began compiling node model.homework.stg_fhv_tripdata
[0m22:37:54.821424 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_fhv_tripdata"
[0m22:37:54.822425 [debug] [Thread-2  ]: Began executing node model.homework.stg_fhv_tripdata
[0m22:37:54.868043 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_fhv_tripdata"
[0m22:37:54.968039 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:37:54.969040 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(dispatching_base_num as string) as dispatching_base_num,
    cast(affiliated_base_number as string) as affiliated_base_number,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as datetime) as pickup_datetime,
    cast(dropoff_datetime as datetime) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as BIGINT) as pickup_locationid,
    cast(dolocationid as BIGINT) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as BIGINT) as sr_flag

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime)  in (2019, 2020));

[0m22:37:54.969040 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m22:37:55.896380 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143755309gk2dt1uisn2
[0m22:37:55.896869 [debug] [Thread-2  ]: SQL status: OK in 0.927 seconds
[0m22:37:55.897401 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143755309gk2dt1uisn2
[0m22:37:56.071550 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:37:56.072569 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ALTER VIEW dataengine_learning.default.stg_fhv_tripdata
            RENAME TO stg_fhv_tripdata__dbt_backup;
        
[0m22:37:56.895498 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143756198gvlqkwjmg7
[0m22:37:56.896023 [debug] [Thread-2  ]: SQL status: OK in 0.823 seconds
[0m22:37:56.896594 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143756198gvlqkwjmg7
[0m22:37:57.086020 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:37:57.086568 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ALTER VIEW dataengine_learning.default.stg_fhv_tripdata__dbt_tmp
            RENAME TO stg_fhv_tripdata;
        
[0m22:37:58.093580 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143757194gv7w356hy5
[0m22:37:58.094104 [debug] [Thread-2  ]: SQL status: OK in 1.007 seconds
[0m22:37:58.094623 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143757194gv7w356hy5
[0m22:37:58.113228 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: COMMIT
[0m22:37:58.712153 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: Close
[0m22:37:58.713321 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26be2ebc-bb73-4977-9cb0-284bffb933ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E69646460>]}
[0m22:37:58.714518 [info ] [Thread-2  ]: 1 of 6 OK created sql view model default.stg_fhv_tripdata ...................... [[32mOK[0m in 3.92s]
[0m22:37:58.715649 [debug] [Thread-2  ]: Finished running node model.homework.stg_fhv_tripdata
[0m22:37:58.716221 [debug] [Thread-2  ]: Began running node model.homework.stg_green_tripdata
[0m22:37:58.717259 [info ] [Thread-2  ]: 2 of 6 START sql view model default.stg_green_tripdata ......................... [RUN]
[0m22:37:58.717789 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_fhv_tripdata, now model.homework.stg_green_tripdata)
[0m22:37:58.718850 [debug] [Thread-2  ]: Began compiling node model.homework.stg_green_tripdata
[0m22:37:58.725038 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_green_tripdata"
[0m22:37:58.726037 [debug] [Thread-2  ]: Began executing node model.homework.stg_green_tripdata
[0m22:37:58.732038 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:38:00.530764 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_green_tripdata"
[0m22:38:00.531761 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:38:00.532760 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as datetime) as pickup_datetime,
    cast(lpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(store_and_fwd_flag as string) as store_and_fwd_flag,
    cast(ratecodeid as bigint) as ratecode_id,
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(extra as double) as extra,
    cast(mta_tax as double) as mta_tax,
    cast(tip_amount as double) as tip_amount,
    cast(tolls_amount as double) as tolls_amount,
    cast(improvement_surcharge as double) as improvement_surcharge,
    cast(total_amount as double) as total_amount,
    cast(congestion_surcharge as double) as congestion_surcharge
    
from `dataengine_learning`.`default`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m22:38:01.334301 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143800666ggvddzkdvu2
[0m22:38:01.335278 [debug] [Thread-2  ]: SQL status: OK in 0.801 seconds
[0m22:38:01.336280 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143800666ggvddzkdvu2
[0m22:38:06.555172 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:38:06.555740 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ALTER VIEW dataengine_learning.default.stg_green_tripdata
            RENAME TO stg_green_tripdata__dbt_backup;
        
[0m22:38:08.390017 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 20241202143806664gk9zth6pgtb
ODPS-0130211:[2,23] Table or view already exists - table or view stg_green_tripdata__dbt_backup is already defined
, retry times 0
[0m22:38:19.079959 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 20241202143818501gxoli0t32
ODPS-0130211:[2,23] Table or view already exists - table or view stg_green_tripdata__dbt_backup is already defined
, retry times 1
[0m22:38:29.876671 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
ALTER VIEW dataengine_learning.default.stg_green_tripdata
            RENAME TO stg_green_tripdata__dbt_backup;
        
[0m22:38:29.877181 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130211: InstanceId: 20241202143829213gc06ulkwk22
ODPS-0130211:[2,23] Table or view already exists - table or view stg_green_tripdata__dbt_backup is already defined

[0m22:38:29.878249 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ROLLBACK
[0m22:38:29.884424 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_green_tripdata'
[0m22:38:29.884942 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: Close
[0m22:38:29.887033 [debug] [Thread-2  ]: Runtime Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  ODPS-0130211: InstanceId: 20241202143829213gc06ulkwk22
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_green_tripdata__dbt_backup is already defined
  
[0m22:38:29.887622 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26be2ebc-bb73-4977-9cb0-284bffb933ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E073FE9D0>]}
[0m22:38:29.888544 [error] [Thread-2  ]: 2 of 6 ERROR creating sql view model default.stg_green_tripdata ................ [[31mERROR[0m in 31.17s]
[0m22:38:29.889543 [debug] [Thread-2  ]: Finished running node model.homework.stg_green_tripdata
[0m22:38:29.890544 [debug] [Thread-2  ]: Began running node model.homework.stg_taxi_zone_lookup
[0m22:38:29.891544 [info ] [Thread-2  ]: 3 of 6 START sql view model default.stg_taxi_zone_lookup ....................... [RUN]
[0m22:38:29.892544 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_green_tripdata, now model.homework.stg_taxi_zone_lookup)
[0m22:38:29.892544 [debug] [Thread-2  ]: Began compiling node model.homework.stg_taxi_zone_lookup
[0m22:38:29.896544 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_taxi_zone_lookup"
[0m22:38:29.897544 [debug] [Thread-2  ]: Began executing node model.homework.stg_taxi_zone_lookup
[0m22:38:29.903543 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:38:31.390392 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_taxi_zone_lookup"
[0m22:38:31.392709 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:38:31.393772 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`default`.`taxi_zone_lookup_in`);

[0m22:38:32.038270 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143831505g3dy2fprkn1
[0m22:38:32.038827 [debug] [Thread-2  ]: SQL status: OK in 0.645 seconds
[0m22:38:32.039376 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143831505g3dy2fprkn1
[0m22:38:32.269849 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:38:32.270426 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup
            RENAME TO stg_taxi_zone_lookup__dbt_backup;
        
[0m22:38:32.942350 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 20241202143832400gmbr8ot0ozd
ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
, retry times 0
[0m22:38:43.602699 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 2024120214384361g7yqkwjmg7
ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
, retry times 1
[0m22:38:54.343438 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup
            RENAME TO stg_taxi_zone_lookup__dbt_backup;
        
[0m22:38:54.344604 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130211: InstanceId: 20241202143853723gor7tp1tjxh5
ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined

[0m22:38:54.345125 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ROLLBACK
[0m22:38:54.347776 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_taxi_zone_lookup'
[0m22:38:54.348305 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: Close
[0m22:38:54.350417 [debug] [Thread-2  ]: Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130211: InstanceId: 20241202143853723gor7tp1tjxh5
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
  
[0m22:38:54.350946 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26be2ebc-bb73-4977-9cb0-284bffb933ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E07F10D90>]}
[0m22:38:54.351995 [error] [Thread-2  ]: 3 of 6 ERROR creating sql view model default.stg_taxi_zone_lookup .............. [[31mERROR[0m in 24.46s]
[0m22:38:54.353811 [debug] [Thread-2  ]: Finished running node model.homework.stg_taxi_zone_lookup
[0m22:38:54.354389 [debug] [Thread-2  ]: Began running node model.homework.stg_yellow_tripdata
[0m22:38:54.355111 [info ] [Thread-2  ]: 4 of 6 START sql view model default.stg_yellow_tripdata ........................ [RUN]
[0m22:38:54.355639 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_taxi_zone_lookup, now model.homework.stg_yellow_tripdata)
[0m22:38:54.356193 [debug] [Thread-2  ]: Began compiling node model.homework.stg_yellow_tripdata
[0m22:38:54.363902 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_yellow_tripdata"
[0m22:38:54.364902 [debug] [Thread-2  ]: Began executing node model.homework.stg_yellow_tripdata
[0m22:38:54.372899 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:38:55.491025 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_yellow_tripdata"
[0m22:38:55.492023 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:38:55.493242 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáågenerate_surrogate_key()ÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Yellow' as service_type,
    
    -- timestamps
    cast(tpep_pickup_datetime as datetime) as pickup_datetime,
    cast(tpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    cast(ratecodeid as bigint) as ratecode_id,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(total_amount as double) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m22:38:56.289872 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143855630g4hs0smmlcr4
[0m22:38:56.290921 [debug] [Thread-2  ]: SQL status: OK in 0.797 seconds
[0m22:38:56.291433 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202143855630g4hs0smmlcr4
[0m22:38:56.472642 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:38:56.473701 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ALTER VIEW dataengine_learning.default.stg_yellow_tripdata
            RENAME TO stg_yellow_tripdata__dbt_backup;
        
[0m22:38:57.170492 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 20241202143856605guiy2fprkn1
ODPS-0130211:[2,23] Table or view already exists - table or view stg_yellow_tripdata__dbt_backup is already defined
, retry times 0
[0m22:39:07.922762 [warn ] [Thread-2  ]: MaxCompute adapter: Retry because of ODPS-0130211: InstanceId: 20241202143907298g72mzr7idlr
ODPS-0130211:[2,23] Table or view already exists - table or view stg_yellow_tripdata__dbt_backup is already defined
, retry times 1
[0m22:39:18.647074 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:
ALTER VIEW dataengine_learning.default.stg_yellow_tripdata
            RENAME TO stg_yellow_tripdata__dbt_backup;
        
[0m22:39:18.647650 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130211: InstanceId: 2024120214391847gi38lsab0e1
ODPS-0130211:[2,23] Table or view already exists - table or view stg_yellow_tripdata__dbt_backup is already defined

[0m22:39:18.648850 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ROLLBACK
[0m22:39:18.651073 [debug] [Thread-2  ]: Failed to rollback 'model.homework.stg_yellow_tripdata'
[0m22:39:18.651662 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: Close
[0m22:39:18.653356 [debug] [Thread-2  ]: Runtime Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  ODPS-0130211: InstanceId: 2024120214391847gi38lsab0e1
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_yellow_tripdata__dbt_backup is already defined
  
[0m22:39:18.654417 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26be2ebc-bb73-4977-9cb0-284bffb933ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E07F13F10>]}
[0m22:39:18.654937 [error] [Thread-2  ]: 4 of 6 ERROR creating sql view model default.stg_yellow_tripdata ............... [[31mERROR[0m in 24.30s]
[0m22:39:18.656023 [debug] [Thread-2  ]: Finished running node model.homework.stg_yellow_tripdata
[0m22:39:18.656572 [debug] [Thread-2  ]: Began running node model.homework.dim_zones
[0m22:39:18.657086 [info ] [Thread-2  ]: 5 of 6 SKIP relation default.dim_zones ......................................... [[33mSKIP[0m]
[0m22:39:18.657605 [debug] [Thread-2  ]: Finished running node model.homework.dim_zones
[0m22:39:18.659599 [debug] [Thread-2  ]: Began running node model.homework.fact_trips
[0m22:39:18.659599 [info ] [Thread-2  ]: 6 of 6 SKIP relation default.fact_trips ........................................ [[33mSKIP[0m]
[0m22:39:18.661597 [debug] [Thread-2  ]: Finished running node model.homework.fact_trips
[0m22:39:18.663596 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:39:18.664597 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m22:39:18.664597 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m22:39:18.665596 [debug] [MainThread]: Connection 'model.homework.stg_yellow_tripdata' was properly closed.
[0m22:39:18.665596 [info ] [MainThread]: 
[0m22:39:18.666599 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 1 minutes and 29.48 seconds (89.48s).
[0m22:39:18.668596 [debug] [MainThread]: Command end result
[0m22:39:18.718780 [info ] [MainThread]: 
[0m22:39:18.719782 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m22:39:18.719782 [info ] [MainThread]: 
[0m22:39:18.720781 [error] [MainThread]:   Runtime Error in model stg_green_tripdata (models\staging\stg_green_tripdata.sql)
  ODPS-0130211: InstanceId: 20241202143829213gc06ulkwk22
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_green_tripdata__dbt_backup is already defined
  
[0m22:39:18.721781 [info ] [MainThread]: 
[0m22:39:18.722782 [error] [MainThread]:   Runtime Error in model stg_taxi_zone_lookup (models\staging\stg_taxi_zone_lookup.sql)
  ODPS-0130211: InstanceId: 20241202143853723gor7tp1tjxh5
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_taxi_zone_lookup__dbt_backup is already defined
  
[0m22:39:18.723781 [info ] [MainThread]: 
[0m22:39:18.724781 [error] [MainThread]:   Runtime Error in model stg_yellow_tripdata (models\staging\stg_yellow_tripdata.sql)
  ODPS-0130211: InstanceId: 2024120214391847gi38lsab0e1
  ODPS-0130211:[2,23] Table or view already exists - table or view stg_yellow_tripdata__dbt_backup is already defined
  
[0m22:39:18.725781 [info ] [MainThread]: 
[0m22:39:18.725781 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=2 TOTAL=6
[0m22:39:18.727781 [debug] [MainThread]: Command `dbt run` failed at 22:39:18.727781 after 92.65 seconds
[0m22:39:18.729781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E692775B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E07291910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014E6B87D700>]}
[0m22:39:18.730783 [debug] [MainThread]: Flushing usage events
[0m22:46:24.593109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D2A8075B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D2D42B610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D2D42B520>]}


============================== 22:46:24.597531 | f9a75814-bbc6-4d7b-9892-5e3772107c3a ==============================
[0m22:46:24.597531 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:46:24.599121 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:46:26.243329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D4731D7F0>]}
[0m22:46:26.374328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D46384EE0>]}
[0m22:46:26.375328 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:46:27.164783 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m22:46:27.441038 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:46:27.442042 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:46:27.510047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D4883C490>]}
[0m22:46:27.682767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D48821910>]}
[0m22:46:27.683768 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 538 macros
[0m22:46:27.684889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D48829A60>]}
[0m22:46:27.686838 [info ] [MainThread]: 
[0m22:46:27.687837 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m22:46:27.695840 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m22:46:27.695840 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:46:28.311928 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m22:46:28.312453 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m22:46:28.315670 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m22:46:28.316733 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m22:46:28.317251 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:46:32.862376 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m22:46:32.868066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D2D3DC430>]}
[0m22:46:32.870067 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:46:32.871067 [info ] [MainThread]: 
[0m22:46:32.874067 [debug] [Thread-2  ]: Began running node model.homework.stg_fhv_tripdata
[0m22:46:32.875068 [info ] [Thread-2  ]: 1 of 6 START sql view model default.stg_fhv_tripdata ........................... [RUN]
[0m22:46:32.876067 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.stg_fhv_tripdata'
[0m22:46:32.876067 [debug] [Thread-2  ]: Began compiling node model.homework.stg_fhv_tripdata
[0m22:46:32.906068 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_fhv_tripdata"
[0m22:46:32.907069 [debug] [Thread-2  ]: Began executing node model.homework.stg_fhv_tripdata
[0m22:46:32.956068 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_fhv_tripdata"
[0m22:46:33.054669 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:46:33.055707 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_fhv_tripdata__dbt_tmp` AS (-- models/staging/stg_fhv_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(dispatching_base_num as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(dispatching_base_num as string) as dispatching_base_num,
    cast(affiliated_base_number as string) as affiliated_base_number,
    'FHV' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(pickup_datetime as datetime) as pickup_datetime,
    cast(dropoff_datetime as datetime) as dropoff_datetime,
    
    -- ‰ΩçÁΩÆ‰ø°ÊÅØ
    cast(pulocationid as BIGINT) as pickup_locationid,
    cast(dolocationid as BIGINT) as dropoff_locationid,
    
    -- FHVÁâπÊúâ‰ø°ÊÅØ
    cast(sr_flag as BIGINT) as sr_flag

from `dataengine_learning`.`default`.`fhv_taxi_trips_in`
where extract(year from pickup_datetime)  in (2019, 2020));

[0m22:46:33.055707 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m22:46:34.102493 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144633418gg5aulkwk22
[0m22:46:34.103154 [debug] [Thread-2  ]: SQL status: OK in 1.047 seconds
[0m22:46:34.103669 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144633418gg5aulkwk22
[0m22:46:34.252050 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:46:34.252614 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ALTER VIEW dataengine_learning.default.stg_fhv_tripdata
            RENAME TO stg_fhv_tripdata__dbt_backup;
        
[0m22:46:35.326561 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144634385goy0dgn0ozd
[0m22:46:35.327603 [debug] [Thread-2  ]: SQL status: OK in 1.074 seconds
[0m22:46:35.328126 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144634385goy0dgn0ozd
[0m22:46:35.518060 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_fhv_tripdata"
[0m22:46:35.518640 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: ALTER VIEW dataengine_learning.default.stg_fhv_tripdata__dbt_tmp
            RENAME TO stg_fhv_tripdata;
        
[0m22:46:36.521159 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144635663gnge1aakjpi
[0m22:46:36.521724 [debug] [Thread-2  ]: SQL status: OK in 1.002 seconds
[0m22:46:36.522245 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144635663gnge1aakjpi
[0m22:46:36.541783 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: COMMIT
[0m22:46:37.364079 [debug] [Thread-2  ]: On model.homework.stg_fhv_tripdata: Close
[0m22:46:37.365725 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D4898C670>]}
[0m22:46:37.366259 [info ] [Thread-2  ]: 1 of 6 OK created sql view model default.stg_fhv_tripdata ...................... [[32mOK[0m in 4.49s]
[0m22:46:37.367905 [debug] [Thread-2  ]: Finished running node model.homework.stg_fhv_tripdata
[0m22:46:37.368569 [debug] [Thread-2  ]: Began running node model.homework.stg_green_tripdata
[0m22:46:37.369138 [info ] [Thread-2  ]: 2 of 6 START sql view model default.stg_green_tripdata ......................... [RUN]
[0m22:46:37.370239 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_fhv_tripdata, now model.homework.stg_green_tripdata)
[0m22:46:37.370799 [debug] [Thread-2  ]: Began compiling node model.homework.stg_green_tripdata
[0m22:46:37.377041 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_green_tripdata"
[0m22:46:37.378963 [debug] [Thread-2  ]: Began executing node model.homework.stg_green_tripdata
[0m22:46:37.385963 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:46:38.233519 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_green_tripdata"
[0m22:46:38.234578 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:46:38.235775 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_green_tripdata__dbt_tmp` AS (-- models/staging/stg_green_tripdata.sql


select
    -- Ê†áËØÜÁ¨¶
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(lpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Green' as service_type,
    
    -- Êó∂Èó¥Êà≥
    cast(lpep_pickup_datetime as datetime) as pickup_datetime,
    cast(lpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(store_and_fwd_flag as string) as store_and_fwd_flag,
    cast(ratecodeid as bigint) as ratecode_id,
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(extra as double) as extra,
    cast(mta_tax as double) as mta_tax,
    cast(tip_amount as double) as tip_amount,
    cast(tolls_amount as double) as tolls_amount,
    cast(improvement_surcharge as double) as improvement_surcharge,
    cast(total_amount as double) as total_amount,
    cast(congestion_surcharge as double) as congestion_surcharge
    
from `dataengine_learning`.`default`.`green_taxi_trips_in`
where extract(year from lpep_pickup_datetime) in (2019, 2020));

[0m22:46:39.017000 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144638360gv6aulkwk22
[0m22:46:39.017000 [debug] [Thread-2  ]: SQL status: OK in 0.781 seconds
[0m22:46:39.018187 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144638360gv6aulkwk22
[0m22:46:39.231923 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:46:39.232442 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ALTER VIEW dataengine_learning.default.stg_green_tripdata
            RENAME TO stg_green_tripdata__dbt_backup;
        
[0m22:46:40.192579 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144639357gz2ip6o5l22
[0m22:46:40.193095 [debug] [Thread-2  ]: SQL status: OK in 0.960 seconds
[0m22:46:40.193631 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144639357gz2ip6o5l22
[0m22:46:40.548533 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_green_tripdata"
[0m22:46:40.549113 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: ALTER VIEW dataengine_learning.default.stg_green_tripdata__dbt_tmp
            RENAME TO stg_green_tripdata;
        
[0m22:46:41.522797 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144640683gwvowfbdgg9
[0m22:46:41.523309 [debug] [Thread-2  ]: SQL status: OK in 0.973 seconds
[0m22:46:41.523895 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144640683gwvowfbdgg9
[0m22:46:41.526121 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: COMMIT
[0m22:46:42.089964 [debug] [Thread-2  ]: On model.homework.stg_green_tripdata: Close
[0m22:46:42.090507 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D4898C370>]}
[0m22:46:42.091553 [info ] [Thread-2  ]: 2 of 6 OK created sql view model default.stg_green_tripdata .................... [[32mOK[0m in 4.72s]
[0m22:46:42.092702 [debug] [Thread-2  ]: Finished running node model.homework.stg_green_tripdata
[0m22:46:42.093217 [debug] [Thread-2  ]: Began running node model.homework.stg_taxi_zone_lookup
[0m22:46:42.093914 [info ] [Thread-2  ]: 3 of 6 START sql view model default.stg_taxi_zone_lookup ....................... [RUN]
[0m22:46:42.095527 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_green_tripdata, now model.homework.stg_taxi_zone_lookup)
[0m22:46:42.096136 [debug] [Thread-2  ]: Began compiling node model.homework.stg_taxi_zone_lookup
[0m22:46:42.100076 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_taxi_zone_lookup"
[0m22:46:42.101146 [debug] [Thread-2  ]: Began executing node model.homework.stg_taxi_zone_lookup
[0m22:46:42.110062 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:46:42.891575 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_taxi_zone_lookup"
[0m22:46:42.892703 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:46:42.893221 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_taxi_zone_lookup__dbt_tmp` AS (-- models/staging/stg_taxi_zone_lookup.sql


select
    locationid,
    borough,
    zone,
    replace(service_zone, 'Boro', 'Green') as service_zone
from `dataengine_learning`.`default`.`taxi_zone_lookup_in`);

[0m22:46:43.751759 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214464331g2wxonrddlr
[0m22:46:43.752282 [debug] [Thread-2  ]: SQL status: OK in 0.858 seconds
[0m22:46:43.752938 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214464331g2wxonrddlr
[0m22:46:43.926835 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:46:43.927406 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup
            RENAME TO stg_taxi_zone_lookup__dbt_backup;
        
[0m22:46:44.815914 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214464464goue9arh6kf
[0m22:46:44.817027 [debug] [Thread-2  ]: SQL status: OK in 0.889 seconds
[0m22:46:44.817593 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 2024120214464464goue9arh6kf
[0m22:46:45.011244 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_taxi_zone_lookup"
[0m22:46:45.012289 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: ALTER VIEW dataengine_learning.default.stg_taxi_zone_lookup__dbt_tmp
            RENAME TO stg_taxi_zone_lookup;
        
[0m22:46:46.034656 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144645166g72qzr7idlr
[0m22:46:46.035256 [debug] [Thread-2  ]: SQL status: OK in 1.022 seconds
[0m22:46:46.035876 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144645166g72qzr7idlr
[0m22:46:46.038105 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: COMMIT
[0m22:46:46.601614 [debug] [Thread-2  ]: On model.homework.stg_taxi_zone_lookup: Close
[0m22:46:46.602707 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D2CF02670>]}
[0m22:46:46.602917 [info ] [Thread-2  ]: 3 of 6 OK created sql view model default.stg_taxi_zone_lookup .................. [[32mOK[0m in 4.51s]
[0m22:46:46.604642 [debug] [Thread-2  ]: Finished running node model.homework.stg_taxi_zone_lookup
[0m22:46:46.605406 [debug] [Thread-2  ]: Began running node model.homework.stg_yellow_tripdata
[0m22:46:46.606002 [info ] [Thread-2  ]: 4 of 6 START sql view model default.stg_yellow_tripdata ........................ [RUN]
[0m22:46:46.607144 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_taxi_zone_lookup, now model.homework.stg_yellow_tripdata)
[0m22:46:46.607667 [debug] [Thread-2  ]: Began compiling node model.homework.stg_yellow_tripdata
[0m22:46:46.615935 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.stg_yellow_tripdata"
[0m22:46:46.616974 [debug] [Thread-2  ]: Began executing node model.homework.stg_yellow_tripdata
[0m22:46:46.626933 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:46:47.504461 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.stg_yellow_tripdata"
[0m22:46:47.505508 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:46:47.506069 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: CREATE OR REPLACE VIEW `dataengine_learning`.`default`.`stg_yellow_tripdata__dbt_tmp` AS (

select 
    -- Ê†áËØÜÁ¨¶ÔºåËøôÈáågenerate_surrogate_key()ÊòØ‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑÂÆèÔºåÈÄöËøáÂØπÂá†‰∏™ÂèÇÊï∞ÁöÑÂìàÂ∏åÁîüÊàê‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑÊ†áËØÜÁ¨¶Ôºå‰øùËØÅ‰∫ÜÊï∞ÊçÆÁöÑÂîØ‰∏ÄÊÄßÔºåÂõ†‰∏∫ËøôÈáåÊï∞ÊçÆÈõÜÁöÑvendoridÂèØ‰ª•ÊòØÈáçÂ§çÁöÑ
    case when concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')) = NULL
        then md5('')
    else
        md5(concat(coalesce(cast(vendorid as string), '_dbt_utils_surrogate_key_null_'), '-', coalesce(cast(tpep_pickup_datetime as string), '_dbt_utils_surrogate_key_null_')))
    end as tripid,
    cast(vendorid as bigint) as vendor_id,
    'Yellow' as service_type,
    
    -- timestamps
    cast(tpep_pickup_datetime as datetime) as pickup_datetime,
    cast(tpep_dropoff_datetime as datetime) as dropoff_datetime,
    
    -- trip info
    cast(passenger_count as bigint) as passenger_count,
    cast(trip_distance as double) as trip_distance,
    cast(ratecodeid as bigint) as ratecode_id,
    
    -- location info
    cast(pulocationid as bigint) as pickup_locationid,
    cast(dolocationid as bigint) as dropoff_locationid,
    
    -- payment info
    cast(payment_type as bigint) as payment_type,
    cast(fare_amount as double) as fare_amount,
    cast(total_amount as double) as total_amount
from `dataengine_learning`.`default`.`yellow_taxi_trips_in`
where extract(year from tpep_pickup_datetime) in (2019, 2020));

[0m22:46:48.314146 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144647652gsje1aakjpi
[0m22:46:48.315363 [debug] [Thread-2  ]: SQL status: OK in 0.808 seconds
[0m22:46:48.315881 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144647652gsje1aakjpi
[0m22:46:48.506880 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:46:48.507988 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ALTER VIEW dataengine_learning.default.stg_yellow_tripdata
            RENAME TO stg_yellow_tripdata__dbt_backup;
        
[0m22:46:49.566595 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144648628g76wpttrpks
[0m22:46:49.567109 [debug] [Thread-2  ]: SQL status: OK in 1.058 seconds
[0m22:46:49.567816 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144648628g76wpttrpks
[0m22:46:49.784517 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.stg_yellow_tripdata"
[0m22:46:49.785267 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: ALTER VIEW dataengine_learning.default.stg_yellow_tripdata__dbt_tmp
            RENAME TO stg_yellow_tripdata;
        
[0m22:46:50.685875 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144649916gixh1yewsod
[0m22:46:50.686418 [debug] [Thread-2  ]: SQL status: OK in 0.901 seconds
[0m22:46:50.687485 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144649916gixh1yewsod
[0m22:46:50.689699 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: COMMIT
[0m22:46:51.284011 [debug] [Thread-2  ]: On model.homework.stg_yellow_tripdata: Close
[0m22:46:51.285056 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D48985D00>]}
[0m22:46:51.285679 [info ] [Thread-2  ]: 4 of 6 OK created sql view model default.stg_yellow_tripdata ................... [[32mOK[0m in 4.68s]
[0m22:46:51.287284 [debug] [Thread-2  ]: Finished running node model.homework.stg_yellow_tripdata
[0m22:46:51.287825 [debug] [Thread-2  ]: Began running node model.homework.dim_zones
[0m22:46:51.288921 [info ] [Thread-2  ]: 5 of 6 START sql table model default.dim_zones ................................. [RUN]
[0m22:46:51.289996 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.stg_yellow_tripdata, now model.homework.dim_zones)
[0m22:46:51.290558 [debug] [Thread-2  ]: Began compiling node model.homework.dim_zones
[0m22:46:51.294302 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.dim_zones"
[0m22:46:51.295812 [debug] [Thread-2  ]: Began executing node model.homework.dim_zones
[0m22:46:51.334450 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.dim_zones"
[0m22:46:51.337451 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.dim_zones"
[0m22:46:51.337451 [debug] [Thread-2  ]: On model.homework.dim_zones: 
  
    CREATE TABLE IF NOT EXISTS `dataengine_learning`.`default`.`dim_zones__dbt_tmp`
    
    AS (
      -- models/core/dim_zones.sql Áª¥Â∫¶Ë°®Á§∫‰æã


select 
    locationid,          -- Áª¥Â∫¶‰∏ªÈîÆ
    borough,            -- ÊèèËø∞ÊÄßÂ±ûÊÄßÔºöË°åÊîøÂå∫
    zone,              -- ÊèèËø∞ÊÄßÂ±ûÊÄßÔºöÂÖ∑‰ΩìÂå∫Âüü
    service_zone       -- ÊèèËø∞ÊÄßÂ±ûÊÄßÔºöÊúçÂä°Âå∫ÂüüÁ±ªÂûã
from `dataengine_learning`.`default`.`stg_taxi_zone_lookup`
    )
    ;

  
[0m22:46:51.338576 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:46:56.310925 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144651704ghy91kd1f3k
[0m22:46:56.311442 [debug] [Thread-2  ]: SQL status: OK in 4.973 seconds
[0m22:46:56.312459 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144651704ghy91kd1f3k
[0m22:46:56.481728 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.dim_zones"
[0m22:46:56.482247 [debug] [Thread-2  ]: On model.homework.dim_zones: ALTER TABLE `dataengine_learning`.`default`.`dim_zones`
            RENAME TO dim_zones__dbt_backup;
        
[0m22:46:57.497578 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144656602g7iay3uwhm1
[0m22:46:57.498110 [debug] [Thread-2  ]: SQL status: OK in 1.015 seconds
[0m22:46:57.498635 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144656602g7iay3uwhm1
[0m22:46:57.812450 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.dim_zones"
[0m22:46:57.812970 [debug] [Thread-2  ]: On model.homework.dim_zones: ALTER TABLE `dataengine_learning`.`default`.`dim_zones__dbt_tmp`
            RENAME TO dim_zones;
        
[0m22:46:59.093499 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144657966gtrocliahcr4
[0m22:46:59.094020 [debug] [Thread-2  ]: SQL status: OK in 1.280 seconds
[0m22:46:59.094542 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202144657966gtrocliahcr4
[0m22:46:59.100312 [debug] [Thread-2  ]: On model.homework.dim_zones: COMMIT
[0m22:46:59.777656 [debug] [Thread-2  ]: On model.homework.dim_zones: Close
[0m22:46:59.778230 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D2CF3A310>]}
[0m22:46:59.778756 [info ] [Thread-2  ]: 5 of 6 OK created sql table model default.dim_zones ............................ [[32mOK[0m in 8.49s]
[0m22:46:59.779801 [debug] [Thread-2  ]: Finished running node model.homework.dim_zones
[0m22:46:59.780843 [debug] [Thread-2  ]: Began running node model.homework.fact_trips
[0m22:46:59.782093 [info ] [Thread-2  ]: 6 of 6 START sql table model default.fact_trips ................................ [RUN]
[0m22:46:59.783157 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.homework.dim_zones, now model.homework.fact_trips)
[0m22:46:59.784236 [debug] [Thread-2  ]: Began compiling node model.homework.fact_trips
[0m22:46:59.789997 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.fact_trips"
[0m22:46:59.790996 [debug] [Thread-2  ]: Began executing node model.homework.fact_trips
[0m22:46:59.798998 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.fact_trips"
[0m22:46:59.800997 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.fact_trips"
[0m22:46:59.800997 [debug] [Thread-2  ]: On model.homework.fact_trips: 
  
    CREATE TABLE IF NOT EXISTS `dataengine_learning`.`default`.`fact_trips__dbt_tmp`
    
    AS (
      

-- 1. È¶ñÂÖàÂ§ÑÁêÜÁªøËâ≤Âá∫ÁßüËΩ¶Êï∞ÊçÆÔºåref ÂáΩÊï∞Áî®‰∫éÂºïÁî®ÂÖ∂‰ªñÊ®°ÂûãÔºåÂπ∂ÁÆ°ÁêÜÊ®°Âûã‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ª„ÄÇ
--ËøôÈáåÁöÑ WITH ... AS ÁªìÊûÑÊòØ SQL ‰∏≠ÁöÑÂÖ¨Áî®Ë°®Ë°®ËææÂºèÔºàCommon Table ExpressionÔºåÁÆÄÁß∞ CTEÔºâÔºåÂÆÉÂÖÅËÆ∏Âú®‰∏Ä‰∏™Êü•ËØ¢‰∏≠ÂÆö‰πâ‰∏¥Êó∂ÁªìÊûúÈõÜÔºåËøô‰∫õÁªìÊûúÈõÜÂèØ‰ª•Âú®ÂêéÁª≠ÁöÑÊü•ËØ¢‰∏≠ÂºïÁî®„ÄÇ
with green_trips as (
    select 
        *,
        'Green' as service_type 
    from `dataengine_learning`.`default`.`stg_green_tripdata`
),

-- 2. Â§ÑÁêÜÈªÑËâ≤Âá∫ÁßüËΩ¶Êï∞ÊçÆ
yellow_trips as (
    select 
        *,
        'Yellow' as service_type
    from `dataengine_learning`.`default`.`stg_yellow_tripdata`
),

-- 3. ÂêàÂπ∂‰∏§ÁßçÊï∞ÊçÆÔºåunion all ÊòØ SQL ‰∏≠ÁöÑÈõÜÂêàËøêÁÆóÁ¨¶ÔºåÁî®‰∫éÂêàÂπ∂‰∏§‰∏™ÊàñÂ§ö‰∏™Êü•ËØ¢ÁöÑÁªìÊûúÈõÜÔºåunion all ‰ºö‰øùÁïôÈáçÂ§çÁöÑË°åÔºåËÄå union ‰ºöÂéªÈô§ÈáçÂ§çÁöÑË°å„ÄÇ
trips_unioned as (
    select * from green_trips
    union all
    select * from yellow_trips
),

-- 4. ÂÖ≥ËÅîÁª¥Â∫¶‰ø°ÊÅØÔºåINNER JOIN Áî®‰∫éËøûÊé•‰∏§‰∏™Ë°®ÔºåËÄå ON Â≠êÂè•Áî®‰∫éÊåáÂÆöËøûÊé•Êù°‰ª∂„ÄÇ
final as (
    select 
        trips_unioned.*,
        pickup_zone.borough as pickup_borough,
        pickup_zone.zone as pickup_zone,
        dropoff_zone.borough as dropoff_borough,
        dropoff_zone.zone as dropoff_zone
    from trips_unioned
    inner join `dataengine_learning`.`default`.`dim_zones` as pickup_zone
        on trips_unioned.pickup_locationid = pickup_zone.locationid
    inner join `dataengine_learning`.`default`.`dim_zones` as dropoff_zone
        on trips_unioned.dropoff_locationid = dropoff_zone.locationid
)

select * from final
    )
    ;

  
[0m22:46:59.801997 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m22:47:01.037903 [error] [Thread-2  ]: MaxCompute adapter: http://logview.odps.aliyun.com/logview/?h=https://service.cn-hangzhou.maxcompute.aliyun.com/api&p=dataengine_learning&i=20241202144700165g81i1yewsod&token=RHB6aGU3bmhIMVpJOUp5L0pZTW5vdG9XUUMwPSxPRFBTX09CTzpwNF8yMDMyMzQxMzEyMjczOTkwNjAsMTczNTc0MjgyMSx7IlN0YXRlbWVudCI6W3siQWN0aW9uIjpbIm9kcHM6UmVhZCJdLCJFZmZlY3QiOiJBbGxvdyIsIlJlc291cmNlIjpbImFjczpvZHBzOio6cHJvamVjdHMvZGF0YWVuZ2luZV9sZWFybmluZy9pbnN0YW5jZXMvMjAyNDEyMDIxNDQ3MDAxNjVnODFpMXlld3NvZCJdfV0sIlZlcnNpb24iOiIxIn0=
[0m22:47:01.039669 [debug] [Thread-2  ]: MaxCompute adapter: Error while running:

  
    CREATE TABLE IF NOT EXISTS `dataengine_learning`.`default`.`fact_trips__dbt_tmp`
    
    AS (
      

-- 1. È¶ñÂÖàÂ§ÑÁêÜÁªøËâ≤Âá∫ÁßüËΩ¶Êï∞ÊçÆÔºåref ÂáΩÊï∞Áî®‰∫éÂºïÁî®ÂÖ∂‰ªñÊ®°ÂûãÔºåÂπ∂ÁÆ°ÁêÜÊ®°Âûã‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ª„ÄÇ
--ËøôÈáåÁöÑ WITH ... AS ÁªìÊûÑÊòØ SQL ‰∏≠ÁöÑÂÖ¨Áî®Ë°®Ë°®ËææÂºèÔºàCommon Table ExpressionÔºåÁÆÄÁß∞ CTEÔºâÔºåÂÆÉÂÖÅËÆ∏Âú®‰∏Ä‰∏™Êü•ËØ¢‰∏≠ÂÆö‰πâ‰∏¥Êó∂ÁªìÊûúÈõÜÔºåËøô‰∫õÁªìÊûúÈõÜÂèØ‰ª•Âú®ÂêéÁª≠ÁöÑÊü•ËØ¢‰∏≠ÂºïÁî®„ÄÇ
with green_trips as (
    select 
        *,
        'Green' as service_type 
    from `dataengine_learning`.`default`.`stg_green_tripdata`
),

-- 2. Â§ÑÁêÜÈªÑËâ≤Âá∫ÁßüËΩ¶Êï∞ÊçÆ
yellow_trips as (
    select 
        *,
        'Yellow' as service_type
    from `dataengine_learning`.`default`.`stg_yellow_tripdata`
),

-- 3. ÂêàÂπ∂‰∏§ÁßçÊï∞ÊçÆÔºåunion all ÊòØ SQL ‰∏≠ÁöÑÈõÜÂêàËøêÁÆóÁ¨¶ÔºåÁî®‰∫éÂêàÂπ∂‰∏§‰∏™ÊàñÂ§ö‰∏™Êü•ËØ¢ÁöÑÁªìÊûúÈõÜÔºåunion all ‰ºö‰øùÁïôÈáçÂ§çÁöÑË°åÔºåËÄå union ‰ºöÂéªÈô§ÈáçÂ§çÁöÑË°å„ÄÇ
trips_unioned as (
    select * from green_trips
    union all
    select * from yellow_trips
),

-- 4. ÂÖ≥ËÅîÁª¥Â∫¶‰ø°ÊÅØÔºåINNER JOIN Áî®‰∫éËøûÊé•‰∏§‰∏™Ë°®ÔºåËÄå ON Â≠êÂè•Áî®‰∫éÊåáÂÆöËøûÊé•Êù°‰ª∂„ÄÇ
final as (
    select 
        trips_unioned.*,
        pickup_zone.borough as pickup_borough,
        pickup_zone.zone as pickup_zone,
        dropoff_zone.borough as dropoff_borough,
        dropoff_zone.zone as dropoff_zone
    from trips_unioned
    inner join `dataengine_learning`.`default`.`dim_zones` as pickup_zone
        on trips_unioned.pickup_locationid = pickup_zone.locationid
    inner join `dataengine_learning`.`default`.`dim_zones` as dropoff_zone
        on trips_unioned.dropoff_locationid = dropoff_zone.locationid
)

select * from final
    )
    ;

  
[0m22:47:01.040263 [debug] [Thread-2  ]: MaxCompute adapter: ODPS-0130071: InstanceId: 20241202144700165g81i1yewsod
ODPS-0130071:[8,6] Semantic analysis exception - column reference @cte_1733150820297.service_type is ambiguous
ODPS-0130071:[16,1] Semantic analysis exception - column reference @cte_1733150820297.service_type is ambiguous
ODPS-0130071:[25,19] Semantic analysis exception - column reference green_trips.service_type is ambiguous
ODPS-0130071:[27,19] Semantic analysis exception - column reference yellow_trips.service_type is ambiguous
ODPS-0130241:[27,5] Illegal union operation - type mismatch for UNION, left has 21 columns while right has 14 columns
ODPS-0130071:[24,1] Semantic analysis exception - column reference @cte_1733150820297.service_type is ambiguous
ODPS-0130071:[38,10] Semantic analysis exception - column reference trips_unioned.service_type is ambiguous
ODPS-0130071:[31,1] Semantic analysis exception - column reference @cte_1733150820298.service_type is ambiguous
ODPS-0130071:[45,15] Semantic analysis exception - column reference final.service_type is ambiguous
ODPS-0130071:[45,8] Semantic analysis exception - column repeated in creation: service_type

[0m22:47:01.041235 [debug] [Thread-2  ]: On model.homework.fact_trips: ROLLBACK
[0m22:47:01.048233 [debug] [Thread-2  ]: Failed to rollback 'model.homework.fact_trips'
[0m22:47:01.049330 [debug] [Thread-2  ]: On model.homework.fact_trips: Close
[0m22:47:01.052319 [debug] [Thread-2  ]: Runtime Error in model fact_trips (models\core\fact_trips.sql)
  ODPS-0130071: InstanceId: 20241202144700165g81i1yewsod
  ODPS-0130071:[8,6] Semantic analysis exception - column reference @cte_1733150820297.service_type is ambiguous
  ODPS-0130071:[16,1] Semantic analysis exception - column reference @cte_1733150820297.service_type is ambiguous
  ODPS-0130071:[25,19] Semantic analysis exception - column reference green_trips.service_type is ambiguous
  ODPS-0130071:[27,19] Semantic analysis exception - column reference yellow_trips.service_type is ambiguous
  ODPS-0130241:[27,5] Illegal union operation - type mismatch for UNION, left has 21 columns while right has 14 columns
  ODPS-0130071:[24,1] Semantic analysis exception - column reference @cte_1733150820297.service_type is ambiguous
  ODPS-0130071:[38,10] Semantic analysis exception - column reference trips_unioned.service_type is ambiguous
  ODPS-0130071:[31,1] Semantic analysis exception - column reference @cte_1733150820298.service_type is ambiguous
  ODPS-0130071:[45,15] Semantic analysis exception - column reference final.service_type is ambiguous
  ODPS-0130071:[45,8] Semantic analysis exception - column repeated in creation: service_type
  
[0m22:47:01.053319 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9a75814-bbc6-4d7b-9892-5e3772107c3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D2CFFF460>]}
[0m22:47:01.054320 [error] [Thread-2  ]: 6 of 6 ERROR creating sql table model default.fact_trips ....................... [[31mERROR[0m in 1.27s]
[0m22:47:01.056318 [debug] [Thread-2  ]: Finished running node model.homework.fact_trips
[0m22:47:01.059340 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:47:01.059340 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m22:47:01.060328 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m22:47:01.061329 [debug] [MainThread]: Connection 'model.homework.fact_trips' was properly closed.
[0m22:47:01.061329 [info ] [MainThread]: 
[0m22:47:01.062328 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 0 minutes and 33.37 seconds (33.37s).
[0m22:47:01.064332 [debug] [MainThread]: Command end result
[0m22:47:01.116330 [info ] [MainThread]: 
[0m22:47:01.117330 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:47:01.118329 [info ] [MainThread]: 
[0m22:47:01.120446 [error] [MainThread]:   Runtime Error in model fact_trips (models\core\fact_trips.sql)
  ODPS-0130071: InstanceId: 20241202144700165g81i1yewsod
  ODPS-0130071:[8,6] Semantic analysis exception - column reference @cte_1733150820297.service_type is ambiguous
  ODPS-0130071:[16,1] Semantic analysis exception - column reference @cte_1733150820297.service_type is ambiguous
  ODPS-0130071:[25,19] Semantic analysis exception - column reference green_trips.service_type is ambiguous
  ODPS-0130071:[27,19] Semantic analysis exception - column reference yellow_trips.service_type is ambiguous
  ODPS-0130241:[27,5] Illegal union operation - type mismatch for UNION, left has 21 columns while right has 14 columns
  ODPS-0130071:[24,1] Semantic analysis exception - column reference @cte_1733150820297.service_type is ambiguous
  ODPS-0130071:[38,10] Semantic analysis exception - column reference trips_unioned.service_type is ambiguous
  ODPS-0130071:[31,1] Semantic analysis exception - column reference @cte_1733150820298.service_type is ambiguous
  ODPS-0130071:[45,15] Semantic analysis exception - column reference final.service_type is ambiguous
  ODPS-0130071:[45,8] Semantic analysis exception - column repeated in creation: service_type
  
[0m22:47:01.123963 [info ] [MainThread]: 
[0m22:47:01.124963 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m22:47:01.126963 [debug] [MainThread]: Command `dbt run` failed at 22:47:01.125964 after 36.60 seconds
[0m22:47:01.126963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D2A8075B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D48821910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D2CE0D700>]}
[0m22:47:01.128013 [debug] [MainThread]: Flushing usage events
[0m22:49:59.087446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181E93665B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181EBF7B6A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181EBF7B5B0>]}


============================== 22:49:59.092445 | 1d277241-d40e-4235-af67-9e942ab0c474 ==============================
[0m22:49:59.092445 [info ] [MainThread]: Running with dbt=1.8.9
[0m22:49:59.092445 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'E:\\Á®ãÂ∫è\\data-engineering-zoomcamp-main\\04-analytics-engineering\\homework\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Êù∞Âì•Â∏¶Â∏ÖÊØî\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run -m fact_trips --full-refresh', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:50:00.725519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1d277241-d40e-4235-af67-9e942ab0c474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181EBE0A700>]}
[0m22:50:00.858333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1d277241-d40e-4235-af67-9e942ab0c474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018185EB3340>]}
[0m22:50:00.859335 [info ] [MainThread]: Registered adapter: maxcompute=1.8.0-alpha8
[0m22:50:01.634811 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m22:50:01.916238 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:50:01.916238 [debug] [MainThread]: Partial parsing: updated file: homework://models\core\fact_trips.sql
[0m22:50:02.219756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1d277241-d40e-4235-af67-9e942ab0c474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181875057C0>]}
[0m22:50:02.392415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1d277241-d40e-4235-af67-9e942ab0c474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181874F4B20>]}
[0m22:50:02.392415 [info ] [MainThread]: Found 6 models, 12 data tests, 4 sources, 538 macros
[0m22:50:02.393417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1d277241-d40e-4235-af67-9e942ab0c474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181874F5670>]}
[0m22:50:02.397421 [info ] [MainThread]: 
[0m22:50:02.399424 [debug] [MainThread]: Acquiring new maxcompute connection 'master'
[0m22:50:02.402417 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning'
[0m22:50:02.403419 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:50:03.056738 [debug] [ThreadPool]: MaxCompute adapter: list_schemas: ['default', 'max_dbt']
[0m22:50:03.057351 [debug] [ThreadPool]: On list_dataengine_learning: Close
[0m22:50:03.064416 [debug] [ThreadPool]: Acquiring new maxcompute connection 'list_dataengine_learning_default'
[0m22:50:03.065458 [debug] [ThreadPool]: MaxCompute adapter: list_relations_without_caching: `dataengine_learning`.`default`
[0m22:50:03.065970 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:50:08.523596 [debug] [ThreadPool]: On list_dataengine_learning_default: Close
[0m22:50:08.529882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1d277241-d40e-4235-af67-9e942ab0c474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018185E8C910>]}
[0m22:50:08.531452 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:50:08.532492 [info ] [MainThread]: 
[0m22:50:08.535597 [debug] [Thread-2  ]: Began running node model.homework.fact_trips
[0m22:50:08.536598 [info ] [Thread-2  ]: 1 of 1 START sql table model default.fact_trips ................................ [RUN]
[0m22:50:08.537596 [debug] [Thread-2  ]: Acquiring new maxcompute connection 'model.homework.fact_trips'
[0m22:50:08.538600 [debug] [Thread-2  ]: Began compiling node model.homework.fact_trips
[0m22:50:08.551594 [debug] [Thread-2  ]: Writing injected SQL for node "model.homework.fact_trips"
[0m22:50:08.553598 [debug] [Thread-2  ]: Began executing node model.homework.fact_trips
[0m22:50:08.610594 [debug] [Thread-2  ]: Writing runtime sql for node "model.homework.fact_trips"
[0m22:50:08.725597 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.fact_trips"
[0m22:50:08.726596 [debug] [Thread-2  ]: On model.homework.fact_trips: 
  
    CREATE TABLE IF NOT EXISTS `dataengine_learning`.`default`.`fact_trips__dbt_tmp`
    
    AS (
      

-- 1. È¶ñÂÖàÂ§ÑÁêÜÁªøËâ≤Âá∫ÁßüËΩ¶Êï∞ÊçÆÔºåref ÂáΩÊï∞Áî®‰∫éÂºïÁî®ÂÖ∂‰ªñÊ®°ÂûãÔºåÂπ∂ÁÆ°ÁêÜÊ®°Âûã‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ª„ÄÇ
--ËøôÈáåÁöÑ WITH ... AS ÁªìÊûÑÊòØ SQL ‰∏≠ÁöÑÂÖ¨Áî®Ë°®Ë°®ËææÂºèÔºàCommon Table ExpressionÔºåÁÆÄÁß∞ CTEÔºâÔºåÂÆÉÂÖÅËÆ∏Âú®‰∏Ä‰∏™Êü•ËØ¢‰∏≠ÂÆö‰πâ‰∏¥Êó∂ÁªìÊûúÈõÜÔºåËøô‰∫õÁªìÊûúÈõÜÂèØ‰ª•Âú®ÂêéÁª≠ÁöÑÊü•ËØ¢‰∏≠ÂºïÁî®„ÄÇ
with green_trips as (
    select 
        tripid,
        vendor_id,
        'Green' as service_type,
        pickup_datetime,
        dropoff_datetime,
        store_and_fwd_flag,
        ratecode_id,
        pickup_locationid,
        dropoff_locationid,
        passenger_count,
        trip_distance,
        fare_amount,
        extra,
        mta_tax,
        tip_amount,
        tolls_amount,
        improvement_surcharge,
        total_amount,
        payment_type,
        congestion_surcharge
    from `dataengine_learning`.`default`.`stg_green_tripdata`
),

-- 2. Â§ÑÁêÜÈªÑËâ≤Âá∫ÁßüËΩ¶Êï∞ÊçÆ
yellow_trips as (
    select 
        tripid,
        vendor_id,
        'Yellow' as service_type,
        pickup_datetime,
        dropoff_datetime,
        null as store_and_fwd_flag,
        ratecode_id,
        pickup_locationid,
        dropoff_locationid,
        passenger_count,
        trip_distance,
        fare_amount,
        null as extra,
        null as mta_tax,
        null as tip_amount,
        null as tolls_amount,
        null as improvement_surcharge,
        total_amount,
        payment_type,
        null as congestion_surcharge
    from `dataengine_learning`.`default`.`stg_yellow_tripdata`
),

-- 3. ÂêàÂπ∂‰∏§ÁßçÊï∞ÊçÆÔºåunion all ÊòØ SQL ‰∏≠ÁöÑÈõÜÂêàËøêÁÆóÁ¨¶ÔºåÁî®‰∫éÂêàÂπ∂‰∏§‰∏™ÊàñÂ§ö‰∏™Êü•ËØ¢ÁöÑÁªìÊûúÈõÜÔºåunion all ‰ºö‰øùÁïôÈáçÂ§çÁöÑË°åÔºåËÄå union ‰ºöÂéªÈô§ÈáçÂ§çÁöÑË°å„ÄÇ
trips_unioned as (
    select * from green_trips
    union all
    select * from yellow_trips
),

-- 4. ÂÖ≥ËÅîÁª¥Â∫¶‰ø°ÊÅØÔºåINNER JOIN Áî®‰∫éËøûÊé•‰∏§‰∏™Ë°®ÔºåËÄå ON Â≠êÂè•Áî®‰∫éÊåáÂÆöËøûÊé•Êù°‰ª∂„ÄÇ
final as (
    select 
        trips_unioned.tripid,
        trips_unioned.vendor_id,
        trips_unioned.service_type,
        trips_unioned.pickup_datetime,
        trips_unioned.dropoff_datetime,
        trips_unioned.store_and_fwd_flag,
        trips_unioned.ratecode_id,
        trips_unioned.pickup_locationid,
        trips_unioned.dropoff_locationid,
        trips_unioned.passenger_count,
        trips_unioned.trip_distance,
        trips_unioned.fare_amount,
        trips_unioned.extra,
        trips_unioned.mta_tax,
        trips_unioned.tip_amount,
        trips_unioned.tolls_amount,
        trips_unioned.improvement_surcharge,
        trips_unioned.total_amount,
        trips_unioned.payment_type,
        trips_unioned.congestion_surcharge,
        pickup_zone.borough as pickup_borough,
        pickup_zone.zone as pickup_zone,
        dropoff_zone.borough as dropoff_borough,
        dropoff_zone.zone as dropoff_zone

    from trips_unioned
    inner join `dataengine_learning`.`default`.`dim_zones` as pickup_zone
        on trips_unioned.pickup_locationid = pickup_zone.locationid
    inner join `dataengine_learning`.`default`.`dim_zones` as dropoff_zone
        on trips_unioned.dropoff_locationid = dropoff_zone.locationid
)

select * from final
    )
    ;

  
[0m22:50:08.727596 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m22:50:30.560751 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202145009100g3e5t5opyz1
[0m22:50:30.561277 [debug] [Thread-2  ]: SQL status: OK in 21.834 seconds
[0m22:50:30.562301 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202145009100g3e5t5opyz1
[0m22:50:30.734285 [debug] [Thread-2  ]: Using maxcompute connection "model.homework.fact_trips"
[0m22:50:30.735327 [debug] [Thread-2  ]: On model.homework.fact_trips: ALTER TABLE `dataengine_learning`.`default`.`fact_trips__dbt_tmp`
            RENAME TO fact_trips;
        
[0m22:50:32.952204 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202145030879geqnnb6awkr
[0m22:50:32.953205 [debug] [Thread-2  ]: SQL status: OK in 2.218 seconds
[0m22:50:32.954205 [debug] [Thread-2  ]: MaxCompute adapter: Current instance id is 20241202145030879geqnnb6awkr
[0m22:50:32.980181 [debug] [Thread-2  ]: On model.homework.fact_trips: COMMIT
[0m22:50:33.485419 [debug] [Thread-2  ]: On model.homework.fact_trips: Close
[0m22:50:33.487656 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1d277241-d40e-4235-af67-9e942ab0c474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181E9736460>]}
[0m22:50:33.489682 [info ] [Thread-2  ]: 1 of 1 OK created sql table model default.fact_trips ........................... [[32mOK[0m in 24.95s]
[0m22:50:33.490876 [debug] [Thread-2  ]: Finished running node model.homework.fact_trips
[0m22:50:33.493683 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:50:33.494285 [debug] [MainThread]: Connection 'list_dataengine_learning' was properly closed.
[0m22:50:33.494804 [debug] [MainThread]: Connection 'list_dataengine_learning_default' was properly closed.
[0m22:50:33.494804 [debug] [MainThread]: Connection 'model.homework.fact_trips' was properly closed.
[0m22:50:33.495803 [info ] [MainThread]: 
[0m22:50:33.496802 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 31.10 seconds (31.10s).
[0m22:50:33.498802 [debug] [MainThread]: Command end result
[0m22:50:33.550074 [info ] [MainThread]: 
[0m22:50:33.551077 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:50:33.552077 [info ] [MainThread]: 
[0m22:50:33.553077 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:50:33.555117 [debug] [MainThread]: Command `dbt run` succeeded at 22:50:33.555117 after 34.53 seconds
[0m22:50:33.557082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181E93665B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181874F4B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181EB96E310>]}
[0m22:50:33.558075 [debug] [MainThread]: Flushing usage events
